{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE-j1JOA1mG7",
        "outputId": "aa81c318-b05d-4c97-c58d-b9d4df2a2dcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.12\n",
            "x86_64\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!uname -m"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update -qq\n",
        "!sudo apt-get install -y python3.10 python3.10-venv python3.10-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04GpEe4E2Fe4",
        "outputId": "d73473ff-1749-44bf-9fda-eb8ef908a664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.10 libpython3.10-dev libpython3.10-minimal libpython3.10-stdlib\n",
            "  python3-pip-whl python3-setuptools-whl python3.10-minimal\n",
            "Suggested packages:\n",
            "  python3.10-doc binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl python3.10-dev python3.10-venv\n",
            "The following packages will be upgraded:\n",
            "  libpython3.10 libpython3.10-dev libpython3.10-minimal libpython3.10-stdlib\n",
            "  python3.10 python3.10-minimal\n",
            "6 upgraded, 4 newly installed, 0 to remove and 47 not upgraded.\n",
            "Need to get 15.2 MB of archives.\n",
            "After this operation, 3,286 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-dev amd64 3.10.12-1~22.04.14 [4,765 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10 amd64 3.10.12-1~22.04.14 [1,949 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10 amd64 3.10.12-1~22.04.14 [509 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-stdlib amd64 3.10.12-1~22.04.14 [1,850 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-minimal amd64 3.10.12-1~22.04.14 [2,275 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpython3.10-minimal amd64 3.10.12-1~22.04.14 [816 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.7 [1,683 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3.10-dev amd64 3.10.12-1~22.04.14 [508 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.14 [5,724 B]\n",
            "Get:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 python3-setuptools-whl all 68.1.2-2~jammy3 [792 kB]\n",
            "Fetched 15.2 MB in 2s (7,778 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 10.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "(Reading database ... 117540 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.10-dev_3.10.12-1~22.04.14_amd64.deb ...\n",
            "Unpacking libpython3.10-dev:amd64 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.13) ...\n",
            "Preparing to unpack .../1-libpython3.10_3.10.12-1~22.04.14_amd64.deb ...\n",
            "Unpacking libpython3.10:amd64 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.13) ...\n",
            "Preparing to unpack .../2-python3.10_3.10.12-1~22.04.14_amd64.deb ...\n",
            "Unpacking python3.10 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.13) ...\n",
            "Preparing to unpack .../3-libpython3.10-stdlib_3.10.12-1~22.04.14_amd64.deb ...\n",
            "Unpacking libpython3.10-stdlib:amd64 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.13) ...\n",
            "Preparing to unpack .../4-python3.10-minimal_3.10.12-1~22.04.14_amd64.deb ...\n",
            "Unpacking python3.10-minimal (3.10.12-1~22.04.14) over (3.10.12-1~22.04.13) ...\n",
            "Preparing to unpack .../5-libpython3.10-minimal_3.10.12-1~22.04.14_amd64.deb ...\n",
            "Unpacking libpython3.10-minimal:amd64 (3.10.12-1~22.04.14) over (3.10.12-1~22.04.13) ...\n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "Preparing to unpack .../6-python3-pip-whl_22.0.2+dfsg-1ubuntu0.7_all.deb ...\n",
            "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.7) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../7-python3-setuptools-whl_68.1.2-2~jammy3_all.deb ...\n",
            "Unpacking python3-setuptools-whl (68.1.2-2~jammy3) ...\n",
            "Selecting previously unselected package python3.10-dev.\n",
            "Preparing to unpack .../8-python3.10-dev_3.10.12-1~22.04.14_amd64.deb ...\n",
            "Unpacking python3.10-dev (3.10.12-1~22.04.14) ...\n",
            "Selecting previously unselected package python3.10-venv.\n",
            "Preparing to unpack .../9-python3.10-venv_3.10.12-1~22.04.14_amd64.deb ...\n",
            "Unpacking python3.10-venv (3.10.12-1~22.04.14) ...\n",
            "Setting up python3-setuptools-whl (68.1.2-2~jammy3) ...\n",
            "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.7) ...\n",
            "Setting up libpython3.10-minimal:amd64 (3.10.12-1~22.04.14) ...\n",
            "Setting up python3.10-minimal (3.10.12-1~22.04.14) ...\n",
            "Setting up libpython3.10-stdlib:amd64 (3.10.12-1~22.04.14) ...\n",
            "Setting up libpython3.10:amd64 (3.10.12-1~22.04.14) ...\n",
            "Setting up python3.10 (3.10.12-1~22.04.14) ...\n",
            "Setting up libpython3.10-dev:amd64 (3.10.12-1~22.04.14) ...\n",
            "Setting up python3.10-dev (3.10.12-1~22.04.14) ...\n",
            "Setting up python3.10-venv (3.10.12-1~22.04.14) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.10 -m venv /content/mfa_env"
      ],
      "metadata": {
        "id": "4Po0ECSN2a1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/mfa_env/bin/activate && python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WxRfGcF2mDb",
        "outputId": "2884b0ec-9523-4175-cedb-6ae087c03557"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/mfa_env/bin/activate && pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrkaAq-O2s6N",
        "outputId": "f769f752-72cc-4656-ef69-78ce9b8261ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in ./mfa_env/lib/python3.10/site-packages (22.0.2)\n",
            "Collecting pip\n",
            "  Downloading pip-26.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.2\n",
            "    Uninstalling pip-22.0.2:\n",
            "      Successfully uninstalled pip-22.0.2\n",
            "Successfully installed pip-26.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/mfa_env/bin/activate && pip install montreal-forced-aligner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC5kdh5i23xt",
        "outputId": "8bcbe719-6e69-416c-f386-d41a54b9f63e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting montreal-forced-aligner\n",
            "  Downloading montreal_forced_aligner-3.3.9-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting click (from montreal-forced-aligner)\n",
            "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting kneed (from montreal-forced-aligner)\n",
            "  Downloading kneed-0.8.5-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting librosa (from montreal-forced-aligner)\n",
            "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting matplotlib (from montreal-forced-aligner)\n",
            "  Downloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (52 kB)\n",
            "Collecting numpy (from montreal-forced-aligner)\n",
            "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting praatio>=6.0.0 (from montreal-forced-aligner)\n",
            "  Downloading praatio-6.2.2-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting pyyaml (from montreal-forced-aligner)\n",
            "  Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting requests (from montreal-forced-aligner)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting rich (from montreal-forced-aligner)\n",
            "  Downloading rich-14.3.2-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting rich-click (from montreal-forced-aligner)\n",
            "  Downloading rich_click-1.9.7-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting scikit-learn (from montreal-forced-aligner)\n",
            "  Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
            "Collecting seaborn (from montreal-forced-aligner)\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting sqlalchemy>=1.4 (from montreal-forced-aligner)\n",
            "  Downloading sqlalchemy-2.0.46-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Collecting tqdm (from montreal-forced-aligner)\n",
            "  Downloading tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting typing-extensions (from praatio>=6.0.0->montreal-forced-aligner)\n",
            "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting greenlet>=1 (from sqlalchemy>=1.4->montreal-forced-aligner)\n",
            "  Downloading greenlet-3.3.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting scipy>=1.0.0 (from kneed->montreal-forced-aligner)\n",
            "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting audioread>=2.1.9 (from librosa->montreal-forced-aligner)\n",
            "  Downloading audioread-3.1.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting numba>=0.51.0 (from librosa->montreal-forced-aligner)\n",
            "  Downloading numba-0.63.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting joblib>=1.0 (from librosa->montreal-forced-aligner)\n",
            "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting decorator>=4.3.0 (from librosa->montreal-forced-aligner)\n",
            "  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting soundfile>=0.12.1 (from librosa->montreal-forced-aligner)\n",
            "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
            "Collecting pooch>=1.1 (from librosa->montreal-forced-aligner)\n",
            "  Downloading pooch-1.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting soxr>=0.3.2 (from librosa->montreal-forced-aligner)\n",
            "  Downloading soxr-1.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting lazy_loader>=0.1 (from librosa->montreal-forced-aligner)\n",
            "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting msgpack>=1.0 (from librosa->montreal-forced-aligner)\n",
            "  Downloading msgpack-1.1.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting packaging (from lazy_loader>=0.1->librosa->montreal-forced-aligner)\n",
            "  Downloading packaging-26.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting llvmlite<0.47,>=0.46.0dev0 (from numba>=0.51.0->librosa->montreal-forced-aligner)\n",
            "  Downloading llvmlite-0.46.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting platformdirs>=2.5.0 (from pooch>=1.1->librosa->montreal-forced-aligner)\n",
            "  Downloading platformdirs-4.5.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->montreal-forced-aligner)\n",
            "  Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->montreal-forced-aligner)\n",
            "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->montreal-forced-aligner)\n",
            "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->montreal-forced-aligner)\n",
            "  Downloading certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn->montreal-forced-aligner)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting cffi>=1.0 (from soundfile>=0.12.1->librosa->montreal-forced-aligner)\n",
            "  Downloading cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.6 kB)\n",
            "Collecting pycparser (from cffi>=1.0->soundfile>=0.12.1->librosa->montreal-forced-aligner)\n",
            "  Downloading pycparser-3.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->montreal-forced-aligner)\n",
            "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->montreal-forced-aligner)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->montreal-forced-aligner)\n",
            "  Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (114 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib->montreal-forced-aligner)\n",
            "  Downloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting pillow>=8 (from matplotlib->montreal-forced-aligner)\n",
            "  Downloading pillow-12.1.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting pyparsing>=3 (from matplotlib->montreal-forced-aligner)\n",
            "  Downloading pyparsing-3.3.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib->montreal-forced-aligner)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib->montreal-forced-aligner)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich->montreal-forced-aligner)\n",
            "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich->montreal-forced-aligner)\n",
            "  Downloading pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->montreal-forced-aligner)\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting pandas>=1.2 (from seaborn->montreal-forced-aligner)\n",
            "  Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "Collecting pytz>=2020.1 (from pandas>=1.2->seaborn->montreal-forced-aligner)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas>=1.2->seaborn->montreal-forced-aligner)\n",
            "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading montreal_forced_aligner-3.3.9-py3-none-any.whl (417 kB)\n",
            "Downloading praatio-6.2.2-py3-none-any.whl (82 kB)\n",
            "Downloading sqlalchemy-2.0.46-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading greenlet-3.3.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (586 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.0/587.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
            "Downloading kneed-0.8.5-py3-none-any.whl (10 kB)\n",
            "Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/37.7 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
            "Downloading audioread-3.1.0-py3-none-any.whl (23 kB)\n",
            "Downloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
            "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
            "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Downloading msgpack-1.1.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (406 kB)\n",
            "Downloading numba-0.63.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m100.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llvmlite-0.46.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pooch-1.9.0-py3-none-any.whl (67 kB)\n",
            "Downloading packaging-26.0-py3-none-any.whl (74 kB)\n",
            "Downloading platformdirs-4.5.1-py3-none-any.whl (18 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
            "Downloading certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
            "Downloading scikit_learn-1.7.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cffi-2.0.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216 kB)\n",
            "Downloading soxr-1.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (242 kB)\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading matplotlib-3.10.8-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.61.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-12.1.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.3.2-py3-none-any.whl (122 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pycparser-3.0-py3-none-any.whl (48 kB)\n",
            "Downloading pyyaml-6.0.3-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (770 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m770.3/770.3 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-14.3.2-py3-none-any.whl (309 kB)\n",
            "Downloading pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
            "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Downloading rich_click-1.9.7-py3-none-any.whl (71 kB)\n",
            "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
            "Downloading tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: pytz, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, six, pyyaml, pyparsing, pygments, pycparser, platformdirs, pillow, packaging, numpy, msgpack, mdurl, llvmlite, kiwisolver, joblib, idna, greenlet, fonttools, decorator, cycler, click, charset_normalizer, certifi, audioread, sqlalchemy, soxr, scipy, requests, python-dateutil, praatio, numba, markdown-it-py, lazy_loader, contourpy, cffi, soundfile, scikit-learn, rich, pooch, pandas, matplotlib, kneed, seaborn, rich-click, librosa, montreal-forced-aligner\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51/51\u001b[0m [montreal-forced-aligner]\n",
            "\u001b[1A\u001b[2KSuccessfully installed audioread-3.1.0 certifi-2026.1.4 cffi-2.0.0 charset_normalizer-3.4.4 click-8.3.1 contourpy-1.3.2 cycler-0.12.1 decorator-5.2.1 fonttools-4.61.1 greenlet-3.3.1 idna-3.11 joblib-1.5.3 kiwisolver-1.4.9 kneed-0.8.5 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.46.0 markdown-it-py-4.0.0 matplotlib-3.10.8 mdurl-0.1.2 montreal-forced-aligner-3.3.9 msgpack-1.1.2 numba-0.63.1 numpy-2.2.6 packaging-26.0 pandas-2.3.3 pillow-12.1.0 platformdirs-4.5.1 pooch-1.9.0 praatio-6.2.2 pycparser-3.0 pygments-2.19.2 pyparsing-3.3.2 python-dateutil-2.9.0.post0 pytz-2025.2 pyyaml-6.0.3 requests-2.32.5 rich-14.3.2 rich-click-1.9.7 scikit-learn-1.7.2 scipy-1.15.3 seaborn-0.13.2 six-1.17.0 soundfile-0.13.1 soxr-1.0.0 sqlalchemy-2.0.46 threadpoolctl-3.6.0 tqdm-4.67.3 typing-extensions-4.15.0 tzdata-2025.3 urllib3-2.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/mfa_env/bin/activate && mfa version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVC1Yy7Q3Wz-",
        "outputId": "d5d56d6b-a6c7-472f-8f2a-15bc123e61e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/mfa_env/bin/mfa\", line 3, in <module>\n",
            "    from montreal_forced_aligner.command_line.mfa import mfa_cli\n",
            "  File \"/content/mfa_env/lib/python3.10/site-packages/montreal_forced_aligner/__init__.py\", line 4, in <module>\n",
            "    import montreal_forced_aligner.acoustic_modeling as acoustic_modeling\n",
            "  File \"/content/mfa_env/lib/python3.10/site-packages/montreal_forced_aligner/acoustic_modeling/__init__.py\", line 7, in <module>\n",
            "    from montreal_forced_aligner.acoustic_modeling.base import AcousticModelTrainingMixin  # noqa\n",
            "  File \"/content/mfa_env/lib/python3.10/site-packages/montreal_forced_aligner/acoustic_modeling/base.py\", line 12, in <module>\n",
            "    from _kalpy.gmm import AccumAmDiagGmm\n",
            "ModuleNotFoundError: No module named '_kalpy'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y sox libsox-dev libsox-fmt-all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b1abyoy3ksy",
        "outputId": "be6e5d09-2cd9-4ab8-f7ff-996e9f48026a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libao-common libao4 libid3tag0 libmad0 libopencore-amrnb0 libopencore-amrwb0\n",
            "  libsox-fmt-alsa libsox-fmt-ao libsox-fmt-base libsox-fmt-mp3 libsox-fmt-oss\n",
            "  libsox-fmt-pulse libsox3 libwavpack1\n",
            "Suggested packages:\n",
            "  libaudio2 libsndio6.1\n",
            "The following NEW packages will be installed:\n",
            "  libao-common libao4 libid3tag0 libmad0 libopencore-amrnb0 libopencore-amrwb0\n",
            "  libsox-dev libsox-fmt-all libsox-fmt-alsa libsox-fmt-ao libsox-fmt-base\n",
            "  libsox-fmt-mp3 libsox-fmt-oss libsox-fmt-pulse libsox3 libwavpack1 sox\n",
            "0 upgraded, 17 newly installed, 0 to remove and 47 not upgraded.\n",
            "Need to get 1,157 kB of archives.\n",
            "After this operation, 4,262 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libao-common all 1.2.2+20180113-1.1ubuntu3 [6,568 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libao4 amd64 1.2.2+20180113-1.1ubuntu3 [35.2 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libid3tag0 amd64 0.15.1b-14 [31.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmad0 amd64 0.15.1b-10ubuntu1 [63.1 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrnb0 amd64 0.1.5-1 [94.8 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrwb0 amd64 0.1.5-1 [49.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [240 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [11.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-ao amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [7,740 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwavpack1 amd64 5.4.0-1build2 [83.7 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-base amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [33.7 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-mp3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [17.3 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-oss amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [9,424 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-pulse amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [7,732 B]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-all amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [5,016 B]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-dev amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [356 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 sox amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [104 kB]\n",
            "Fetched 1,157 kB in 1s (1,115 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 17.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libao-common.\n",
            "(Reading database ... 117564 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libao-common_1.2.2+20180113-1.1ubuntu3_all.deb ...\n",
            "Unpacking libao-common (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Selecting previously unselected package libao4:amd64.\n",
            "Preparing to unpack .../01-libao4_1.2.2+20180113-1.1ubuntu3_amd64.deb ...\n",
            "Unpacking libao4:amd64 (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Selecting previously unselected package libid3tag0:amd64.\n",
            "Preparing to unpack .../02-libid3tag0_0.15.1b-14_amd64.deb ...\n",
            "Unpacking libid3tag0:amd64 (0.15.1b-14) ...\n",
            "Selecting previously unselected package libmad0:amd64.\n",
            "Preparing to unpack .../03-libmad0_0.15.1b-10ubuntu1_amd64.deb ...\n",
            "Unpacking libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "Preparing to unpack .../04-libopencore-amrnb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../05-libopencore-amrwb0_0.1.5-1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../06-libsox3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../07-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-ao:amd64.\n",
            "Preparing to unpack .../08-libsox-fmt-ao_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-ao:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libwavpack1:amd64.\n",
            "Preparing to unpack .../09-libwavpack1_5.4.0-1build2_amd64.deb ...\n",
            "Unpacking libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../10-libsox-fmt-base_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-mp3:amd64.\n",
            "Preparing to unpack .../11-libsox-fmt-mp3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-oss:amd64.\n",
            "Preparing to unpack .../12-libsox-fmt-oss_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-oss:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-pulse:amd64.\n",
            "Preparing to unpack .../13-libsox-fmt-pulse_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-pulse:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-all:amd64.\n",
            "Preparing to unpack .../14-libsox-fmt-all_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-all:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libsox-dev:amd64.\n",
            "Preparing to unpack .../15-libsox-dev_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsox-dev:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package sox.\n",
            "Preparing to unpack .../16-sox_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-oss:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libao-common (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Setting up libid3tag0:amd64 (0.15.1b-14) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libao4:amd64 (1.2.2+20180113-1.1ubuntu3) ...\n",
            "Setting up libmad0:amd64 (0.15.1b-10ubuntu1) ...\n",
            "Setting up libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-ao:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-mp3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-pulse:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-fmt-all:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Setting up libsox-dev:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.11) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!source /content/mfa_env/bin/activate && pip install kalpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb8GucIm33Ry",
        "outputId": "2e7f1723-6091-47f5-e46b-86963e0a5081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement kalpy (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for kalpy\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n",
        "!bash miniconda.sh -b -p /content/miniconda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoiJZFdv4HfR",
        "outputId": "5da64027-ecc0-465e-8dc9-2535d64c7f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-02-06 16:54:43--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.191.158, 104.16.32.241, 2606:4700::6810:bf9e, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.191.158|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 156772981 (150M) [application/octet-stream]\n",
            "Saving to: ‘miniconda.sh’\n",
            "\n",
            "miniconda.sh        100%[===================>] 149.51M   116MB/s    in 1.3s    \n",
            "\n",
            "2026-02-06 16:54:44 (116 MB/s) - ‘miniconda.sh’ saved [156772981/156772981]\n",
            "\n",
            "PREFIX=/content/miniconda\n",
            "Unpacking bootstrapper...\n",
            "Unpacking payload...\n",
            "\n",
            "Installing base environment...\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /content/miniconda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && conda --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pza9PzZN4Zc-",
        "outputId": "a2daa3a0-d41a-4476-9022-578843c34e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conda 25.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && conda create -n mfa_conda python=3.10 -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VJUj3hm4iIV",
        "outputId": "9f882260-f3da-42f9-fe7f-16c8ae470430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;33mJupyter detected\u001b[0m\u001b[1;33m...\u001b[0m\n",
            "\n",
            "CondaToSNonInteractiveError: Terms of Service have not been accepted for the following channels. Please accept or remove them before proceeding:\n",
            "    - https://repo.anaconda.com/pkgs/main\n",
            "    - https://repo.anaconda.com/pkgs/r\n",
            "\n",
            "To accept these channels' Terms of Service, run the following commands:\n",
            "    conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\n",
            "    conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n",
            "\n",
            "For information on safely removing channels from your conda configuration,\n",
            "please see the official documentation:\n",
            "\n",
            "    https://www.anaconda.com/docs/tools/working-with-conda/channels\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && conda config --set restore_free_channel true"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5inH1mC4q85",
        "outputId": "931200d5-ace5-4158-c6bd-5a7e32885313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unknown key: 'restore_free_channel'\n",
            "\n",
            "CondaKeyError: 'restore_free_channel': unknown parameter\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && conda create -n mfa_conda python=3.10 -c conda-forge -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsuWEFkF4yV_",
        "outputId": "ace32bf4-994a-4ae3-c245-5f666c329fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;33mJupyter detected\u001b[0m\u001b[1;33m...\u001b[0m\n",
            "\n",
            "CondaToSNonInteractiveError: Terms of Service have not been accepted for the following channels. Please accept or remove them before proceeding:\n",
            "    - https://repo.anaconda.com/pkgs/main\n",
            "    - https://repo.anaconda.com/pkgs/r\n",
            "\n",
            "To accept these channels' Terms of Service, run the following commands:\n",
            "    conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\n",
            "    conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n",
            "\n",
            "For information on safely removing channels from your conda configuration,\n",
            "please see the official documentation:\n",
            "\n",
            "    https://www.anaconda.com/docs/tools/working-with-conda/channels\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && conda config --remove channels defaults && conda config --add channels conda-forge && conda config --set channel_priority strict"
      ],
      "metadata": {
        "id": "qtLMDzIH453y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && conda create -n mfa_conda python=3.10 -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MthxFhp-5Bes",
        "outputId": "a771a2b8-e116-435d-bca2-8a1ee1086989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;33mJupyter detected\u001b[0m\u001b[1;33m...\u001b[0m\n",
            "\n",
            "CondaToSNonInteractiveError: Terms of Service have not been accepted for the following channels. Please accept or remove them before proceeding:\n",
            "    - https://repo.anaconda.com/pkgs/main\n",
            "    - https://repo.anaconda.com/pkgs/r\n",
            "\n",
            "To accept these channels' Terms of Service, run the following commands:\n",
            "    conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\n",
            "    conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n",
            "\n",
            "For information on safely removing channels from your conda configuration,\n",
            "please see the official documentation:\n",
            "\n",
            "    https://www.anaconda.com/docs/tools/working-with-conda/channels\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && rm -f /content/miniconda/.condarc ~/.condarc && conda config --add channels conda-forge && conda config --set channel_priority strict"
      ],
      "metadata": {
        "id": "BJqI8CPt5JVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && conda create -n mfa_conda python=3.10 -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_LBB9r05OMj",
        "outputId": "3611f0dc-38de-4e12-ee15-27f0748bf136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;33mJupyter detected\u001b[0m\u001b[1;33m...\u001b[0m\n",
            "Retrieving notices: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /content/miniconda/envs/mfa_conda\n",
            "\n",
            "  added / updated specs:\n",
            "    - python=3.10\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _libgcc_mutex-0.1          |      conda_forge           3 KB  conda-forge\n",
            "    _openmp_mutex-4.5          |            2_gnu          23 KB  conda-forge\n",
            "    bzip2-1.0.8                |       hda65f42_8         254 KB  conda-forge\n",
            "    ca-certificates-2026.1.4   |       hbd8a1cb_0         143 KB  conda-forge\n",
            "    icu-78.2                   |       h33c6efd_0        12.1 MB  conda-forge\n",
            "    ld_impl_linux-64-2.45.1    |default_hbd61a6d_101         709 KB  conda-forge\n",
            "    libexpat-2.7.3             |       hecca717_0          75 KB  conda-forge\n",
            "    libffi-3.5.2               |       h3435931_0          57 KB  conda-forge\n",
            "    libgcc-15.2.0              |      he0feb66_17        1016 KB  conda-forge\n",
            "    libgcc-ng-15.2.0           |      h69a702a_17          27 KB  conda-forge\n",
            "    libgomp-15.2.0             |      he0feb66_17         589 KB  conda-forge\n",
            "    liblzma-5.8.2              |       hb03c661_0         111 KB  conda-forge\n",
            "    libnsl-2.0.1               |       hb9d3cd8_1          33 KB  conda-forge\n",
            "    libsqlite-3.51.2           |       hf4e2dac_0         921 KB  conda-forge\n",
            "    libstdcxx-15.2.0           |      h934c35e_17         5.6 MB  conda-forge\n",
            "    libuuid-2.41.3             |       h5347b49_0          39 KB  conda-forge\n",
            "    libxcrypt-4.4.36           |       hd590300_1          98 KB  conda-forge\n",
            "    libzlib-1.3.1              |       hb9d3cd8_2          60 KB  conda-forge\n",
            "    ncurses-6.5                |       h2d0b736_3         871 KB  conda-forge\n",
            "    openssl-3.6.1              |       h35e630c_1         3.0 MB  conda-forge\n",
            "    packaging-26.0             |     pyhcf101f3_0          70 KB  conda-forge\n",
            "    pip-26.0.1                 |     pyh8b19718_0         1.1 MB  conda-forge\n",
            "    python-3.10.19             |h3c07f61_3_cpython        24.2 MB  conda-forge\n",
            "    readline-8.3               |       h853b02a_0         337 KB  conda-forge\n",
            "    setuptools-80.10.2         |     pyh332efcf_0         663 KB  conda-forge\n",
            "    tk-8.6.13                  |noxft_h366c992_103         3.1 MB  conda-forge\n",
            "    tzdata-2025c               |       hc9c84f9_1         116 KB  conda-forge\n",
            "    wheel-0.46.3               |     pyhd8ed1ab_0          31 KB  conda-forge\n",
            "    zstd-1.5.7                 |       hb78ec9c_6         587 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        55.9 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge \n",
            "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-2_gnu \n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-hda65f42_8 \n",
            "  ca-certificates    conda-forge/noarch::ca-certificates-2026.1.4-hbd8a1cb_0 \n",
            "  icu                conda-forge/linux-64::icu-78.2-h33c6efd_0 \n",
            "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.45.1-default_hbd61a6d_101 \n",
            "  libexpat           conda-forge/linux-64::libexpat-2.7.3-hecca717_0 \n",
            "  libffi             conda-forge/linux-64::libffi-3.5.2-h3435931_0 \n",
            "  libgcc             conda-forge/linux-64::libgcc-15.2.0-he0feb66_17 \n",
            "  libgcc-ng          conda-forge/linux-64::libgcc-ng-15.2.0-h69a702a_17 \n",
            "  libgomp            conda-forge/linux-64::libgomp-15.2.0-he0feb66_17 \n",
            "  liblzma            conda-forge/linux-64::liblzma-5.8.2-hb03c661_0 \n",
            "  libnsl             conda-forge/linux-64::libnsl-2.0.1-hb9d3cd8_1 \n",
            "  libsqlite          conda-forge/linux-64::libsqlite-3.51.2-hf4e2dac_0 \n",
            "  libstdcxx          conda-forge/linux-64::libstdcxx-15.2.0-h934c35e_17 \n",
            "  libuuid            conda-forge/linux-64::libuuid-2.41.3-h5347b49_0 \n",
            "  libxcrypt          conda-forge/linux-64::libxcrypt-4.4.36-hd590300_1 \n",
            "  libzlib            conda-forge/linux-64::libzlib-1.3.1-hb9d3cd8_2 \n",
            "  ncurses            conda-forge/linux-64::ncurses-6.5-h2d0b736_3 \n",
            "  openssl            conda-forge/linux-64::openssl-3.6.1-h35e630c_1 \n",
            "  packaging          conda-forge/noarch::packaging-26.0-pyhcf101f3_0 \n",
            "  pip                conda-forge/noarch::pip-26.0.1-pyh8b19718_0 \n",
            "  python             conda-forge/linux-64::python-3.10.19-h3c07f61_3_cpython \n",
            "  readline           conda-forge/linux-64::readline-8.3-h853b02a_0 \n",
            "  setuptools         conda-forge/noarch::setuptools-80.10.2-pyh332efcf_0 \n",
            "  tk                 conda-forge/linux-64::tk-8.6.13-noxft_h366c992_103 \n",
            "  tzdata             conda-forge/noarch::tzdata-2025c-hc9c84f9_1 \n",
            "  wheel              conda-forge/noarch::wheel-0.46.3-pyhd8ed1ab_0 \n",
            "  zstd               conda-forge/linux-64::zstd-1.5.7-hb78ec9c_6 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "python-3.10.19       | 24.2 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "icu-78.2             | 12.1 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "libstdcxx-15.2.0     | 5.6 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tk-8.6.13            | 3.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.6.1        | 3.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-26.0.1           | 1.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.2.0        | 1016 KB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.51.2     | 921 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 709 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.10.2   | 663 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.2.0       | 589 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstd-1.5.7           | 587 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.3         | 337 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 254 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2026 | 143 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025c         | 116 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.2        | 111 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.19       | 24.2 MB   | :   0% 0.0006460997877145765/1 [00:00<10:57, 657.98s/it]\n",
            "\n",
            "libstdcxx-15.2.0     | 5.6 MB    | :   0% 0.002799532363270764/1 [00:00<02:30, 150.59s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tk-8.6.13            | 3.1 MB    | :   0% 0.004963049755300806/1 [00:00<01:27, 88.17s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.6.1        | 3.0 MB    | :   1% 0.005177353754134473/1 [00:00<01:25, 86.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "python-3.10.19       | 24.2 MB   | :  12% 0.12082066030262582/1 [00:00<00:02,  3.31s/it]   \n",
            "\n",
            "libstdcxx-15.2.0     | 5.6 MB    | :  70% 0.6998830908176911/1 [00:00<00:00,  1.76it/s]   \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tk-8.6.13            | 3.1 MB    | :  87% 0.8734967569329419/1 [00:00<00:00,  2.12it/s]  \u001b[A\u001b[A\u001b[A\n",
            "python-3.10.19       | 24.2 MB   | :  28% 0.28363780680669914/1 [00:00<00:01,  1.54s/it]\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.6.1        | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  1.97it/s]                 \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "openssl-3.6.1        | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  1.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tk-8.6.13            | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  2.12it/s]               \u001b[A\u001b[A\u001b[A\n",
            "python-3.10.19       | 24.2 MB   | :  41% 0.41350386413732904/1 [00:00<00:00,  1.21s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.2.0        | 1016 KB   | :   2% 0.01574660877019985/1 [00:00<00:46, 47.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "icu-78.2             | 12.1 MB   | :  92% 0.9242065311198657/1 [00:00<00:00,  1.80it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-26.0.1           | 1.1 MB    | :   1% 0.013863715211670432/1 [00:00<00:53, 54.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "python-3.10.19       | 24.2 MB   | :  57% 0.5679217134011129/1 [00:00<00:00,  1.03it/s] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.2.0        | 1016 KB   | : 100% 1.0/1 [00:00<00:00, 47.05s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-26.0.1           | 1.1 MB    | : 100% 1.0/1 [00:00<00:00, 54.50s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.19       | 24.2 MB   | :  71% 0.7107097664860342/1 [00:00<00:00,  1.14it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.51.2     | 921 KB    | : 100% 1.0/1 [00:00<00:00, 48.97s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | :   2% 0.018375108367605347/1 [00:00<00:49, 50.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 709 KB    | :   2% 0.022582828284220553/1 [00:00<00:42, 43.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.19       | 24.2 MB   | :  85% 0.8522056199955265/1 [00:01<00:00,  1.18it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | : 100% 1.0/1 [00:01<00:00, 50.88s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 709 KB    | : 100% 1.0/1 [00:01<00:00, 43.62s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.10.2   | 663 KB    | : 100% 1.0/1 [00:01<00:00, 40.81s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstd-1.5.7           | 587 KB    | :   3% 0.027244231968405738/1 [00:01<00:39, 40.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.2.0       | 589 KB    | :   3% 0.02715577109859547/1 [00:01<00:40, 41.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.3         | 337 KB    | :   5% 0.047479808620205/1 [00:01<00:23, 24.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstd-1.5.7           | 587 KB    | : 100% 1.0/1 [00:01<00:00, 40.79s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "icu-78.2             | 12.1 MB   | : 100% 1.0/1 [00:01<00:00,  1.80it/s]               \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.2.0       | 589 KB    | : 100% 1.0/1 [00:01<00:00, 41.88s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.3         | 337 KB    | : 100% 1.0/1 [00:01<00:00, 24.18s/it]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 254 KB    | :   6% 0.06293284576766625/1 [00:01<00:18, 19.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 254 KB    | : 100% 1.0/1 [00:01<00:00, 19.36s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.2        | 111 KB    | :  14% 0.14472603284249208/1 [00:01<00:07,  8.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.2        | 111 KB    | : 100% 1.0/1 [00:01<00:00,  8.80s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | :  16% 0.163198629386511/1 [00:01<00:06,  7.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025c         | 116 KB    | :  14% 0.13752465690183405/1 [00:01<00:08,  9.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025c         | 116 KB    | : 100% 1.0/1 [00:01<00:00,  9.56s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2026 | 143 KB    | :  11% 0.11182167500460691/1 [00:01<00:10, 11.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | : 100% 1.0/1 [00:01<00:00,  7.96s/it]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2026 | 143 KB    | : 100% 1.0/1 [00:01<00:00, 11.88s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.19       | 24.2 MB   | : 100% 1.0/1 [00:01<00:00,  2.02s/it]\n",
            "\n",
            "\n",
            "tk-8.6.13            | 3.1 MB    | : 100% 1.0/1 [00:01<00:00,  2.12it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.2.0        | 1016 KB   | : 100% 1.0/1 [00:01<00:00,  1.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.2.0        | 1016 KB   | : 100% 1.0/1 [00:01<00:00,  1.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libstdcxx-15.2.0     | 5.6 MB    | : 100% 1.0/1 [00:01<00:00,  1.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.51.2     | 921 KB    | : 100% 1.0/1 [00:01<00:00,  1.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.51.2     | 921 KB    | : 100% 1.0/1 [00:01<00:00,  1.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-26.0.1           | 1.1 MB    | : 100% 1.0/1 [00:02<00:00,  2.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pip-26.0.1           | 1.1 MB    | : 100% 1.0/1 [00:02<00:00,  2.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 709 KB    | : 100% 1.0/1 [00:02<00:00,  2.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 709 KB    | : 100% 1.0/1 [00:02<00:00,  2.07s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.10.2   | 663 KB    | : 100% 1.0/1 [00:02<00:00,  2.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.10.2   | 663 KB    | : 100% 1.0/1 [00:02<00:00,  2.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstd-1.5.7           | 587 KB    | : 100% 1.0/1 [00:02<00:00,  2.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstd-1.5.7           | 587 KB    | : 100% 1.0/1 [00:02<00:00,  2.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "icu-78.2             | 12.1 MB   | : 100% 1.0/1 [00:03<00:00,  1.80it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | : 100% 1.0/1 [00:03<00:00,  3.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | : 100% 1.0/1 [00:03<00:00,  3.44s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.3         | 337 KB    | : 100% 1.0/1 [00:03<00:00,  3.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.3         | 337 KB    | : 100% 1.0/1 [00:03<00:00,  3.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.2.0       | 589 KB    | : 100% 1.0/1 [00:03<00:00,  3.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.2.0       | 589 KB    | : 100% 1.0/1 [00:03<00:00,  3.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.2        | 111 KB    | : 100% 1.0/1 [00:03<00:00,  3.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.2        | 111 KB    | : 100% 1.0/1 [00:03<00:00,  3.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 254 KB    | : 100% 1.0/1 [00:03<00:00,  3.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "bzip2-1.0.8          | 254 KB    | : 100% 1.0/1 [00:03<00:00,  3.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | : 100% 1.0/1 [00:03<00:00,  3.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcrypt-4.4.36     | 98 KB     | : 100% 1.0/1 [00:03<00:00,  3.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2026 | 143 KB    | : 100% 1.0/1 [00:03<00:00,  3.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2026 | 143 KB    | : 100% 1.0/1 [00:03<00:00,  3.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025c         | 116 KB    | : 100% 1.0/1 [00:04<00:00,  3.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.19       | 24.2 MB   | : 100% 1.0/1 [00:05<00:00,  2.02s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: \\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate mfa_conda\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && conda install -n mfa_conda -c conda-forge montreal-forced-aligner -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYj8I6tB5yoD",
        "outputId": "8fff4c0e-e6c3-46c2-a98b-a590d2c31a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;33mJupyter detected\u001b[0m\u001b[1;33m...\u001b[0m\n",
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /content/miniconda/envs/mfa_conda\n",
            "\n",
            "  added / updated specs:\n",
            "    - montreal-forced-aligner\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    adwaita-icon-theme-49.0    |           unix_0         617 KB  conda-forge\n",
            "    alsa-lib-1.2.15.3          |       hb03c661_0         571 KB  conda-forge\n",
            "    aom-3.9.1                  |       hac33072_0         2.6 MB  conda-forge\n",
            "    at-spi2-atk-2.38.0         |       h0630a04_3         332 KB  conda-forge\n",
            "    at-spi2-core-2.40.3        |       h0630a04_0         643 KB  conda-forge\n",
            "    atk-1.0-2.38.0             |       h04ea711_2         348 KB  conda-forge\n",
            "    attr-2.5.2                 |       h39aace5_0          66 KB  conda-forge\n",
            "    audioread-3.0.1            |  py310hff52083_3          37 KB  conda-forge\n",
            "    backports.zstd-1.3.0       |  py310h69bd2ac_0         187 KB  conda-forge\n",
            "    baumwelch-0.3.11           |       hb700be7_0         402 KB  conda-forge\n",
            "    brotli-1.2.0               |       hed03a55_1          20 KB  conda-forge\n",
            "    brotli-bin-1.2.0           |       hb03c661_1          21 KB  conda-forge\n",
            "    brotli-python-1.2.0        |  py310hba01987_1         358 KB  conda-forge\n",
            "    cairo-1.18.4               |       he90730b_1         966 KB  conda-forge\n",
            "    certifi-2026.1.4           |     pyhd8ed1ab_0         147 KB  conda-forge\n",
            "    cffi-2.0.0                 |  py310he7384ee_1         239 KB  conda-forge\n",
            "    charset-normalizer-3.4.4   |     pyhd8ed1ab_0          50 KB  conda-forge\n",
            "    click-8.3.1                |     pyh8f84b5b_1          95 KB  conda-forge\n",
            "    contourpy-1.3.2            |  py310h3788b33_0         255 KB  conda-forge\n",
            "    cycler-0.12.1              |     pyhcf101f3_2          14 KB  conda-forge\n",
            "    cyrus-sasl-2.1.28          |       hd9c7081_0         205 KB  conda-forge\n",
            "    dav1d-1.2.1                |       hd590300_0         742 KB  conda-forge\n",
            "    dbus-1.16.2                |       h24cb091_1         437 KB  conda-forge\n",
            "    decorator-5.2.1            |     pyhd8ed1ab_0          14 KB  conda-forge\n",
            "    epoxy-1.5.10               |       hb03c661_2         402 KB  conda-forge\n",
            "    ffmpeg-8.0.1               | gpl_h43fde53_912        11.9 MB  conda-forge\n",
            "    font-ttf-dejavu-sans-mono-2.37|       hab24e00_0         388 KB  conda-forge\n",
            "    font-ttf-inconsolata-3.000 |       h77eed37_0          94 KB  conda-forge\n",
            "    font-ttf-source-code-pro-2.038|       h77eed37_0         684 KB  conda-forge\n",
            "    font-ttf-ubuntu-0.83       |       h77eed37_3         1.5 MB  conda-forge\n",
            "    fontconfig-2.15.0          |       h7e30c49_1         259 KB  conda-forge\n",
            "    fonts-conda-ecosystem-1    |                0           4 KB  conda-forge\n",
            "    fonts-conda-forge-1        |       hc364b38_1           4 KB  conda-forge\n",
            "    fonttools-4.61.1           |  py310h3406613_0         2.3 MB  conda-forge\n",
            "    freetype-2.14.1            |       ha770c72_0         169 KB  conda-forge\n",
            "    fribidi-1.0.16             |       hb03c661_0          60 KB  conda-forge\n",
            "    gdk-pixbuf-2.44.5          |       h2b0a6b4_0         562 KB  conda-forge\n",
            "    gettext-0.25.1             |       h3f43e3d_1         529 KB  conda-forge\n",
            "    gettext-tools-0.25.1       |       h3f43e3d_1         3.5 MB  conda-forge\n",
            "    glib-tools-2.86.3          |       hf516916_0         114 KB  conda-forge\n",
            "    glslang-16.2.0             |       h96af755_1         1.3 MB  conda-forge\n",
            "    gmp-6.3.0                  |       hac33072_2         449 KB  conda-forge\n",
            "    graphite2-1.3.14           |       hecca717_2          97 KB  conda-forge\n",
            "    graphviz-14.1.2            |       h8b86629_0         2.3 MB  conda-forge\n",
            "    greenlet-3.3.1             |  py310h25320af_1         222 KB  conda-forge\n",
            "    gtk3-3.24.43               |       h993cebd_6         5.3 MB  conda-forge\n",
            "    gts-0.7.6                  |       h977cf35_4         311 KB  conda-forge\n",
            "    h2-4.3.0                   |     pyhcf101f3_0          94 KB  conda-forge\n",
            "    harfbuzz-12.3.2            |       h6083320_0         1.9 MB  conda-forge\n",
            "    hdbscan-0.8.41             |  py310hf779ad0_0         556 KB  conda-forge\n",
            "    hicolor-icon-theme-0.17    |       ha770c72_2          14 KB  conda-forge\n",
            "    hpack-4.1.0                |     pyhd8ed1ab_0          30 KB  conda-forge\n",
            "    hyperframe-6.1.0           |     pyhd8ed1ab_0          17 KB  conda-forge\n",
            "    idna-3.11                  |     pyhd8ed1ab_0          50 KB  conda-forge\n",
            "    importlib-metadata-8.7.0   |     pyhe01879c_1          34 KB  conda-forge\n",
            "    intel-gmmlib-22.9.0        |       hb700be7_0         986 KB  conda-forge\n",
            "    intel-media-driver-25.3.4  |       hecca717_0         8.0 MB  conda-forge\n",
            "    joblib-1.5.3               |     pyhd8ed1ab_0         221 KB  conda-forge\n",
            "    kaldi-5.5.1172             |   cpu_h5f874f2_3        20.6 MB  conda-forge\n",
            "    kalpy-0.9.0                |  py310h03d9f68_0         3.5 MB  conda-forge\n",
            "    keyutils-1.6.3             |       hb9d3cd8_0         131 KB  conda-forge\n",
            "    kiwisolver-1.4.9           |  py310haaf941d_2          76 KB  conda-forge\n",
            "    kneed-0.8.5                |     pyhd8ed1ab_1          15 KB  conda-forge\n",
            "    krb5-1.21.3                |       h659f571_0         1.3 MB  conda-forge\n",
            "    lame-3.100                 |    h166bdaf_1003         496 KB  conda-forge\n",
            "    lazy-loader-0.4            |     pyhd8ed1ab_2          16 KB  conda-forge\n",
            "    lazy_loader-0.4            |     pyhd8ed1ab_2           7 KB  conda-forge\n",
            "    lcms2-2.18                 |       h0c24ade_0         244 KB  conda-forge\n",
            "    lerc-4.0.0                 |       h0aef613_1         258 KB  conda-forge\n",
            "    level-zero-1.28.0          |       hb700be7_0         657 KB  conda-forge\n",
            "    libabseil-20250512.1       | cxx17_hba17884_0         1.2 MB  conda-forge\n",
            "    libasprintf-0.25.1         |       h3f43e3d_1          52 KB  conda-forge\n",
            "    libasprintf-devel-0.25.1   |       h3f43e3d_1          34 KB  conda-forge\n",
            "    libass-0.17.4              |       h96ad9f0_0         149 KB  conda-forge\n",
            "    libblas-3.11.0             |5_h4a7cf45_openblas          18 KB  conda-forge\n",
            "    libbrotlicommon-1.2.0      |       hb03c661_1          78 KB  conda-forge\n",
            "    libbrotlidec-1.2.0         |       hb03c661_1          34 KB  conda-forge\n",
            "    libbrotlienc-1.2.0         |       hb03c661_1         291 KB  conda-forge\n",
            "    libcap-2.77                |       h3ff7636_0         119 KB  conda-forge\n",
            "    libcblas-3.11.0            |5_h0358290_openblas          18 KB  conda-forge\n",
            "    libcups-2.3.3              |       hb8b1518_5         4.3 MB  conda-forge\n",
            "    libdeflate-1.25            |       h17f619e_0          72 KB  conda-forge\n",
            "    libdrm-2.4.125             |       hb03c661_1         304 KB  conda-forge\n",
            "    libedit-3.1.20250104       | pl5321h7949ede_0         132 KB  conda-forge\n",
            "    libegl-1.7.0               |       ha4b6fd6_2          44 KB  conda-forge\n",
            "    libegl-devel-1.7.0         |       ha4b6fd6_2          30 KB  conda-forge\n",
            "    libflac-1.4.3              |       h59595ed_0         385 KB  conda-forge\n",
            "    libfreetype-2.14.1         |       ha770c72_0           7 KB  conda-forge\n",
            "    libfreetype6-2.14.1        |       h73754d4_0         378 KB  conda-forge\n",
            "    libgd-2.3.3                |      h5fbf134_12         173 KB  conda-forge\n",
            "    libgettextpo-0.25.1        |       h3f43e3d_1         184 KB  conda-forge\n",
            "    libgettextpo-devel-0.25.1  |       h3f43e3d_1          37 KB  conda-forge\n",
            "    libgfortran-15.2.0         |      h69a702a_17          27 KB  conda-forge\n",
            "    libgfortran5-15.2.0        |      h68bc16d_17         2.4 MB  conda-forge\n",
            "    libgl-1.7.0                |       ha4b6fd6_2         132 KB  conda-forge\n",
            "    libgl-devel-1.7.0          |       ha4b6fd6_2         111 KB  conda-forge\n",
            "    libglib-2.86.3             |       h6548e54_0         3.8 MB  conda-forge\n",
            "    libglvnd-1.7.0             |       ha4b6fd6_2         129 KB  conda-forge\n",
            "    libglx-1.7.0               |       ha4b6fd6_2          74 KB  conda-forge\n",
            "    libglx-devel-1.7.0         |       ha4b6fd6_2          26 KB  conda-forge\n",
            "    libhwloc-2.12.2            |default_hafda6a7_1000         2.3 MB  conda-forge\n",
            "    libhwy-1.3.0               |       h4c17acf_1         1.4 MB  conda-forge\n",
            "    libiconv-1.18              |       h3b78370_2         772 KB  conda-forge\n",
            "    libjpeg-turbo-3.1.2        |       hb03c661_0         619 KB  conda-forge\n",
            "    libjxl-0.11.1              |       ha09017c_8         1.8 MB  conda-forge\n",
            "    liblapack-3.11.0           |5_h47877c9_openblas          18 KB  conda-forge\n",
            "    liblapacke-3.11.0          |5_h6ae95b6_openblas          18 KB  conda-forge\n",
            "    liblzma-devel-5.8.2        |       hb03c661_0         454 KB  conda-forge\n",
            "    libntlm-1.8                |       hb9d3cd8_0          33 KB  conda-forge\n",
            "    libogg-1.3.5               |       hd0c01bc_1         213 KB  conda-forge\n",
            "    libopenblas-0.3.30         |pthreads_h94d23a6_4         5.7 MB  conda-forge\n",
            "    libopenvino-2025.4.1       |       hb56ce9e_1         6.2 MB  conda-forge\n",
            "    libopenvino-auto-batch-plugin-2025.4.1|       hd85de46_1         112 KB  conda-forge\n",
            "    libopenvino-auto-plugin-2025.4.1|       hd85de46_1         244 KB  conda-forge\n",
            "    libopenvino-hetero-plugin-2025.4.1|       hd41364c_1         207 KB  conda-forge\n",
            "    libopenvino-intel-cpu-plugin-2025.4.1|       hb56ce9e_1        12.4 MB  conda-forge\n",
            "    libopenvino-intel-gpu-plugin-2025.4.1|       hb56ce9e_1        10.9 MB  conda-forge\n",
            "    libopenvino-intel-npu-plugin-2025.4.1|       hb56ce9e_1         1.7 MB  conda-forge\n",
            "    libopenvino-ir-frontend-2025.4.1|       hd41364c_1         196 KB  conda-forge\n",
            "    libopenvino-onnx-frontend-2025.4.1|       h1862bb8_1         1.8 MB  conda-forge\n",
            "    libopenvino-paddle-frontend-2025.4.1|       h1862bb8_1         728 KB  conda-forge\n",
            "    libopenvino-pytorch-frontend-2025.4.1|       hecca717_1         1.2 MB  conda-forge\n",
            "    libopenvino-tensorflow-frontend-2025.4.1|       h0767aad_1         1.3 MB  conda-forge\n",
            "    libopenvino-tensorflow-lite-frontend-2025.4.1|       hecca717_1         485 KB  conda-forge\n",
            "    libopus-1.6.1              |       h280c20c_0         317 KB  conda-forge\n",
            "    libpciaccess-0.18          |       hb9d3cd8_0          28 KB  conda-forge\n",
            "    libpng-1.6.54              |       h421ea60_0         310 KB  conda-forge\n",
            "    libpq-18.1                 |       hb80d175_3         2.6 MB  conda-forge\n",
            "    libprotobuf-6.31.1         |       h49aed37_4         4.2 MB  conda-forge\n",
            "    librosa-0.11.0             |     pyhd8ed1ab_0         195 KB  conda-forge\n",
            "    librsvg-2.60.0             |       h61e6d4b_0         3.3 MB  conda-forge\n",
            "    libsndfile-1.2.2           |       hc60ed4a_1         346 KB  conda-forge\n",
            "    libstdcxx-ng-15.2.0        |      hdf11a46_17          27 KB  conda-forge\n",
            "    libsystemd0-258.3          |       h6569c3e_0         512 KB  conda-forge\n",
            "    libtiff-4.7.1              |       h9d88235_1         425 KB  conda-forge\n",
            "    libudev1-258.3             |       h6569c3e_0         163 KB  conda-forge\n",
            "    libunwind-1.8.3            |       h65a8314_0          74 KB  conda-forge\n",
            "    liburing-2.13              |       hb700be7_0         129 KB  conda-forge\n",
            "    libusb-1.0.29              |       h73b1eb8_0          87 KB  conda-forge\n",
            "    libva-2.23.0               |       he1eb515_0         216 KB  conda-forge\n",
            "    libvorbis-1.3.7            |       h54a6638_2         279 KB  conda-forge\n",
            "    libvpl-2.15.0              |       h54a6638_1         281 KB  conda-forge\n",
            "    libvpx-1.15.2              |       hecca717_0         1.0 MB  conda-forge\n",
            "    libvulkan-loader-1.4.341.0 |       h5279c79_0         195 KB  conda-forge\n",
            "    libwebp-base-1.6.0         |       hd42ef1d_0         419 KB  conda-forge\n",
            "    libxcb-1.17.0              |       h8a09558_0         387 KB  conda-forge\n",
            "    libxkbcommon-1.13.1        |       hca5e8e5_0         818 KB  conda-forge\n",
            "    libxml2-2.15.1             |       he237659_1          44 KB  conda-forge\n",
            "    libxml2-16-2.15.1          |       hca6bf5a_1         543 KB  conda-forge\n",
            "    libxslt-1.1.43             |       h711ed8c_1         240 KB  conda-forge\n",
            "    llvmlite-0.46.0            |  py310hee1c697_0        32.5 MB  conda-forge\n",
            "    lz4-c-1.10.0               |       h5888daf_1         163 KB  conda-forge\n",
            "    mad-0.15.1b                |       h9c3ff4c_1         113 KB  conda-forge\n",
            "    markdown-it-py-4.0.0       |     pyhd8ed1ab_0          63 KB  conda-forge\n",
            "    matplotlib-base-3.10.8     |  py310hfde16b3_0         6.9 MB  conda-forge\n",
            "    mdurl-0.1.2                |     pyhd8ed1ab_1          14 KB  conda-forge\n",
            "    montreal-forced-aligner-3.3.9|     pyhd8ed1ab_0        11.0 MB  conda-forge\n",
            "    mpg123-1.32.9              |       hc50e24c_0         480 KB  conda-forge\n",
            "    msgpack-python-1.1.2       |  py310h03d9f68_1          93 KB  conda-forge\n",
            "    munkres-1.1.4              |     pyhd8ed1ab_1          15 KB  conda-forge\n",
            "    ngram-1.3.17               |       hb700be7_0         2.6 MB  conda-forge\n",
            "    numba-0.63.1               |  py310h225f558_0         4.2 MB  conda-forge\n",
            "    numpy-2.2.6                |  py310hefbff90_0         7.5 MB  conda-forge\n",
            "    ocl-icd-2.3.3              |       hb9d3cd8_0         104 KB  conda-forge\n",
            "    opencl-headers-2025.06.13  |       h5888daf_0          54 KB  conda-forge\n",
            "    openfst-1.8.4              |       h84d6215_1         5.2 MB  conda-forge\n",
            "    openh264-2.6.0             |       hc22cd8d_0         714 KB  conda-forge\n",
            "    openjpeg-2.5.4             |       h55fea9a_0         347 KB  conda-forge\n",
            "    openldap-2.6.10            |       he970967_0         762 KB  conda-forge\n",
            "    pango-1.56.4               |       hadf4263_0         445 KB  conda-forge\n",
            "    pcre2-10.47                |       haa7fec5_0         1.2 MB  conda-forge\n",
            "    pgvector-0.8.1             |       ha802094_1         118 KB  conda-forge\n",
            "    pgvector-python-0.4.1      |     pyhc48fcf7_0          23 KB  conda-forge\n",
            "    pillow-12.1.0              |  py310h5a73078_0         863 KB  conda-forge\n",
            "    pixman-0.46.4              |       h54a6638_1         440 KB  conda-forge\n",
            "    platformdirs-4.5.1         |     pyhcf101f3_0          23 KB  conda-forge\n",
            "    pooch-1.9.0                |     pyhd8ed1ab_0          56 KB  conda-forge\n",
            "    postgresql-18.1            |       h234baaa_3         5.5 MB  conda-forge\n",
            "    praatio-6.2.2              |     pyhd8ed1ab_0          63 KB  conda-forge\n",
            "    psycopg2-2.9.11            |  py310haeef193_0         170 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    hb9d3cd8_1002           8 KB  conda-forge\n",
            "    pugixml-1.15               |       h3f63f65_0         116 KB  conda-forge\n",
            "    pulseaudio-client-17.0     |       h9a6aba3_3         733 KB  conda-forge\n",
            "    pycparser-2.22             |     pyh29332c3_1         108 KB  conda-forge\n",
            "    pygments-2.19.2            |     pyhd8ed1ab_0         868 KB  conda-forge\n",
            "    pynini-2.1.7               |  py310h03d9f68_2         1.5 MB  conda-forge\n",
            "    pyparsing-3.3.2            |     pyhcf101f3_0         108 KB  conda-forge\n",
            "    pysocks-1.7.1              |     pyha55dd90_7          21 KB  conda-forge\n",
            "    pysoundfile-0.13.1         |     pyhd8ed1ab_0          30 KB  conda-forge\n",
            "    python-dateutil-2.9.0.post0|     pyhe01879c_2         228 KB  conda-forge\n",
            "    python_abi-3.10            |          8_cp310           7 KB  conda-forge\n",
            "    pyyaml-6.0.3               |  py310h3406613_1         172 KB  conda-forge\n",
            "    qhull-2020.2               |       h434a139_5         540 KB  conda-forge\n",
            "    requests-2.32.5            |     pyhcf101f3_1          62 KB  conda-forge\n",
            "    rich-14.3.2                |     pyhcf101f3_0         203 KB  conda-forge\n",
            "    rich-click-1.9.7           |     pyh8f84b5b_0          63 KB  conda-forge\n",
            "    scikit-learn-1.7.2         |  py310h228f341_0         8.0 MB  conda-forge\n",
            "    scipy-1.15.2               |  py310h1d65ade_0        15.7 MB  conda-forge\n",
            "    sdl2-2.32.56               |       h54a6638_0         575 KB  conda-forge\n",
            "    sdl3-3.4.0                 |       h3b84278_0         2.0 MB  conda-forge\n",
            "    shaderc-2025.5             |       h718be3e_1         111 KB  conda-forge\n",
            "    six-1.17.0                 |     pyhe01879c_1          18 KB  conda-forge\n",
            "    snappy-1.2.2               |       h03e3b7b_1          45 KB  conda-forge\n",
            "    sox-14.4.2                 |    h59a48fd_1020         496 KB  conda-forge\n",
            "    soxr-0.1.3                 |       h0b41bf4_3         128 KB  conda-forge\n",
            "    soxr-python-1.0.0          |  py310hea6c23e_1          99 KB  conda-forge\n",
            "    spirv-tools-2026.1         |       hb700be7_0         2.2 MB  conda-forge\n",
            "    sqlalchemy-2.0.46          |  py310h139afa4_1         2.8 MB  conda-forge\n",
            "    sqlite-3.51.2              |       h04a0ce9_0         179 KB  conda-forge\n",
            "    standard-aifc-3.13.0       |  py310hff52083_3          23 KB  conda-forge\n",
            "    standard-sunau-3.13.0      |  py310hff52083_3          18 KB  conda-forge\n",
            "    svt-av1-4.0.1              |       hecca717_0         2.5 MB  conda-forge\n",
            "    tbb-2022.3.0               |       hb700be7_2         177 KB  conda-forge\n",
            "    threadpoolctl-3.6.0        |     pyhecae5ae_0          23 KB  conda-forge\n",
            "    tqdm-4.67.3                |     pyh8f84b5b_0          92 KB  conda-forge\n",
            "    typing-extensions-4.15.0   |       h396c80c_0          89 KB  conda-forge\n",
            "    typing_extensions-4.15.0   |     pyhcf101f3_0          50 KB  conda-forge\n",
            "    tzcode-2025c               |       hb03c661_0          70 KB  conda-forge\n",
            "    unicodedata2-17.0.0        |  py310h7c4b9e2_1         400 KB  conda-forge\n",
            "    urllib3-2.6.3              |     pyhd8ed1ab_0         101 KB  conda-forge\n",
            "    wayland-1.24.0             |       hd6090a7_1         322 KB  conda-forge\n",
            "    wayland-protocols-1.47     |       hd8ed1ab_0         137 KB  conda-forge\n",
            "    x264-1!164.3095            |       h166bdaf_2         877 KB  conda-forge\n",
            "    x265-3.5                   |       h924138e_3         3.2 MB  conda-forge\n",
            "    xkeyboard-config-2.46      |       hb03c661_0         388 KB  conda-forge\n",
            "    xorg-libice-1.1.2          |       hb9d3cd8_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.6           |       he73a12e_0          27 KB  conda-forge\n",
            "    xorg-libx11-1.8.12         |       h4f16b4b_0         816 KB  conda-forge\n",
            "    xorg-libxau-1.0.12         |       hb03c661_1          15 KB  conda-forge\n",
            "    xorg-libxcomposite-0.4.7   |       hb03c661_0          14 KB  conda-forge\n",
            "    xorg-libxcursor-1.2.3      |       hb9d3cd8_0          32 KB  conda-forge\n",
            "    xorg-libxdamage-1.1.6      |       hb9d3cd8_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.5        |       hb03c661_1          20 KB  conda-forge\n",
            "    xorg-libxext-1.3.7         |       hb03c661_0          49 KB  conda-forge\n",
            "    xorg-libxfixes-6.0.2       |       hb03c661_0          20 KB  conda-forge\n",
            "    xorg-libxi-1.8.2           |       hb9d3cd8_0          46 KB  conda-forge\n",
            "    xorg-libxinerama-1.1.6     |       hecca717_0          14 KB  conda-forge\n",
            "    xorg-libxrandr-1.5.5       |       hb03c661_0          30 KB  conda-forge\n",
            "    xorg-libxrender-0.9.12     |       hb9d3cd8_0          32 KB  conda-forge\n",
            "    xorg-libxscrnsaver-1.2.4   |       hb9d3cd8_0          14 KB  conda-forge\n",
            "    xorg-libxtst-1.2.5         |       hb9d3cd8_3          32 KB  conda-forge\n",
            "    xorg-libxxf86vm-1.1.7      |       hb03c661_0          18 KB  conda-forge\n",
            "    xorg-xorgproto-2025.1      |       hb03c661_0         557 KB  conda-forge\n",
            "    yaml-0.2.5                 |       h280c20c_3          83 KB  conda-forge\n",
            "    zipp-3.23.0                |     pyhcf101f3_1          24 KB  conda-forge\n",
            "    zlib-1.3.1                 |       hb9d3cd8_2          90 KB  conda-forge\n",
            "    zlib-ng-2.3.3              |       hceb46e0_1         120 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       292.2 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  adwaita-icon-theme conda-forge/noarch::adwaita-icon-theme-49.0-unix_0 \n",
            "  alsa-lib           conda-forge/linux-64::alsa-lib-1.2.15.3-hb03c661_0 \n",
            "  aom                conda-forge/linux-64::aom-3.9.1-hac33072_0 \n",
            "  at-spi2-atk        conda-forge/linux-64::at-spi2-atk-2.38.0-h0630a04_3 \n",
            "  at-spi2-core       conda-forge/linux-64::at-spi2-core-2.40.3-h0630a04_0 \n",
            "  atk-1.0            conda-forge/linux-64::atk-1.0-2.38.0-h04ea711_2 \n",
            "  attr               conda-forge/linux-64::attr-2.5.2-h39aace5_0 \n",
            "  audioread          conda-forge/linux-64::audioread-3.0.1-py310hff52083_3 \n",
            "  backports.zstd     conda-forge/linux-64::backports.zstd-1.3.0-py310h69bd2ac_0 \n",
            "  baumwelch          conda-forge/linux-64::baumwelch-0.3.11-hb700be7_0 \n",
            "  brotli             conda-forge/linux-64::brotli-1.2.0-hed03a55_1 \n",
            "  brotli-bin         conda-forge/linux-64::brotli-bin-1.2.0-hb03c661_1 \n",
            "  brotli-python      conda-forge/linux-64::brotli-python-1.2.0-py310hba01987_1 \n",
            "  cairo              conda-forge/linux-64::cairo-1.18.4-he90730b_1 \n",
            "  certifi            conda-forge/noarch::certifi-2026.1.4-pyhd8ed1ab_0 \n",
            "  cffi               conda-forge/linux-64::cffi-2.0.0-py310he7384ee_1 \n",
            "  charset-normalizer conda-forge/noarch::charset-normalizer-3.4.4-pyhd8ed1ab_0 \n",
            "  click              conda-forge/noarch::click-8.3.1-pyh8f84b5b_1 \n",
            "  contourpy          conda-forge/linux-64::contourpy-1.3.2-py310h3788b33_0 \n",
            "  cycler             conda-forge/noarch::cycler-0.12.1-pyhcf101f3_2 \n",
            "  cyrus-sasl         conda-forge/linux-64::cyrus-sasl-2.1.28-hd9c7081_0 \n",
            "  dav1d              conda-forge/linux-64::dav1d-1.2.1-hd590300_0 \n",
            "  dbus               conda-forge/linux-64::dbus-1.16.2-h24cb091_1 \n",
            "  decorator          conda-forge/noarch::decorator-5.2.1-pyhd8ed1ab_0 \n",
            "  epoxy              conda-forge/linux-64::epoxy-1.5.10-hb03c661_2 \n",
            "  ffmpeg             conda-forge/linux-64::ffmpeg-8.0.1-gpl_h43fde53_912 \n",
            "  font-ttf-dejavu-s~ conda-forge/noarch::font-ttf-dejavu-sans-mono-2.37-hab24e00_0 \n",
            "  font-ttf-inconsol~ conda-forge/noarch::font-ttf-inconsolata-3.000-h77eed37_0 \n",
            "  font-ttf-source-c~ conda-forge/noarch::font-ttf-source-code-pro-2.038-h77eed37_0 \n",
            "  font-ttf-ubuntu    conda-forge/noarch::font-ttf-ubuntu-0.83-h77eed37_3 \n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.15.0-h7e30c49_1 \n",
            "  fonts-conda-ecosy~ conda-forge/noarch::fonts-conda-ecosystem-1-0 \n",
            "  fonts-conda-forge  conda-forge/noarch::fonts-conda-forge-1-hc364b38_1 \n",
            "  fonttools          conda-forge/linux-64::fonttools-4.61.1-py310h3406613_0 \n",
            "  freetype           conda-forge/linux-64::freetype-2.14.1-ha770c72_0 \n",
            "  fribidi            conda-forge/linux-64::fribidi-1.0.16-hb03c661_0 \n",
            "  gdk-pixbuf         conda-forge/linux-64::gdk-pixbuf-2.44.5-h2b0a6b4_0 \n",
            "  gettext            conda-forge/linux-64::gettext-0.25.1-h3f43e3d_1 \n",
            "  gettext-tools      conda-forge/linux-64::gettext-tools-0.25.1-h3f43e3d_1 \n",
            "  glib-tools         conda-forge/linux-64::glib-tools-2.86.3-hf516916_0 \n",
            "  glslang            conda-forge/linux-64::glslang-16.2.0-h96af755_1 \n",
            "  gmp                conda-forge/linux-64::gmp-6.3.0-hac33072_2 \n",
            "  graphite2          conda-forge/linux-64::graphite2-1.3.14-hecca717_2 \n",
            "  graphviz           conda-forge/linux-64::graphviz-14.1.2-h8b86629_0 \n",
            "  greenlet           conda-forge/linux-64::greenlet-3.3.1-py310h25320af_1 \n",
            "  gtk3               conda-forge/linux-64::gtk3-3.24.43-h993cebd_6 \n",
            "  gts                conda-forge/linux-64::gts-0.7.6-h977cf35_4 \n",
            "  h2                 conda-forge/noarch::h2-4.3.0-pyhcf101f3_0 \n",
            "  harfbuzz           conda-forge/linux-64::harfbuzz-12.3.2-h6083320_0 \n",
            "  hdbscan            conda-forge/linux-64::hdbscan-0.8.41-py310hf779ad0_0 \n",
            "  hicolor-icon-theme conda-forge/linux-64::hicolor-icon-theme-0.17-ha770c72_2 \n",
            "  hpack              conda-forge/noarch::hpack-4.1.0-pyhd8ed1ab_0 \n",
            "  hyperframe         conda-forge/noarch::hyperframe-6.1.0-pyhd8ed1ab_0 \n",
            "  idna               conda-forge/noarch::idna-3.11-pyhd8ed1ab_0 \n",
            "  importlib-metadata conda-forge/noarch::importlib-metadata-8.7.0-pyhe01879c_1 \n",
            "  intel-gmmlib       conda-forge/linux-64::intel-gmmlib-22.9.0-hb700be7_0 \n",
            "  intel-media-driver conda-forge/linux-64::intel-media-driver-25.3.4-hecca717_0 \n",
            "  joblib             conda-forge/noarch::joblib-1.5.3-pyhd8ed1ab_0 \n",
            "  kaldi              conda-forge/linux-64::kaldi-5.5.1172-cpu_h5f874f2_3 \n",
            "  kalpy              conda-forge/linux-64::kalpy-0.9.0-py310h03d9f68_0 \n",
            "  keyutils           conda-forge/linux-64::keyutils-1.6.3-hb9d3cd8_0 \n",
            "  kiwisolver         conda-forge/linux-64::kiwisolver-1.4.9-py310haaf941d_2 \n",
            "  kneed              conda-forge/noarch::kneed-0.8.5-pyhd8ed1ab_1 \n",
            "  krb5               conda-forge/linux-64::krb5-1.21.3-h659f571_0 \n",
            "  lame               conda-forge/linux-64::lame-3.100-h166bdaf_1003 \n",
            "  lazy-loader        conda-forge/noarch::lazy-loader-0.4-pyhd8ed1ab_2 \n",
            "  lazy_loader        conda-forge/noarch::lazy_loader-0.4-pyhd8ed1ab_2 \n",
            "  lcms2              conda-forge/linux-64::lcms2-2.18-h0c24ade_0 \n",
            "  lerc               conda-forge/linux-64::lerc-4.0.0-h0aef613_1 \n",
            "  level-zero         conda-forge/linux-64::level-zero-1.28.0-hb700be7_0 \n",
            "  libabseil          conda-forge/linux-64::libabseil-20250512.1-cxx17_hba17884_0 \n",
            "  libasprintf        conda-forge/linux-64::libasprintf-0.25.1-h3f43e3d_1 \n",
            "  libasprintf-devel  conda-forge/linux-64::libasprintf-devel-0.25.1-h3f43e3d_1 \n",
            "  libass             conda-forge/linux-64::libass-0.17.4-h96ad9f0_0 \n",
            "  libblas            conda-forge/linux-64::libblas-3.11.0-5_h4a7cf45_openblas \n",
            "  libbrotlicommon    conda-forge/linux-64::libbrotlicommon-1.2.0-hb03c661_1 \n",
            "  libbrotlidec       conda-forge/linux-64::libbrotlidec-1.2.0-hb03c661_1 \n",
            "  libbrotlienc       conda-forge/linux-64::libbrotlienc-1.2.0-hb03c661_1 \n",
            "  libcap             conda-forge/linux-64::libcap-2.77-h3ff7636_0 \n",
            "  libcblas           conda-forge/linux-64::libcblas-3.11.0-5_h0358290_openblas \n",
            "  libcups            conda-forge/linux-64::libcups-2.3.3-hb8b1518_5 \n",
            "  libdeflate         conda-forge/linux-64::libdeflate-1.25-h17f619e_0 \n",
            "  libdrm             conda-forge/linux-64::libdrm-2.4.125-hb03c661_1 \n",
            "  libedit            conda-forge/linux-64::libedit-3.1.20250104-pl5321h7949ede_0 \n",
            "  libegl             conda-forge/linux-64::libegl-1.7.0-ha4b6fd6_2 \n",
            "  libegl-devel       conda-forge/linux-64::libegl-devel-1.7.0-ha4b6fd6_2 \n",
            "  libflac            conda-forge/linux-64::libflac-1.4.3-h59595ed_0 \n",
            "  libfreetype        conda-forge/linux-64::libfreetype-2.14.1-ha770c72_0 \n",
            "  libfreetype6       conda-forge/linux-64::libfreetype6-2.14.1-h73754d4_0 \n",
            "  libgd              conda-forge/linux-64::libgd-2.3.3-h5fbf134_12 \n",
            "  libgettextpo       conda-forge/linux-64::libgettextpo-0.25.1-h3f43e3d_1 \n",
            "  libgettextpo-devel conda-forge/linux-64::libgettextpo-devel-0.25.1-h3f43e3d_1 \n",
            "  libgfortran        conda-forge/linux-64::libgfortran-15.2.0-h69a702a_17 \n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-15.2.0-h68bc16d_17 \n",
            "  libgl              conda-forge/linux-64::libgl-1.7.0-ha4b6fd6_2 \n",
            "  libgl-devel        conda-forge/linux-64::libgl-devel-1.7.0-ha4b6fd6_2 \n",
            "  libglib            conda-forge/linux-64::libglib-2.86.3-h6548e54_0 \n",
            "  libglvnd           conda-forge/linux-64::libglvnd-1.7.0-ha4b6fd6_2 \n",
            "  libglx             conda-forge/linux-64::libglx-1.7.0-ha4b6fd6_2 \n",
            "  libglx-devel       conda-forge/linux-64::libglx-devel-1.7.0-ha4b6fd6_2 \n",
            "  libhwloc           conda-forge/linux-64::libhwloc-2.12.2-default_hafda6a7_1000 \n",
            "  libhwy             conda-forge/linux-64::libhwy-1.3.0-h4c17acf_1 \n",
            "  libiconv           conda-forge/linux-64::libiconv-1.18-h3b78370_2 \n",
            "  libjpeg-turbo      conda-forge/linux-64::libjpeg-turbo-3.1.2-hb03c661_0 \n",
            "  libjxl             conda-forge/linux-64::libjxl-0.11.1-ha09017c_8 \n",
            "  liblapack          conda-forge/linux-64::liblapack-3.11.0-5_h47877c9_openblas \n",
            "  liblapacke         conda-forge/linux-64::liblapacke-3.11.0-5_h6ae95b6_openblas \n",
            "  liblzma-devel      conda-forge/linux-64::liblzma-devel-5.8.2-hb03c661_0 \n",
            "  libntlm            conda-forge/linux-64::libntlm-1.8-hb9d3cd8_0 \n",
            "  libogg             conda-forge/linux-64::libogg-1.3.5-hd0c01bc_1 \n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.30-pthreads_h94d23a6_4 \n",
            "  libopenvino        conda-forge/linux-64::libopenvino-2025.4.1-hb56ce9e_1 \n",
            "  libopenvino-auto-~ conda-forge/linux-64::libopenvino-auto-batch-plugin-2025.4.1-hd85de46_1 \n",
            "  libopenvino-auto-~ conda-forge/linux-64::libopenvino-auto-plugin-2025.4.1-hd85de46_1 \n",
            "  libopenvino-heter~ conda-forge/linux-64::libopenvino-hetero-plugin-2025.4.1-hd41364c_1 \n",
            "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-cpu-plugin-2025.4.1-hb56ce9e_1 \n",
            "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-gpu-plugin-2025.4.1-hb56ce9e_1 \n",
            "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-npu-plugin-2025.4.1-hb56ce9e_1 \n",
            "  libopenvino-ir-fr~ conda-forge/linux-64::libopenvino-ir-frontend-2025.4.1-hd41364c_1 \n",
            "  libopenvino-onnx-~ conda-forge/linux-64::libopenvino-onnx-frontend-2025.4.1-h1862bb8_1 \n",
            "  libopenvino-paddl~ conda-forge/linux-64::libopenvino-paddle-frontend-2025.4.1-h1862bb8_1 \n",
            "  libopenvino-pytor~ conda-forge/linux-64::libopenvino-pytorch-frontend-2025.4.1-hecca717_1 \n",
            "  libopenvino-tenso~ conda-forge/linux-64::libopenvino-tensorflow-frontend-2025.4.1-h0767aad_1 \n",
            "  libopenvino-tenso~ conda-forge/linux-64::libopenvino-tensorflow-lite-frontend-2025.4.1-hecca717_1 \n",
            "  libopus            conda-forge/linux-64::libopus-1.6.1-h280c20c_0 \n",
            "  libpciaccess       conda-forge/linux-64::libpciaccess-0.18-hb9d3cd8_0 \n",
            "  libpng             conda-forge/linux-64::libpng-1.6.54-h421ea60_0 \n",
            "  libpq              conda-forge/linux-64::libpq-18.1-hb80d175_3 \n",
            "  libprotobuf        conda-forge/linux-64::libprotobuf-6.31.1-h49aed37_4 \n",
            "  librosa            conda-forge/noarch::librosa-0.11.0-pyhd8ed1ab_0 \n",
            "  librsvg            conda-forge/linux-64::librsvg-2.60.0-h61e6d4b_0 \n",
            "  libsndfile         conda-forge/linux-64::libsndfile-1.2.2-hc60ed4a_1 \n",
            "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-15.2.0-hdf11a46_17 \n",
            "  libsystemd0        conda-forge/linux-64::libsystemd0-258.3-h6569c3e_0 \n",
            "  libtiff            conda-forge/linux-64::libtiff-4.7.1-h9d88235_1 \n",
            "  libudev1           conda-forge/linux-64::libudev1-258.3-h6569c3e_0 \n",
            "  libunwind          conda-forge/linux-64::libunwind-1.8.3-h65a8314_0 \n",
            "  liburing           conda-forge/linux-64::liburing-2.13-hb700be7_0 \n",
            "  libusb             conda-forge/linux-64::libusb-1.0.29-h73b1eb8_0 \n",
            "  libva              conda-forge/linux-64::libva-2.23.0-he1eb515_0 \n",
            "  libvorbis          conda-forge/linux-64::libvorbis-1.3.7-h54a6638_2 \n",
            "  libvpl             conda-forge/linux-64::libvpl-2.15.0-h54a6638_1 \n",
            "  libvpx             conda-forge/linux-64::libvpx-1.15.2-hecca717_0 \n",
            "  libvulkan-loader   conda-forge/linux-64::libvulkan-loader-1.4.341.0-h5279c79_0 \n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.6.0-hd42ef1d_0 \n",
            "  libxcb             conda-forge/linux-64::libxcb-1.17.0-h8a09558_0 \n",
            "  libxkbcommon       conda-forge/linux-64::libxkbcommon-1.13.1-hca5e8e5_0 \n",
            "  libxml2            conda-forge/linux-64::libxml2-2.15.1-he237659_1 \n",
            "  libxml2-16         conda-forge/linux-64::libxml2-16-2.15.1-hca6bf5a_1 \n",
            "  libxslt            conda-forge/linux-64::libxslt-1.1.43-h711ed8c_1 \n",
            "  llvmlite           conda-forge/linux-64::llvmlite-0.46.0-py310hee1c697_0 \n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.10.0-h5888daf_1 \n",
            "  mad                conda-forge/linux-64::mad-0.15.1b-h9c3ff4c_1 \n",
            "  markdown-it-py     conda-forge/noarch::markdown-it-py-4.0.0-pyhd8ed1ab_0 \n",
            "  matplotlib-base    conda-forge/linux-64::matplotlib-base-3.10.8-py310hfde16b3_0 \n",
            "  mdurl              conda-forge/noarch::mdurl-0.1.2-pyhd8ed1ab_1 \n",
            "  montreal-forced-a~ conda-forge/noarch::montreal-forced-aligner-3.3.9-pyhd8ed1ab_0 \n",
            "  mpg123             conda-forge/linux-64::mpg123-1.32.9-hc50e24c_0 \n",
            "  msgpack-python     conda-forge/linux-64::msgpack-python-1.1.2-py310h03d9f68_1 \n",
            "  munkres            conda-forge/noarch::munkres-1.1.4-pyhd8ed1ab_1 \n",
            "  ngram              conda-forge/linux-64::ngram-1.3.17-hb700be7_0 \n",
            "  numba              conda-forge/linux-64::numba-0.63.1-py310h225f558_0 \n",
            "  numpy              conda-forge/linux-64::numpy-2.2.6-py310hefbff90_0 \n",
            "  ocl-icd            conda-forge/linux-64::ocl-icd-2.3.3-hb9d3cd8_0 \n",
            "  opencl-headers     conda-forge/linux-64::opencl-headers-2025.06.13-h5888daf_0 \n",
            "  openfst            conda-forge/linux-64::openfst-1.8.4-h84d6215_1 \n",
            "  openh264           conda-forge/linux-64::openh264-2.6.0-hc22cd8d_0 \n",
            "  openjpeg           conda-forge/linux-64::openjpeg-2.5.4-h55fea9a_0 \n",
            "  openldap           conda-forge/linux-64::openldap-2.6.10-he970967_0 \n",
            "  pango              conda-forge/linux-64::pango-1.56.4-hadf4263_0 \n",
            "  pcre2              conda-forge/linux-64::pcre2-10.47-haa7fec5_0 \n",
            "  pgvector           conda-forge/linux-64::pgvector-0.8.1-ha802094_1 \n",
            "  pgvector-python    conda-forge/noarch::pgvector-python-0.4.1-pyhc48fcf7_0 \n",
            "  pillow             conda-forge/linux-64::pillow-12.1.0-py310h5a73078_0 \n",
            "  pixman             conda-forge/linux-64::pixman-0.46.4-h54a6638_1 \n",
            "  platformdirs       conda-forge/noarch::platformdirs-4.5.1-pyhcf101f3_0 \n",
            "  pooch              conda-forge/noarch::pooch-1.9.0-pyhd8ed1ab_0 \n",
            "  postgresql         conda-forge/linux-64::postgresql-18.1-h234baaa_3 \n",
            "  praatio            conda-forge/noarch::praatio-6.2.2-pyhd8ed1ab_0 \n",
            "  psycopg2           conda-forge/linux-64::psycopg2-2.9.11-py310haeef193_0 \n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-hb9d3cd8_1002 \n",
            "  pugixml            conda-forge/linux-64::pugixml-1.15-h3f63f65_0 \n",
            "  pulseaudio-client  conda-forge/linux-64::pulseaudio-client-17.0-h9a6aba3_3 \n",
            "  pycparser          conda-forge/noarch::pycparser-2.22-pyh29332c3_1 \n",
            "  pygments           conda-forge/noarch::pygments-2.19.2-pyhd8ed1ab_0 \n",
            "  pynini             conda-forge/linux-64::pynini-2.1.7-py310h03d9f68_2 \n",
            "  pyparsing          conda-forge/noarch::pyparsing-3.3.2-pyhcf101f3_0 \n",
            "  pysocks            conda-forge/noarch::pysocks-1.7.1-pyha55dd90_7 \n",
            "  pysoundfile        conda-forge/noarch::pysoundfile-0.13.1-pyhd8ed1ab_0 \n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.9.0.post0-pyhe01879c_2 \n",
            "  python_abi         conda-forge/noarch::python_abi-3.10-8_cp310 \n",
            "  pyyaml             conda-forge/linux-64::pyyaml-6.0.3-py310h3406613_1 \n",
            "  qhull              conda-forge/linux-64::qhull-2020.2-h434a139_5 \n",
            "  requests           conda-forge/noarch::requests-2.32.5-pyhcf101f3_1 \n",
            "  rich               conda-forge/noarch::rich-14.3.2-pyhcf101f3_0 \n",
            "  rich-click         conda-forge/noarch::rich-click-1.9.7-pyh8f84b5b_0 \n",
            "  scikit-learn       conda-forge/linux-64::scikit-learn-1.7.2-py310h228f341_0 \n",
            "  scipy              conda-forge/linux-64::scipy-1.15.2-py310h1d65ade_0 \n",
            "  sdl2               conda-forge/linux-64::sdl2-2.32.56-h54a6638_0 \n",
            "  sdl3               conda-forge/linux-64::sdl3-3.4.0-h3b84278_0 \n",
            "  shaderc            conda-forge/linux-64::shaderc-2025.5-h718be3e_1 \n",
            "  six                conda-forge/noarch::six-1.17.0-pyhe01879c_1 \n",
            "  snappy             conda-forge/linux-64::snappy-1.2.2-h03e3b7b_1 \n",
            "  sox                conda-forge/linux-64::sox-14.4.2-h59a48fd_1020 \n",
            "  soxr               conda-forge/linux-64::soxr-0.1.3-h0b41bf4_3 \n",
            "  soxr-python        conda-forge/linux-64::soxr-python-1.0.0-py310hea6c23e_1 \n",
            "  spirv-tools        conda-forge/linux-64::spirv-tools-2026.1-hb700be7_0 \n",
            "  sqlalchemy         conda-forge/linux-64::sqlalchemy-2.0.46-py310h139afa4_1 \n",
            "  sqlite             conda-forge/linux-64::sqlite-3.51.2-h04a0ce9_0 \n",
            "  standard-aifc      conda-forge/linux-64::standard-aifc-3.13.0-py310hff52083_3 \n",
            "  standard-sunau     conda-forge/linux-64::standard-sunau-3.13.0-py310hff52083_3 \n",
            "  svt-av1            conda-forge/linux-64::svt-av1-4.0.1-hecca717_0 \n",
            "  tbb                conda-forge/linux-64::tbb-2022.3.0-hb700be7_2 \n",
            "  threadpoolctl      conda-forge/noarch::threadpoolctl-3.6.0-pyhecae5ae_0 \n",
            "  tqdm               conda-forge/noarch::tqdm-4.67.3-pyh8f84b5b_0 \n",
            "  typing-extensions  conda-forge/noarch::typing-extensions-4.15.0-h396c80c_0 \n",
            "  typing_extensions  conda-forge/noarch::typing_extensions-4.15.0-pyhcf101f3_0 \n",
            "  tzcode             conda-forge/linux-64::tzcode-2025c-hb03c661_0 \n",
            "  unicodedata2       conda-forge/linux-64::unicodedata2-17.0.0-py310h7c4b9e2_1 \n",
            "  urllib3            conda-forge/noarch::urllib3-2.6.3-pyhd8ed1ab_0 \n",
            "  wayland            conda-forge/linux-64::wayland-1.24.0-hd6090a7_1 \n",
            "  wayland-protocols  conda-forge/noarch::wayland-protocols-1.47-hd8ed1ab_0 \n",
            "  x264               conda-forge/linux-64::x264-1!164.3095-h166bdaf_2 \n",
            "  x265               conda-forge/linux-64::x265-3.5-h924138e_3 \n",
            "  xkeyboard-config   conda-forge/linux-64::xkeyboard-config-2.46-hb03c661_0 \n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.1.2-hb9d3cd8_0 \n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.6-he73a12e_0 \n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.8.12-h4f16b4b_0 \n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.12-hb03c661_1 \n",
            "  xorg-libxcomposite conda-forge/linux-64::xorg-libxcomposite-0.4.7-hb03c661_0 \n",
            "  xorg-libxcursor    conda-forge/linux-64::xorg-libxcursor-1.2.3-hb9d3cd8_0 \n",
            "  xorg-libxdamage    conda-forge/linux-64::xorg-libxdamage-1.1.6-hb9d3cd8_0 \n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.5-hb03c661_1 \n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.7-hb03c661_0 \n",
            "  xorg-libxfixes     conda-forge/linux-64::xorg-libxfixes-6.0.2-hb03c661_0 \n",
            "  xorg-libxi         conda-forge/linux-64::xorg-libxi-1.8.2-hb9d3cd8_0 \n",
            "  xorg-libxinerama   conda-forge/linux-64::xorg-libxinerama-1.1.6-hecca717_0 \n",
            "  xorg-libxrandr     conda-forge/linux-64::xorg-libxrandr-1.5.5-hb03c661_0 \n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.12-hb9d3cd8_0 \n",
            "  xorg-libxscrnsaver conda-forge/linux-64::xorg-libxscrnsaver-1.2.4-hb9d3cd8_0 \n",
            "  xorg-libxtst       conda-forge/linux-64::xorg-libxtst-1.2.5-hb9d3cd8_3 \n",
            "  xorg-libxxf86vm    conda-forge/linux-64::xorg-libxxf86vm-1.1.7-hb03c661_0 \n",
            "  xorg-xorgproto     conda-forge/linux-64::xorg-xorgproto-2025.1-hb03c661_0 \n",
            "  yaml               conda-forge/linux-64::yaml-0.2.5-h280c20c_3 \n",
            "  zipp               conda-forge/noarch::zipp-3.23.0-pyhcf101f3_1 \n",
            "  zlib               conda-forge/linux-64::zlib-1.3.1-hb9d3cd8_2 \n",
            "  zlib-ng            conda-forge/linux-64::zlib-ng-2.3.3-hceb46e0_1 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "llvmlite-0.46.0      | 32.5 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "kaldi-5.5.1172       | 20.6 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libopenvino-intel-cp | 12.4 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-8.0.1         | 11.9 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "montreal-forced-alig | 11.0 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-intel-gp | 10.9 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-media-driver-2 | 8.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-learn-1.7.2   | 8.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-2.2.6          | 7.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 6.9 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-2025.4.1 | 6.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.30   | 5.7 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "postgresql-18.1      | 5.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gtk3-3.24.43         | 5.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openfst-1.8.4        | 5.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcups-2.3.3        | 4.3 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numba-0.63.1         | 4.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-6.31.1   | 4.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | :   0% 0.000997983748775134/1 [00:01<17:07, 1028.60s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-8.0.1         | 11.9 MB   | :   0% 0.0013128316634740647/1 [00:01<12:59, 780.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libopenvino-intel-cp | 12.4 MB   | :   0% 0.001264509169929688/1 [00:01<13:37, 818.80s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | :  18% 0.18362900977462465/1 [00:01<00:03,  4.47s/it]   \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libopenvino-intel-cp | 12.4 MB   | :  32% 0.3224498383320704/1 [00:01<00:01,  2.56s/it]   \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-8.0.1         | 11.9 MB   | :  18% 0.18117076955942094/1 [00:01<00:03,  4.59s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | :  62% 0.6207458917381333/1 [00:01<00:00,  1.20s/it] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libopenvino-intel-cp | 12.4 MB   | :  73% 0.7258282635396409/1 [00:01<00:00,  1.08s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-8.0.1         | 11.9 MB   | :  53% 0.5330096553704703/1 [00:01<00:00,  1.43s/it] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "llvmlite-0.46.0      | 32.5 MB   | :   0% 0.0004812137206297062/1 [00:01<44:47, 2689.01s/it]\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | :  94% 0.9361087563510756/1 [00:01<00:00,  1.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-8.0.1         | 11.9 MB   | :  80% 0.8008273147191795/1 [00:01<00:00,  1.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "llvmlite-0.46.0      | 32.5 MB   | :   8% 0.08373118738956888/1 [00:01<00:11, 12.03s/it]    \n",
            "llvmlite-0.46.0      | 32.5 MB   | :  24% 0.24493778380052048/1 [00:01<00:02,  3.66s/it]\n",
            "kaldi-5.5.1172       | 20.6 MB   | :  57% 0.5653548160624425/1 [00:01<00:00,  1.53s/it] \u001b[A\n",
            "\n",
            "\n",
            "llvmlite-0.46.0      | 32.5 MB   | :  38% 0.3840085490625056/1 [00:01<00:01,  2.29s/it] \n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-8.0.1         | 11.9 MB   | : 100% 1.0/1 [00:01<00:00,  1.04it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | : 100% 1.0/1 [00:01<00:00,  1.22it/s]               \u001b[A\u001b[A\n",
            "kaldi-5.5.1172       | 20.6 MB   | :  73% 0.7313235891424358/1 [00:01<00:00,  1.21s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvmlite-0.46.0      | 32.5 MB   | :  50% 0.49853741457237566/1 [00:01<00:00,  1.78s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "montreal-forced-alig | 11.0 MB   | :   0% 0.0014170974222475472/1 [00:01<20:14, 1216.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "kaldi-5.5.1172       | 20.6 MB   | :  93% 0.9344269278887288/1 [00:01<00:00,  1.07it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-media-driver-2 | 8.0 MB    | :   0% 0.0019447784526524076/1 [00:01<15:07, 909.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-intel-gp | 10.9 MB   | :  17% 0.1721361445191359/1 [00:01<00:06,  7.42s/it]    \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvmlite-0.46.0      | 32.5 MB   | :  61% 0.6116226389203566/1 [00:01<00:00,  1.60s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-media-driver-2 | 8.0 MB    | :  24% 0.24309730658155096/1 [00:01<00:04,  5.53s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-intel-gp | 10.9 MB   | :  33% 0.3327965460703294/1 [00:01<00:02,  3.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvmlite-0.46.0      | 32.5 MB   | :  71% 0.714121161414484/1 [00:01<00:00,  1.48s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-media-driver-2 | 8.0 MB    | :  55% 0.548427523647979/1 [00:01<00:00,  2.20s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-intel-gp | 10.9 MB   | :  57% 0.570918212655134/1 [00:02<00:00,  1.88s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvmlite-0.46.0      | 32.5 MB   | :  83% 0.8262439583212056/1 [00:02<00:00,  1.29s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-media-driver-2 | 8.0 MB    | :  87% 0.8693159683356262/1 [00:02<00:00,  1.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-intel-gp | 10.9 MB   | :  73% 0.7258407427223563/1 [00:02<00:00,  1.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvmlite-0.46.0      | 32.5 MB   | :  93% 0.9272988396534438/1 [00:02<00:00,  1.38s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "montreal-forced-alig | 11.0 MB   | : 100% 1.0/1 [00:02<00:00,  1.32s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "montreal-forced-alig | 11.0 MB   | : 100% 1.0/1 [00:02<00:00,  1.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-media-driver-2 | 8.0 MB    | : 100% 1.0/1 [00:02<00:00,  1.27s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "kaldi-5.5.1172       | 20.6 MB   | : 100% 1.0/1 [00:02<00:00,  1.07it/s]               \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-learn-1.7.2   | 8.0 MB    | :   0% 0.001946968402404525/1 [00:02<20:27, 1229.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-2.2.6          | 7.5 MB    | :   0% 0.0020756941710924873/1 [00:02<19:17, 1160.35s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 6.9 MB    | :   0% 0.0022526204379933364/1 [00:02<18:04, 1087.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-intel-gp | 10.9 MB   | : 100% 1.0/1 [00:02<00:00,  1.01s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-learn-1.7.2   | 8.0 MB    | :  33% 0.3329315968111738/1 [00:02<00:03,  5.35s/it]    \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-2.2.6          | 7.5 MB    | :  23% 0.23455344133345107/1 [00:02<00:05,  7.65s/it]    \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 6.9 MB    | :  43% 0.43475574453271393/1 [00:02<00:02,  4.18s/it]    \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-2025.4.1 | 6.2 MB    | :   0% 0.0025190094192256507/1 [00:02<17:04, 1027.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-learn-1.7.2   | 8.0 MB    | :  69% 0.6911737828536064/1 [00:02<00:00,  2.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-2.2.6          | 7.5 MB    | :  51% 0.5106207660887518/1 [00:02<00:01,  3.08s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 6.9 MB    | :  93% 0.930332240891248/1 [00:02<00:00,  1.72s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-2025.4.1 | 6.2 MB    | :   8% 0.08312731083444647/1 [00:02<00:21, 23.23s/it]    \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-2.2.6          | 7.5 MB    | :  77% 0.7742339258174978/1 [00:02<00:00,  1.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-2025.4.1 | 6.2 MB    | :  43% 0.43075061068758624/1 [00:02<00:02,  3.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 6.9 MB    | : 100% 1.0/1 [00:02<00:00,  1.72s/it]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-learn-1.7.2   | 8.0 MB    | : 100% 1.0/1 [00:02<00:00,  1.68s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-learn-1.7.2   | 8.0 MB    | : 100% 1.0/1 [00:02<00:00,  1.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-2025.4.1 | 6.2 MB    | :  90% 0.8967673532443317/1 [00:02<00:00,  1.48s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.30   | 5.7 MB    | :   0% 0.0027638610991105005/1 [00:02<17:30, 1053.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "postgresql-18.1      | 5.5 MB    | :   0% 0.0028428088422737335/1 [00:02<17:26, 1049.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-2.2.6          | 7.5 MB    | : 100% 1.0/1 [00:02<00:00,  1.63s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-2.2.6          | 7.5 MB    | : 100% 1.0/1 [00:03<00:00,  1.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.30   | 5.7 MB    | :  59% 0.591466275209647/1 [00:03<00:01,  3.62s/it]      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-2025.4.1 | 6.2 MB    | : 100% 1.0/1 [00:03<00:00,  1.48s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvmlite-0.46.0      | 32.5 MB   | : 100% 1.0/1 [00:03<00:00,  1.38s/it]               \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openfst-1.8.4        | 5.2 MB    | :   0% 0.002999984802323084/1 [00:03<17:06, 1029.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gtk3-3.24.43         | 5.3 MB    | :   0% 0.0029324652396194952/1 [00:03<17:30, 1053.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcups-2.3.3        | 4.3 MB    | :   0% 0.0036218772527583545/1 [00:03<14:30, 873.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gtk3-3.24.43         | 5.3 MB    | :  47% 0.4662619730994998/1 [00:03<00:02,  4.86s/it]     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openfst-1.8.4        | 5.2 MB    | :  44% 0.43799778113917026/1 [00:03<00:02,  5.18s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.30   | 5.7 MB    | : 100% 1.0/1 [00:03<00:00,  2.10s/it]              \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.30   | 5.7 MB    | : 100% 1.0/1 [00:03<00:00,  2.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcups-2.3.3        | 4.3 MB    | :  39% 0.39478462055066066/1 [00:03<00:03,  5.88s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openfst-1.8.4        | 5.2 MB    | :  84% 0.8399957446504634/1 [00:03<00:00,  2.38s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gtk3-3.24.43         | 5.3 MB    | :  89% 0.8914694328443267/1 [00:03<00:00,  2.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "postgresql-18.1      | 5.5 MB    | : 100% 1.0/1 [00:03<00:00,  2.17s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "postgresql-18.1      | 5.5 MB    | : 100% 1.0/1 [00:03<00:00,  2.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numba-0.63.1         | 4.2 MB    | :   0% 0.00372410187637091/1 [00:03<14:52, 895.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-6.31.1   | 4.2 MB    | :   0% 0.0037469886186135503/1 [00:03<15:12, 916.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcups-2.3.3        | 4.3 MB    | : 100% 1.0/1 [00:03<00:00,  2.03s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcups-2.3.3        | 4.3 MB    | : 100% 1.0/1 [00:03<00:00,  2.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numba-0.63.1         | 4.2 MB    | :  79% 0.7895095977906329/1 [00:03<00:00,  3.09s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "openfst-1.8.4        | 5.2 MB    | : 100% 1.0/1 [00:03<00:00,  2.38s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gtk3-3.24.43         | 5.3 MB    | : 100% 1.0/1 [00:03<00:00,  2.24s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-8.0.1         | 11.9 MB   | : 100% 1.0/1 [00:03<00:00,  1.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numba-0.63.1         | 4.2 MB    | : 100% 1.0/1 [00:03<00:00,  3.09s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "libopenvino-intel-cp | 12.4 MB   | : 100% 1.0/1 [00:03<00:00,  1.08s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-6.31.1   | 4.2 MB    | : 100% 1.0/1 [00:03<00:00,  2.62s/it]                   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-6.31.1   | 4.2 MB    | : 100% 1.0/1 [00:03<00:00,  2.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "montreal-forced-alig | 11.0 MB   | : 100% 1.0/1 [00:04<00:00,  1.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "intel-media-driver-2 | 8.0 MB    | : 100% 1.0/1 [00:06<00:00,  1.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "scipy-1.15.2         | 15.7 MB   | : 100% 1.0/1 [00:08<00:00,  1.22it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-intel-gp | 10.9 MB   | : 100% 1.0/1 [00:09<00:00,  1.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "kaldi-5.5.1172       | 20.6 MB   | : 100% 1.0/1 [00:10<00:00,  1.07it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 6.9 MB    | : 100% 1.0/1 [00:10<00:00,  1.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-learn-1.7.2   | 8.0 MB    | : 100% 1.0/1 [00:11<00:00,  1.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-2.2.6          | 7.5 MB    | : 100% 1.0/1 [00:12<00:00,  1.63s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenvino-2025.4.1 | 6.2 MB    | : 100% 1.0/1 [00:12<00:00,  1.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.30   | 5.7 MB    | : 100% 1.0/1 [00:12<00:00,  2.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "postgresql-18.1      | 5.5 MB    | : 100% 1.0/1 [00:12<00:00,  2.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libcups-2.3.3        | 4.3 MB    | : 100% 1.0/1 [00:13<00:00,  2.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "llvmlite-0.46.0      | 32.5 MB   | : 100% 1.0/1 [00:14<00:00,  1.38s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gtk3-3.24.43         | 5.3 MB    | : 100% 1.0/1 [00:14<00:00,  2.24s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libprotobuf-6.31.1   | 4.2 MB    | : 100% 1.0/1 [00:14<00:00,  2.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numba-0.63.1         | 4.2 MB    | : 100% 1.0/1 [00:15<00:00,  3.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \n",
            "\b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \n",
            "\b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \n",
            "\b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && conda run -n mfa_conda mfa version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S20rgBjl6iPW",
        "outputId": "db869d12-c56e-4622-8087-11e01ea03140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.3.9\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/mfa_data/corpus"
      ],
      "metadata": {
        "id": "9SWmz3Dm6xM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zx0mEzI64iB",
        "outputId": "68ba39d2-9560-4eff-c0f0-47bc195301a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 153132\n",
            "drwxr-xr-x  1 root root      4096 Feb  6 17:06 .\n",
            "drwxr-xr-x  1 root root      4096 Feb  6 16:42 ..\n",
            "drwxr-xr-x  4 root root      4096 Jan 16 14:24 .config\n",
            "drwxr-xr-x  3 root root      4096 Feb  6 17:06 mfa_data\n",
            "drwxr-xr-x  6 root root      4096 Feb  6 16:49 mfa_env\n",
            "drwxr-xr-x 18 root root      4096 Feb  6 16:59 miniconda\n",
            "-rw-r--r--  1 root root 156772981 Dec 16 21:40 miniconda.sh\n",
            "drwxr-xr-x  1 root root      4096 Jan 16 14:24 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cpnFcqd8vPc",
        "outputId": "2c58a841-7a4b-4bcf-9137-39d5a7361e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/MFA_Assignment_LTRC/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dirPJ8PU8-mq",
        "outputId": "8d8683e1-84ae-4a8c-ca75-f79b8b122678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transcripts  wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"WAV files:\"\n",
        "!ls /content/drive/MyDrive/MFA_Assignment_LTRC/wav/ | head -5\n",
        "!echo \"Total wav files:\"\n",
        "!ls /content/drive/MyDrive/MFA_Assignment_LTRC/wav/ | wc -l\n",
        "\n",
        "!echo \"\"\n",
        "!echo \"Transcript files:\"\n",
        "!ls /content/drive/MyDrive/MFA_Assignment_LTRC/transcripts/ | head -5\n",
        "!echo \"Total transcript files:\"\n",
        "!ls /content/drive/MyDrive/MFA_Assignment_LTRC/transcripts/ | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJv7jCzU9JlJ",
        "outputId": "83657b00-1148-4b2f-ae88-74c1b23ca0ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WAV files:\n",
            "F2BJRLP1.wav\n",
            "F2BJRLP2.wav\n",
            "F2BJRLP3.wav\n",
            "ISLE_SESS0131_BLOCKD02_01_sprt1.wav\n",
            "ISLE_SESS0131_BLOCKD02_02_sprt1.wav\n",
            "Total wav files:\n",
            "6\n",
            "\n",
            "Transcript files:\n",
            "F2BJRLP1.TXT\n",
            "F2BJRLP2.TXT\n",
            "F2BJRLP3.TXT\n",
            "ISLE_SESS0131_BLOCKD02_01_sprt1.txt\n",
            "ISLE_SESS0131_BLOCKD02_02_sprt1.txt\n",
            "Total transcript files:\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && \\\n",
        "cp /content/drive/MyDrive/MFA_Assignment_LTRC/wav/*.wav /content/mfa_data/corpus/ && \\\n",
        "cp /content/drive/MyDrive/MFA_Assignment_LTRC/transcripts/*.txt /content/mfa_data/corpus/ && \\\n",
        "cp /content/drive/MyDrive/MFA_Assignment_LTRC/transcripts/*.TXT /content/mfa_data/corpus/"
      ],
      "metadata": {
        "id": "vVS8CShY9Sh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/mfa_data/corpus && \\\n",
        "for file in *.TXT; do \\\n",
        "  if [ -f \"$file\" ]; then \\\n",
        "    mv \"$file\" \"${file%.TXT}.txt\"; \\\n",
        "  fi; \\\n",
        "done && \\\n",
        "echo \"Files renamed successfully\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3_nyKaY9bBw",
        "outputId": "1544b6d8-dfe4-43fb-b12c-f3a9dc77de2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files renamed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"Files in corpus:\"\n",
        "!ls -1 /content/mfa_data/corpus/ | sort\n",
        "!echo \"\"\n",
        "!echo \"WAV files: $(ls /content/mfa_data/corpus/*.wav 2>/dev/null | wc -l)\"\n",
        "!echo \"TXT files: $(ls /content/mfa_data/corpus/*.txt 2>/dev/null | wc -l)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-PAh8gv9i9I",
        "outputId": "6f86fd83-7b70-4de6-948b-42d4ba832013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in corpus:\n",
            "F2BJRLP1.txt\n",
            "F2BJRLP1.wav\n",
            "F2BJRLP2.txt\n",
            "F2BJRLP2.wav\n",
            "F2BJRLP3.txt\n",
            "F2BJRLP3.wav\n",
            "ISLE_SESS0131_BLOCKD02_01_sprt1.txt\n",
            "ISLE_SESS0131_BLOCKD02_01_sprt1.wav\n",
            "ISLE_SESS0131_BLOCKD02_02_sprt1.txt\n",
            "ISLE_SESS0131_BLOCKD02_02_sprt1.wav\n",
            "ISLE_SESS0131_BLOCKD02_03_sprt1.txt\n",
            "ISLE_SESS0131_BLOCKD02_03_sprt1.wav\n",
            "\n",
            "WAV files: 6\n",
            "TXT files: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -3 /content/mfa_data/corpus/F2BJRLP1.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJLwgBl59o6o",
        "outputId": "92be5591-4629-4e21-92df-64f5c6de764a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wanted:  Chief Justice of the Massachusetts Supreme Court.  In April,\n",
            "\n",
            "the S.J.C.'s current leader Edward Hennessy reaches the mandatory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && \\\n",
        "conda run -n mfa_conda mfa model download dictionary english_us_arpa"
      ],
      "metadata": {
        "id": "BtyVCDdY91f3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && \\\n",
        "conda run -n mfa_conda mfa model list dictionary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teYyImU7-BMV",
        "outputId": "c12e4c58-b262-4123-d695-89464642fcb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['english_us_arpa']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && \\\n",
        "conda run -n mfa_conda mfa model download acoustic english_us_arpa"
      ],
      "metadata": {
        "id": "JlqOMdSS-JDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && \\\n",
        "conda run -n mfa_conda mfa model list acoustic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUPAGlvV-SDw",
        "outputId": "6b16e00f-49b2-4cc9-e68e-5de578661c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['english_us_arpa']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && \\\n",
        "conda run -n mfa_conda mfa validate /content/mfa_data/corpus english_us_arpa english_us_arpa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHItwAOm-a3h",
        "outputId": "d3502398-6ce4-4703-f7f6-0b381fe59d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   6% ━━                                   6/100  [ 0:00:01 < -:--:-- , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:20 < 0:00:00 , 4 it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:05 < 0:00:00 , ? it/s ]\n",
            "  83% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸       5/6  [ 0:00:01 < -:--:-- , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:04 < 0:00:00 , ? it/s ]\n",
            "  83% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸       5/6  [ 0:00:01 < -:--:-- , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:03 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:03 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:02 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:02 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:02 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            "\n",
            " INFO     Setting up corpus information...                                      \n",
            " INFO     Loading corpus from source files...                                   \n",
            " INFO     Found 1 speaker across 6 files, average number of utterances per      \n",
            "          speaker: 6.0                                                          \n",
            " INFO     Initializing multiprocessing jobs...                                  \n",
            " WARNING  Number of jobs was specified as 3, but due to only having 1 speakers, \n",
            "          MFA will only use 1 jobs. Use the --single_speaker flag if you would  \n",
            "          like to split utterances across jobs regardless of their speaker.     \n",
            " INFO     Normalizing text...                                                   \n",
            " INFO     Generating MFCCs...                                                   \n",
            " INFO     Calculating CMVN...                                                   \n",
            " INFO     Generating final features...                                          \n",
            " INFO     Creating corpus split...                                              \n",
            " INFO     Creating corpus split...                                              \n",
            " INFO     Corpus                                                                \n",
            " INFO     6 sound files                                                         \n",
            " INFO     6 text files                                                          \n",
            " INFO     1 speakers                                                            \n",
            " INFO     6 utterances                                                          \n",
            " INFO     97.163 seconds total duration                                         \n",
            " INFO     Sound file read errors                                                \n",
            " INFO     There were no issues reading sound files.                             \n",
            " INFO     Feature generation                                                    \n",
            " INFO     There were no utterances missing features.                            \n",
            " INFO     Files without transcriptions                                          \n",
            " INFO     There were no sound files missing transcriptions.                     \n",
            " INFO     Transcriptions without sound files                                    \n",
            " INFO     There were no transcription files missing sound files.                \n",
            " INFO     Dictionary                                                            \n",
            " INFO     Out of vocabulary words                                               \n",
            " WARNING  29 OOV word types                                                     \n",
            " WARNING  61total OOV tokens                                                    \n",
            " WARNING  For a full list of the word types, please see:                        \n",
            "          /root/Documents/MFA/corpus/oovs_found.txt. For a by-utterance         \n",
            "          breakdown of missing words, see:                                      \n",
            "          /root/Documents/MFA/corpus/utterance_oovs.txt                         \n",
            " INFO     Training                                                              \n",
            " INFO     Initializing training for monophone...                                \n",
            " INFO     Compiling training graphs...                                          \n",
            " INFO     Generating initial alignments...                                      \n",
            " INFO     Initialization complete!                                              \n",
            " INFO     monophone - Iteration 1 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 2 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 3 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 4 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 5 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 6 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 7 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 8 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 9 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 10 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 11 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 12 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 13 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 14 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 15 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 16 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 17 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 18 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 19 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 20 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 21 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 22 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 23 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 24 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 25 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 26 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 27 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 28 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 29 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 30 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 31 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 32 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 33 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 34 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 35 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 36 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 37 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 38 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 39 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 40 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     Training complete!                                                    \n",
            " INFO     Compiling training graphs...                                          \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating transition stats...                                      \n",
            " INFO     Finished accumulating transition stats!                               \n",
            " INFO     Collecting phone and word alignments from monophone_ali lattices...   \n",
            " INFO     Analyzing alignment quality...                                        \n",
            " INFO     Beginning phone LM training...                                        \n",
            " INFO     Collecting training data...                                           \n",
            " INFO     Training model...                                                     \n",
            " INFO     Completed training in 98.97474646568298 seconds!                      \n",
            " INFO     Done! Everything took 195.104 seconds                                 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/mfa_data/corpus/oovs_found_english_us_arpa.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRhK-MJu_zzX",
        "outputId": "ea413989-afd0-4766-bc6d-b24f8d93a74b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: /content/mfa_data/corpus/oovs_found_english_us_arpa.txt: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/mfa_data -name \"*oov*\" -type f"
      ],
      "metadata": {
        "id": "7wFmQJsz_7yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la ~/.local/share/mfa/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnmz9LIeADwV",
        "outputId": "4faf6d25-a6af-48c2-8090-998d7d90fcb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/root/.local/share/mfa/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content -type d -name \"mfa\" 2>/dev/null\n",
        "!find /tmp -type d -name \"mfa\" 2>/dev/null"
      ],
      "metadata": {
        "id": "XJN4X6x_AJep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && \\\n",
        "conda run -n mfa_conda mfa validate /content/mfa_data/corpus english_us_arpa english_us_arpa --clean 2>&1 | grep -A 100 \"Out of vocabulary\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIf_JaB5AVCr",
        "outputId": "717de4d3-5ab9-46ee-c465-9cb3b32a9b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " INFO     Out of vocabulary words                                               \n",
            " WARNING  29 OOV word types                                                     \n",
            " WARNING  61total OOV tokens                                                    \n",
            " WARNING  For a full list of the word types, please see:                        \n",
            "          /root/Documents/MFA/corpus/oovs_found.txt. For a by-utterance         \n",
            "          breakdown of missing words, see:                                      \n",
            "          /root/Documents/MFA/corpus/utterance_oovs.txt                         \n",
            " INFO     Training                                                              \n",
            " INFO     Initializing training for monophone...                                \n",
            " INFO     Compiling training graphs...                                          \n",
            " INFO     Generating initial alignments...                                      \n",
            " INFO     Initialization complete!                                              \n",
            " INFO     monophone - Iteration 1 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 2 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 3 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 4 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 5 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 6 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 7 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 8 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 9 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 10 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 11 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 12 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 13 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 14 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 15 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 16 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 17 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 18 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 19 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 20 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 21 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 22 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 23 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 24 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 25 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 26 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 27 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 28 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 29 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 30 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 31 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 32 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 33 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 34 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 35 of 40                                        \n",
            " INFO     Generating alignments...                                              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /root/Documents/MFA/corpus/oovs_found.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ngd06AYBO9P",
        "outputId": "22c59ab6-1daa-442a-a67b-1857f3219ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: /root/Documents/MFA/corpus/oovs_found.txt: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /root -name \"oovs_found.txt\" 2>/dev/null\n",
        "!find /tmp -name \"oovs_found.txt\" 2>/dev/null"
      ],
      "metadata": {
        "id": "bWoB2RQVBUtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /root/Documents/MFA/corpus\n",
        "!export PATH=\"/content/miniconda/bin:$PATH\" && \\\n",
        "conda run -n mfa_conda mfa validate /content/mfa_data/corpus english_us_arpa english_us_arpa --output_directory /root/Documents/MFA/corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mbvaf99JBcWs",
        "outputId": "5def1e6d-7272-4007-99e1-322818348dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   6% ━━                                   6/100  [ 0:00:01 < -:--:-- , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:02 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:05 < 0:00:00 , ? it/s ]\n",
            "  83% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸       5/6  [ 0:00:01 < -:--:-- , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:04 < 0:00:00 , ? it/s ]\n",
            "  83% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸       5/6  [ 0:00:01 < -:--:-- , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:03 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:03 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:02 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:02 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:02 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:02 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            "\n",
            " INFO     Setting up corpus information...                                      \n",
            " INFO     Loading corpus from source files...                                   \n",
            " INFO     Found 1 speaker across 6 files, average number of utterances per      \n",
            "          speaker: 6.0                                                          \n",
            " INFO     Initializing multiprocessing jobs...                                  \n",
            " WARNING  Number of jobs was specified as 3, but due to only having 1 speakers, \n",
            "          MFA will only use 1 jobs. Use the --single_speaker flag if you would  \n",
            "          like to split utterances across jobs regardless of their speaker.     \n",
            " INFO     Normalizing text...                                                   \n",
            " INFO     Generating MFCCs...                                                   \n",
            " INFO     Calculating CMVN...                                                   \n",
            " INFO     Generating final features...                                          \n",
            " INFO     Creating corpus split...                                              \n",
            " INFO     Creating corpus split...                                              \n",
            " INFO     Corpus                                                                \n",
            " INFO     6 sound files                                                         \n",
            " INFO     6 text files                                                          \n",
            " INFO     1 speakers                                                            \n",
            " INFO     6 utterances                                                          \n",
            " INFO     97.163 seconds total duration                                         \n",
            " INFO     Sound file read errors                                                \n",
            " INFO     There were no issues reading sound files.                             \n",
            " INFO     Feature generation                                                    \n",
            " INFO     There were no utterances missing features.                            \n",
            " INFO     Files without transcriptions                                          \n",
            " INFO     There were no sound files missing transcriptions.                     \n",
            " INFO     Transcriptions without sound files                                    \n",
            " INFO     There were no transcription files missing sound files.                \n",
            " INFO     Dictionary                                                            \n",
            " INFO     Out of vocabulary words                                               \n",
            " WARNING  29 OOV word types                                                     \n",
            " WARNING  61total OOV tokens                                                    \n",
            " WARNING  For a full list of the word types, please see:                        \n",
            "          /root/Documents/MFA/corpus/oovs_found.txt. For a by-utterance         \n",
            "          breakdown of missing words, see:                                      \n",
            "          /root/Documents/MFA/corpus/utterance_oovs.txt                         \n",
            " INFO     Training                                                              \n",
            " INFO     Initializing training for monophone...                                \n",
            " INFO     Compiling training graphs...                                          \n",
            " INFO     Generating initial alignments...                                      \n",
            " INFO     Initialization complete!                                              \n",
            " INFO     monophone - Iteration 1 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 2 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 3 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 4 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 5 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 6 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 7 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 8 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 9 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 10 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 11 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 12 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 13 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 14 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 15 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 16 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 17 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 18 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 19 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 20 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 21 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 22 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 23 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 24 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 25 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 26 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 27 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 28 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 29 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 30 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 31 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 32 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 33 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 34 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 35 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 36 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 37 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 38 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 39 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 40 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     Training complete!                                                    \n",
            " INFO     Compiling training graphs...                                          \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating transition stats...                                      \n",
            " INFO     Finished accumulating transition stats!                               \n",
            " INFO     Collecting phone and word alignments from monophone_ali lattices...   \n",
            " INFO     Analyzing alignment quality...                                        \n",
            " INFO     Beginning phone LM training...                                        \n",
            " INFO     Collecting training data...                                           \n",
            " INFO     Training model...                                                     \n",
            " INFO     Completed training in 101.04846024513245 seconds!                     \n",
            " INFO     Done! Everything took 173.542 seconds                                 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /root/Documents/MFA/corpus/oovs_found.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6DzPcRzCasy",
        "outputId": "dddd6872-b279-4045-f469-3674677c107e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat: /root/Documents/MFA/corpus/oovs_found.txt: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la /root/Documents/MFA/corpus/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X38qAoxLCjjX",
        "outputId": "1437a7cb-c9b0-4a1d-c847-45c0f5d53844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/root/Documents/MFA/corpus/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /root -type f -name \"*.txt\" 2>/dev/null | head -20\n",
        "!find /tmp -type d -name \"MFA\" 2>/dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFeIYwoOCr5-",
        "outputId": "766c71ca-a0eb-44b5-df16-2c38f7e50e4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.config/Google/DriveFS/Logs/drive_fs_1.txt\n",
            "/root/.config/Google/DriveFS/Logs/timeouts.txt\n",
            "/root/.config/Google/DriveFS/Logs/parent_1.txt\n",
            "/root/.config/Google/DriveFS/Logs/dpb.txt\n",
            "/root/.config/Google/DriveFS/Logs/parent.txt\n",
            "/root/.config/Google/DriveFS/Logs/drive_fs.txt\n",
            "/root/.config/Google/DriveFS/pid.txt\n",
            "/root/.conda/environments.txt\n",
            "/root/.julia/packages/AdaptivePredicates/rvPuS/test/original/macro_defs.txt\n",
            "/root/.julia/packages/MacroTools/Ar0jT/animals.txt\n",
            "/root/.julia/packages/StringManipulation/SXVLT/LICENSE.txt\n",
            "/root/.julia/packages/ColorBrewer/Ic9lh/data/colorbrewerLicense.txt\n",
            "/root/.julia/packages/FreeType/ATaWH/LICENSE.txt\n",
            "/root/.julia/packages/ProgressMeter/N660J/LICENSE.txt\n",
            "/root/.julia/packages/StaticArrays/IZgIP/perf/bench10.txt\n",
            "/root/.julia/packages/StaticArrays/IZgIP/perf/bench6.txt\n",
            "/root/.julia/packages/StaticArrays/IZgIP/perf/bench5.txt\n",
            "/root/.julia/packages/StaticArrays/IZgIP/perf/bench9.txt\n",
            "/root/.julia/packages/StaticArrays/IZgIP/perf/bench4.txt\n",
            "/root/.julia/packages/StaticArrays/IZgIP/perf/bench3.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && \\\n",
        "conda run -n mfa_conda mfa align /content/mfa_data/corpus english_us_arpa english_us_arpa /content/mfa_data/output_before_oov"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChiHDgLPC1xX",
        "outputId": "6261f20f-12fc-499c-c8bc-27855db654f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   6% ━━                                   6/100  [ 0:00:01 < -:--:-- , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:03 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:02 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:05 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:00 < 0:00:00 , ? it/s ]\n",
            "\n",
            " INFO     Setting up corpus information...                                      \n",
            " INFO     Loading corpus from source files...                                   \n",
            " INFO     Found 1 speaker across 6 files, average number of utterances per      \n",
            "          speaker: 6.0                                                          \n",
            " INFO     Initializing multiprocessing jobs...                                  \n",
            " WARNING  Number of jobs was specified as 3, but due to only having 1 speakers, \n",
            "          MFA will only use 1 jobs. Use the --single_speaker flag if you would  \n",
            "          like to split utterances across jobs regardless of their speaker.     \n",
            " INFO     Normalizing text...                                                   \n",
            " INFO     Generating MFCCs...                                                   \n",
            " INFO     Calculating CMVN...                                                   \n",
            " INFO     Generating final features...                                          \n",
            " INFO     Creating corpus split...                                              \n",
            " INFO     Compiling training graphs...                                          \n",
            " INFO     Performing first-pass alignment...                                    \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Collecting phone and word alignments from alignment lattices...       \n",
            " INFO     Analyzing alignment quality...                                        \n",
            " INFO     Exporting alignment TextGrids to                                      \n",
            "          /content/mfa_data/output_before_oov...                                \n",
            " INFO     Finished exporting TextGrids to /content/mfa_data/output_before_oov!  \n",
            " INFO     Done! Everything took 113.670 seconds                                 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/mfa_data/output_before_oov/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSgCdse-De78",
        "outputId": "a02afc39-111b-4021-c5cb-34c78fa2cd82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 148K\n",
            "-rw-r--r-- 1 root root  788 Feb  6 17:43 alignment_analysis.csv\n",
            "-rw-r--r-- 1 root root  39K Feb  6 17:43 F2BJRLP1.TextGrid\n",
            "-rw-r--r-- 1 root root  41K Feb  6 17:43 F2BJRLP2.TextGrid\n",
            "-rw-r--r-- 1 root root  47K Feb  6 17:43 F2BJRLP3.TextGrid\n",
            "-rw-r--r-- 1 root root 2.7K Feb  6 17:43 ISLE_SESS0131_BLOCKD02_01_sprt1.TextGrid\n",
            "-rw-r--r-- 1 root root 2.6K Feb  6 17:43 ISLE_SESS0131_BLOCKD02_02_sprt1.TextGrid\n",
            "-rw-r--r-- 1 root root 2.5K Feb  6 17:43 ISLE_SESS0131_BLOCKD02_03_sprt1.TextGrid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -50 /content/mfa_data/output_before_oov/F2BJRLP1.TextGrid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf0E_6G-DrM6",
        "outputId": "a7946289-06cf-41bf-de7f-b250780da396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File type = \"ooTextFile\"\n",
            "Object class = \"TextGrid\"\n",
            "\n",
            "xmin = 0 \n",
            "xmax = 25.309125 \n",
            "tiers? <exists> \n",
            "size = 2 \n",
            "item []: \n",
            "    item [1]:\n",
            "        class = \"IntervalTier\" \n",
            "        name = \"words\" \n",
            "        xmin = 0 \n",
            "        xmax = 25.309125 \n",
            "        intervals: size = 83 \n",
            "        intervals [1]:\n",
            "            xmin = 0.0 \n",
            "            xmax = 0.54 \n",
            "            text = \"\" \n",
            "        intervals [2]:\n",
            "            xmin = 0.54 \n",
            "            xmax = 1.12 \n",
            "            text = \"wanted\" \n",
            "        intervals [3]:\n",
            "            xmin = 1.12 \n",
            "            xmax = 1.28 \n",
            "            text = \"\" \n",
            "        intervals [4]:\n",
            "            xmin = 1.28 \n",
            "            xmax = 1.58 \n",
            "            text = \"chief\" \n",
            "        intervals [5]:\n",
            "            xmin = 1.58 \n",
            "            xmax = 2.09 \n",
            "            text = \"justice\" \n",
            "        intervals [6]:\n",
            "            xmin = 2.09 \n",
            "            xmax = 2.23 \n",
            "            text = \"of\" \n",
            "        intervals [7]:\n",
            "            xmin = 2.23 \n",
            "            xmax = 2.31 \n",
            "            text = \"the\" \n",
            "        intervals [8]:\n",
            "            xmin = 2.31 \n",
            "            xmax = 3.05 \n",
            "            text = \"massachusetts\" \n",
            "        intervals [9]:\n",
            "            xmin = 3.05 \n",
            "            xmax = 3.47 \n",
            "            text = \"supreme\" \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/mfa_data/output_before_oov/alignment_analysis.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUn_533kDz3V",
        "outputId": "3eedd0c5-8bfb-4538-956c-154b73a229b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file,begin,end,speaker,overall_log_likelihood,speech_log_likelihood,phone_duration_deviation,snr\r\n",
            "F2BJRLP3,0.0,30.7068125,corpus,-46.5452417779225,-46.86912183983382,4.435994028842631,10.391514516372963\r\n",
            "ISLE_SESS0131_BLOCKD02_03_sprt1,0.0,4.5,corpus,-43.7720703125,-53.594077770526596,3.8679425530287452,11.443148868500742\r\n",
            "F2BJRLP1,0.0,25.309125,corpus,-45.817059092256024,-45.885584089491104,3.7727068024287895,8.1713368361116\r\n",
            "F2BJRLP2,0.0,28.6474375,corpus,-45.74211660122164,-45.74934758736179,3.561935412226064,7.983564690353116\r\n",
            "ISLE_SESS0131_BLOCKD02_01_sprt1,0.0,4.125,corpus,-43.13321447487893,-52.31244160578801,2.7052057720024796,11.85118774544399\r\n",
            "ISLE_SESS0131_BLOCKD02_02_sprt1,0.0,3.875,corpus,-44.82033263530928,-50.90904235839844,2.5495603553087056,12.358243745435463\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/mfa_data -name \"*.log\" -o -name \"*oov*\" 2>/dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaEhWxWyD8LE",
        "outputId": "01e84ea9-c57d-49e1-8063-e33592eca2cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mfa_data/output_before_oov\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/mfa_data/corpus/*.txt | tr ' ' '\\n' | tr -d '.,!?;:' | tr '[:upper:]' '[:lower:]' | sort -u > /content/all_words.txt\n",
        "!head -20 /content/all_words.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KecGSBlLEIAy",
        "outputId": "1dae30c0-53f7-40d0-ade1-4fa1e810d87d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1971\n",
            "300\n",
            "35\n",
            "800\n",
            "a\n",
            "abilities\n",
            "act\n",
            "administration\n",
            "administrative\n",
            "admirers\n",
            "age\n",
            "ago\n",
            "along\n",
            "an\n",
            "and\n",
            "another\n",
            "appointment\n",
            "appointments\n",
            "approval\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && \\\n",
        "conda run -n mfa_conda mfa model download g2p english_us_arpa"
      ],
      "metadata": {
        "id": "nZSU05DHEQZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && \\\n",
        "conda run -n mfa_conda mfa g2p english_us_arpa /content/all_words.txt /content/generated_pronunciations.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOBFs0i7Egsj",
        "outputId": "41d0af91-ca29-463f-ffd5-8c64be91cebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                \n",
            " Usage: mfa g2p [OPTIONS] INPUT_PATH G2P_MODEL_PATH OUTPUT_PATH                 \n",
            "                                                                                \n",
            "╭─ Error ──────────────────────────────────────────────────────────────────────╮\n",
            "│ Invalid value for 'INPUT_PATH': Path 'english_us_arpa' does not exist.       │\n",
            "╰──────────────────────────────────────────────────────────────────────────────╯\n",
            "                                                                                \n",
            "\n",
            "ERROR conda.cli.main_run:execute(127): `conda run mfa g2p english_us_arpa /content/all_words.txt /content/generated_pronunciations.txt` failed. (See above for error)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && \\\n",
        "conda run -n mfa_conda mfa g2p /content/all_words.txt english_us_arpa /content/generated_pronunciations.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j8sz20ZEpLY",
        "outputId": "fa92bd8b-ab8d-4292-c3ab-88cef3a2ba1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 141/141  [ 0:01:51 < 0:00:00 , 1 it/s ]\n",
            "\n",
            " INFO     Generating pronunciations...                                          \n",
            " INFO     Done! Everything took 114.551 seconds                                 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/generated_pronunciations.txt | head -40"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHgxRVMgFT11",
        "outputId": "006ccb2e-2c66-48f8-819d-2ebcb37655ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\tAA1\n",
            "a\tAH0\n",
            "act\tAE1 K T\n",
            "abilities\tAH0 B IH1 L AH0 T IY0 Z\n",
            "abilities\tAH0 B IH1 L IH0 T IY0 Z\n",
            "admirers\tAE0 D M AY1 R ER0 Z\n",
            "age\tAH0 JH\n",
            "age\tEY1 JH\n",
            "ago\tAH0 G OW1\n",
            "ago\tAH0 G OW2\n",
            "ago\tEY1 G OW0\n",
            "along\tAH0 L AO1 NG\n",
            "an\tAA0 N\n",
            "an\tAA1 N\n",
            "an\tAE0 N\n",
            "an\tAE1 N\n",
            "an\tAE2 N\n",
            "an\tAH0 N\n",
            "and\tAE0 N D\n",
            "and\tAE1 N D\n",
            "and\tAE2 N D\n",
            "and\tAH0 N D\n",
            "administrative\tAE0 D M IH2 N IH0 S T R EY2 T IH0 V\n",
            "administrative\tAH0 D M IH1 N AH0 S T R EY2 T IH0 V\n",
            "administration\tAE0 D M IH2 N IH0 S T R EY1 SH AH0 N\n",
            "another\tAH0 N AH1 DH ER0\n",
            "approval\tAH0 P R UW1 V AH0 L\n",
            "appointment\tAH0 P OY1 N T M AH0 N T\n",
            "as\tAE1 Z\n",
            "as\tAH0 S\n",
            "as\tAH0 Z\n",
            "april\tEY1 P R AH0 L\n",
            "appointments\tAH0 P OY1 N T M AH0 N T S\n",
            "author\tAO1 TH ER0\n",
            "bad\tB AE0 D\n",
            "bad\tB AE1 D\n",
            "bad\tB AH0 D\n",
            "bait\tB EY1 T\n",
            "associate\tAH0 S OW1 S IY0 AH0 T\n",
            "associate\tAH0 S OW1 S IY0 EY2 T\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && \\\n",
        "conda run -n mfa_conda mfa validate /content/mfa_data/corpus english_us_arpa english_us_arpa 2>&1 | grep -i \"oov\" -A 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT5E--ejFdov",
        "outputId": "2abb607e-7278-4172-d60d-6955d30ced70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " WARNING  29 OOV word types                                                     \n",
            " WARNING  61total OOV tokens                                                    \n",
            " WARNING  For a full list of the word types, please see:                        \n",
            "          /root/Documents/MFA/corpus/oovs_found.txt. For a by-utterance         \n",
            "          breakdown of missing words, see:                                      \n",
            "          /root/Documents/MFA/corpus/utterance_oovs.txt                         \n",
            " INFO     Training                                                              \n",
            " INFO     Initializing training for monophone...                                \n",
            " INFO     Compiling training graphs...                                          \n",
            " INFO     Generating initial alignments...                                      \n",
            " INFO     Initialization complete!                                              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /root/Documents/MFA/corpus\n",
        "!export PATH=\"/content/miniconda/bin:$PATH\" && \\\n",
        "conda run -n mfa_conda mfa validate /content/mfa_data/corpus english_us_arpa english_us_arpa --clean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZLEpNY7GufH",
        "outputId": "bd8548e8-3290-41ac-8140-7d32f68149c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   6% ━━                                   6/100  [ 0:00:01 < -:--:-- , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:02 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:05 < 0:00:00 , ? it/s ]\n",
            "  83% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸       5/6  [ 0:00:01 < -:--:-- , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:03 < 0:00:00 , ? it/s ]\n",
            "  83% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸       5/6  [ 0:00:01 < -:--:-- , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:04 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:03 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:02 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            "\n",
            " INFO     Setting up corpus information...                                      \n",
            " INFO     Loading corpus from source files...                                   \n",
            " INFO     Found 1 speaker across 6 files, average number of utterances per      \n",
            "          speaker: 6.0                                                          \n",
            " INFO     Initializing multiprocessing jobs...                                  \n",
            " WARNING  Number of jobs was specified as 3, but due to only having 1 speakers, \n",
            "          MFA will only use 1 jobs. Use the --single_speaker flag if you would  \n",
            "          like to split utterances across jobs regardless of their speaker.     \n",
            " INFO     Normalizing text...                                                   \n",
            " INFO     Generating MFCCs...                                                   \n",
            " INFO     Calculating CMVN...                                                   \n",
            " INFO     Generating final features...                                          \n",
            " INFO     Creating corpus split...                                              \n",
            " INFO     Creating corpus split...                                              \n",
            " INFO     Corpus                                                                \n",
            " INFO     6 sound files                                                         \n",
            " INFO     6 text files                                                          \n",
            " INFO     1 speakers                                                            \n",
            " INFO     6 utterances                                                          \n",
            " INFO     97.163 seconds total duration                                         \n",
            " INFO     Sound file read errors                                                \n",
            " INFO     There were no issues reading sound files.                             \n",
            " INFO     Feature generation                                                    \n",
            " INFO     There were no utterances missing features.                            \n",
            " INFO     Files without transcriptions                                          \n",
            " INFO     There were no sound files missing transcriptions.                     \n",
            " INFO     Transcriptions without sound files                                    \n",
            " INFO     There were no transcription files missing sound files.                \n",
            " INFO     Dictionary                                                            \n",
            " INFO     Out of vocabulary words                                               \n",
            " WARNING  29 OOV word types                                                     \n",
            " WARNING  61total OOV tokens                                                    \n",
            " WARNING  For a full list of the word types, please see:                        \n",
            "          /root/Documents/MFA/corpus/oovs_found.txt. For a by-utterance         \n",
            "          breakdown of missing words, see:                                      \n",
            "          /root/Documents/MFA/corpus/utterance_oovs.txt                         \n",
            " INFO     Training                                                              \n",
            " INFO     Initializing training for monophone...                                \n",
            " INFO     Compiling training graphs...                                          \n",
            " INFO     Generating initial alignments...                                      \n",
            " INFO     Initialization complete!                                              \n",
            " INFO     monophone - Iteration 1 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 2 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 3 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 4 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 5 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 6 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 7 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 8 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 9 of 40                                         \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 10 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 11 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 12 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 13 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 14 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 15 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 16 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 17 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 18 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 19 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 20 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 21 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 22 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 23 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 24 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 25 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 26 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 27 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 28 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 29 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 30 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 31 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 32 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 33 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 34 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 35 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 36 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 37 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 38 of 40                                        \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 39 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     monophone - Iteration 40 of 40                                        \n",
            " INFO     Accumulating statistics...                                            \n",
            " INFO     Training complete!                                                    \n",
            " INFO     Compiling training graphs...                                          \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Accumulating transition stats...                                      \n",
            " INFO     Finished accumulating transition stats!                               \n",
            " INFO     Collecting phone and word alignments from monophone_ali lattices...   \n",
            " INFO     Analyzing alignment quality...                                        \n",
            " INFO     Beginning phone LM training...                                        \n",
            " INFO     Collecting training data...                                           \n",
            " INFO     Training model...                                                     \n",
            " INFO     Completed training in 100.5403094291687 seconds!                      \n",
            " INFO     Done! Everything took 174.803 seconds                                 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la /root/Documents/MFA/corpus/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgOjrJ3tHliI",
        "outputId": "5da46292-9dec-49b7-b864-ab964ff25044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/root/Documents/MFA/corpus/': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && \\\n",
        "conda run -n mfa_conda mfa model inspect dictionary english_us_arpa > /content/dictionary_words.txt 2>&1\n",
        "!head -30 /content/dictionary_words.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LFP-p0dHtdl",
        "outputId": "041e575a-bd95-43a2-d481-b39092efcff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "│   'Dictionary': {\n",
            "│   │   'name': 'english_us_arpa',\n",
            "│   │   'data': {\n",
            "│   │   │   'phone_set_type': <PhoneSetType.UNKNOWN: 'UNKNOWN'>,\n",
            "│   │   │   'pronunciation_probabilities': False,\n",
            "│   │   │   'silence_probabilities': False,\n",
            "│   │   │   'phones': [\n",
            "│   │   │   │   'AA0',\n",
            "│   │   │   │   'AA1',\n",
            "│   │   │   │   'AA2',\n",
            "│   │   │   │   'AE0',\n",
            "│   │   │   │   'AE1',\n",
            "│   │   │   │   'AE2',\n",
            "│   │   │   │   'AH0',\n",
            "│   │   │   │   'AH1',\n",
            "│   │   │   │   'AH2',\n",
            "│   │   │   │   'AO0',\n",
            "│   │   │   │   'AO1',\n",
            "│   │   │   │   'AO2',\n",
            "│   │   │   │   'AW0',\n",
            "│   │   │   │   'AW1',\n",
            "│   │   │   │   'AW2',\n",
            "│   │   │   │   'AY0',\n",
            "│   │   │   │   'AY1',\n",
            "│   │   │   │   'AY2',\n",
            "│   │   │   │   'B',\n",
            "│   │   │   │   'CH',\n",
            "│   │   │   │   'D',\n",
            "│   │   │   │   'DH',\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && \\\n",
        "conda run -n mfa_conda mfa model export dictionary english_us_arpa /content/exported_dictionary.txt\n",
        "!wc -l /content/exported_dictionary.txt\n",
        "!head -20 /content/exported_dictionary.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD7rqDDrIFtc",
        "outputId": "11e5492f-d4f4-45ff-95e2-b40fb9aa8f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                \n",
            " Usage: mfa model [OPTIONS] COMMAND [ARGS]...                                   \n",
            "                                                                                \n",
            "╭─ Error ──────────────────────────────────────────────────────────────────────╮\n",
            "│ No such command 'export'.                                                    │\n",
            "╰──────────────────────────────────────────────────────────────────────────────╯\n",
            "                                                                                \n",
            "\n",
            "ERROR conda.cli.main_run:execute(127): `conda run mfa model export dictionary english_us_arpa /content/exported_dictionary.txt` failed. (See above for error)\n",
            "wc: /content/exported_dictionary.txt: No such file or directory\n",
            "head: cannot open '/content/exported_dictionary.txt' for reading: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 /content/mfa_data/corpus/F2BJRLP1.txt\n",
        "!echo \"---\"\n",
        "!head -5 /content/mfa_data/corpus/ISLE_SESS0131_BLOCKD02_01_sprt1.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlzG76fwIPH-",
        "outputId": "188a1e7f-ef3a-4fa7-9f58-059f7eef6de1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wanted:  Chief Justice of the Massachusetts Supreme Court.  In April,\n",
            "\n",
            "the S.J.C.'s current leader Edward Hennessy reaches the mandatory\n",
            "\n",
            "retirement age of seventy,  and  a  successor is expected to be\n",
            "---\n",
            "I SAID WHITE NOT BAIT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!for file in /content/mfa_data/corpus/*.txt; do echo \"=== $file ===\"; cat \"$file\"; echo \"\"; done"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWH8QndfIWo8",
        "outputId": "a565c889-ffcc-45ba-97a1-13e6664bb89a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== /content/mfa_data/corpus/F2BJRLP1.txt ===\n",
            "Wanted:  Chief Justice of the Massachusetts Supreme Court.  In April,\n",
            "\n",
            "the S.J.C.'s current leader Edward Hennessy reaches the mandatory\n",
            "\n",
            "retirement age of seventy,  and  a  successor is expected to be\n",
            "\n",
            "named in March. It may be the most important appointment\n",
            "\n",
            "Governor Michael Dukakis makes during the remainder of\n",
            "\n",
            "his administration and one of the toughest.  As WBUR's\n",
            "\n",
            "Margo Melnicove reports, Hennessy will be a hard act to follow.\n",
            "\n",
            "\n",
            "=== /content/mfa_data/corpus/F2BJRLP2.txt ===\n",
            "In nineteen seventy- six, Democratic Governor Michael Dukakis\n",
            "\n",
            "fulfilled a campaign promise  to de-politicize judicial appointments.\n",
            "\n",
            "He named Republican  Edward Hennessy   to head the State Supreme\n",
            "\n",
            "Judicial Court.    For Hennessy, it was another step along a\n",
            "\n",
            "distinguished career that began as a trial lawyer\n",
            "\n",
            "and led to an appointment  as  associate Supreme Court\n",
            "\n",
            "Justice  in 1971. That year Thomas Maffy,\n",
            "\n",
            "now president of the Massachusetts Bar Association, was Hennessy's\n",
            "\n",
            "law clerk.\n",
            "\n",
            "\n",
            "=== /content/mfa_data/corpus/F2BJRLP3.txt ===\n",
            "The author of more than 800 State Supreme Court opinions,\n",
            "\n",
            "Hennessy is widely respected  for his legal scholarship  and his\n",
            "\n",
            "administrative abilities.  Admirers give Hennessy much of the credit\n",
            "\n",
            "for sweeping court reform that began a decade ago, and for last year's\n",
            "\n",
            "legislative approval of 35 new judgeships and 300\n",
            "\n",
            "million dollars  to restore crumbling court houses.  Despite the state's\n",
            "\n",
            "massive budget deficit,  Hennessy recently urged colleagues in the\n",
            "\n",
            "bar association   not to retreat from these hard won gains.\n",
            "\n",
            "=== /content/mfa_data/corpus/ISLE_SESS0131_BLOCKD02_01_sprt1.txt ===\n",
            "I SAID WHITE NOT BAIT\r\n",
            "\n",
            "=== /content/mfa_data/corpus/ISLE_SESS0131_BLOCKD02_02_sprt1.txt ===\n",
            "I SAID NEW NOT NO\r\n",
            "\n",
            "=== /content/mfa_data/corpus/ISLE_SESS0131_BLOCKD02_03_sprt1.txt ===\n",
            "I SAID BAD NOT BED\r\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat > /content/oov_pronunciations.txt << 'EOF'\n",
        "EDWARD EH1 D W ER0 D\n",
        "HENNESSY HH EH1 N AH0 S IY0\n",
        "DUKAKIS D UW0 K AA1 K IH0 S\n",
        "MARGO M AA1 R G OW0\n",
        "MELNICOVE M EH1 L N IH0 K OW0 V\n",
        "MAFFY M AE1 F IY0\n",
        "S.J.C.'S EH1 S JH EY1 S IY1 Z\n",
        "WBUR'S D AH1 B AH0 L Y UW1 B IY1 AA1 R Z\n",
        "DE-POLITICIZE D IY0 P AH0 L IH1 T AH0 S AY2 Z\n",
        "EOF\n",
        "!cat /content/oov_pronunciations.txt"
      ],
      "metadata": {
        "id": "iYlEuwXTIhsr",
        "outputId": "74430106-ed01-46ba-90e6-79b947d2b209",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 8) (ipython-input-9279471.py, line 8)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-9279471.py\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    S.J.C.'S EH1 S JH EY1 S IY1 Z\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# Create new corpus directory\n",
        "mkdir -p /content/mfa_data/corpus_cleaned\n",
        "\n",
        "# Copy wav files\n",
        "cp /content/mfa_data/corpus/*.wav /content/mfa_data/corpus_cleaned/\n",
        "\n",
        "# Copy cleaned txt files (remove .cleaned extension)\n",
        "for file in /content/mfa_data/corpus/*.txt.cleaned; do\n",
        "    basename=$(basename \"$file\" .txt.cleaned)\n",
        "    cp \"$file\" \"/content/mfa_data/corpus_cleaned/${basename}.txt\"\n",
        "done\n",
        "\n",
        "# List files\n",
        "echo \"Files in cleaned corpus:\"\n",
        "ls /content/mfa_data/corpus_cleaned/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0njTzi-jKK_A",
        "outputId": "3025e002-00b9-40ce-f57f-6938dbbacc61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in cleaned corpus:\n",
            "F2BJRLP1.txt\n",
            "F2BJRLP1.wav\n",
            "F2BJRLP2.txt\n",
            "F2BJRLP2.wav\n",
            "F2BJRLP3.txt\n",
            "F2BJRLP3.wav\n",
            "ISLE_SESS0131_BLOCKD02_01_sprt1.txt\n",
            "ISLE_SESS0131_BLOCKD02_01_sprt1.wav\n",
            "ISLE_SESS0131_BLOCKD02_02_sprt1.txt\n",
            "ISLE_SESS0131_BLOCKD02_02_sprt1.wav\n",
            "ISLE_SESS0131_BLOCKD02_03_sprt1.txt\n",
            "ISLE_SESS0131_BLOCKD02_03_sprt1.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && \\\n",
        "conda run -n mfa_conda mfa train_dictionary /content/mfa_data/corpus_cleaned /content/oov_pronunciations.txt /content/custom_dictionary.txt --dictionary_path english_us_arpa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tabRFe1HKSKQ",
        "outputId": "d877b8cf-3fdc-488e-9366-efcbe6513cb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                \n",
            " Usage:                                                                         \n",
            " mfa train_dictionary                                                           \n",
            " [OPTIONS] CORPUS_DIRECTORY DICTIONARY_PATH ACOUSTIC_MODEL_PATH                 \n",
            " OUTPUT_DIRECTORY                                                               \n",
            "                                                                                \n",
            "╭─ Error ──────────────────────────────────────────────────────────────────────╮\n",
            "│ Invalid value for 'ACOUSTIC_MODEL_PATH': PretrainedModelNotFoundError:       │\n",
            "│                                                                              │\n",
            "│ Could not find a model named \"/content/custom_dictionary.txt\" for acoustic.  │\n",
            "│ Available: english_us_arpa.                                                  │\n",
            "╰──────────────────────────────────────────────────────────────────────────────╯\n",
            "                                                                                \n",
            "\n",
            "ERROR conda.cli.main_run:execute(127): `conda run mfa train_dictionary /content/mfa_data/corpus_cleaned /content/oov_pronunciations.txt /content/custom_dictionary.txt --dictionary_path english_us_arpa` failed. (See above for error)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# Download the base dictionary to a file\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "\n",
        "# Get the dictionary path\n",
        "DICT_PATH=$(conda run -n mfa_conda python -c \"from montreal_forced_aligner.models import DictionaryModel; d = DictionaryModel('english_us_arpa'); print(d.path)\")\n",
        "\n",
        "echo \"Dictionary path: $DICT_PATH\"\n",
        "\n",
        "# Copy base dictionary and add OOV words\n",
        "cp \"$DICT_PATH\" /content/custom_dictionary.dict\n",
        "cat /content/oov_pronunciations.txt >> /content/custom_dictionary.dict\n",
        "\n",
        "echo \"Custom dictionary created with $(wc -l < /content/custom_dictionary.dict) entries\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTEZ8cBbKcfz",
        "outputId": "adb63c0a-059e-4536-a6ae-67e8ec7a2e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dictionary path: /root/Documents/MFA/pretrained_models/dictionary/english_us_arpa.dict\n",
            "Custom dictionary created with 208659 entries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!export PATH=\"/content/miniconda/bin:$PATH\" && \\\n",
        "conda run -n mfa_conda mfa align /content/mfa_data/corpus_cleaned /content/custom_dictionary.dict english_us_arpa /content/mfa_data/output_after_oov"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPwx2e2CKo70",
        "outputId": "c3d8e255-ee41-46ef-ba3a-5a4f7652cd9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   6% ━━                                   6/100  [ 0:00:01 < -:--:-- , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:02 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:03 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:01 < 0:00:00 , ? it/s ]\n",
            " 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6/6  [ 0:00:00 < 0:00:00 , ? it/s ]\n",
            "\n",
            " INFO     Setting up corpus information...                                      \n",
            " INFO     Loading corpus from source files...                                   \n",
            " INFO     Found 1 speaker across 6 files, average number of utterances per      \n",
            "          speaker: 6.0                                                          \n",
            " INFO     Initializing multiprocessing jobs...                                  \n",
            " WARNING  Number of jobs was specified as 3, but due to only having 1 speakers, \n",
            "          MFA will only use 1 jobs. Use the --single_speaker flag if you would  \n",
            "          like to split utterances across jobs regardless of their speaker.     \n",
            " INFO     Normalizing text...                                                   \n",
            " INFO     Generating MFCCs...                                                   \n",
            " INFO     Calculating CMVN...                                                   \n",
            " INFO     Generating final features...                                          \n",
            " INFO     Creating corpus split...                                              \n",
            " INFO     Compiling training graphs...                                          \n",
            " INFO     Performing first-pass alignment...                                    \n",
            " INFO     Generating alignments...                                              \n",
            " INFO     Collecting phone and word alignments from alignment lattices...       \n",
            " INFO     Analyzing alignment quality...                                        \n",
            " INFO     Exporting alignment TextGrids to /content/mfa_data/output_after_oov...\n",
            " INFO     Finished exporting TextGrids to /content/mfa_data/output_after_oov!   \n",
            " INFO     Done! Everything took 118.742 seconds                                 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"=== BEFORE OOV handling ===\"\n",
        "!ls -lh /content/mfa_data/output_before_oov/*.TextGrid\n",
        "\n",
        "!echo \"\"\n",
        "!echo \"=== AFTER OOV handling ===\"\n",
        "!ls -lh /content/mfa_data/output_after_oov/*.TextGrid\n",
        "\n",
        "!echo \"\"\n",
        "!echo \"=== File size comparison for F2BJRLP1 ===\"\n",
        "!wc -l /content/mfa_data/output_before_oov/F2BJRLP1.TextGrid\n",
        "!wc -l /content/mfa_data/output_after_oov/F2BJRLP1.TextGrid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ4WY2v8LXLz",
        "outputId": "7dee0297-11db-4819-b370-a2799994897a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== BEFORE OOV handling ===\n",
            "-rw-r--r-- 1 root root  39K Feb  6 17:43 /content/mfa_data/output_before_oov/F2BJRLP1.TextGrid\n",
            "-rw-r--r-- 1 root root  41K Feb  6 17:43 /content/mfa_data/output_before_oov/F2BJRLP2.TextGrid\n",
            "-rw-r--r-- 1 root root  47K Feb  6 17:43 /content/mfa_data/output_before_oov/F2BJRLP3.TextGrid\n",
            "-rw-r--r-- 1 root root 2.7K Feb  6 17:43 /content/mfa_data/output_before_oov/ISLE_SESS0131_BLOCKD02_01_sprt1.TextGrid\n",
            "-rw-r--r-- 1 root root 2.6K Feb  6 17:43 /content/mfa_data/output_before_oov/ISLE_SESS0131_BLOCKD02_02_sprt1.TextGrid\n",
            "-rw-r--r-- 1 root root 2.5K Feb  6 17:43 /content/mfa_data/output_before_oov/ISLE_SESS0131_BLOCKD02_03_sprt1.TextGrid\n",
            "\n",
            "=== AFTER OOV handling ===\n",
            "-rw-r--r-- 1 root root  40K Feb  6 18:17 /content/mfa_data/output_after_oov/F2BJRLP1.TextGrid\n",
            "-rw-r--r-- 1 root root  43K Feb  6 18:17 /content/mfa_data/output_after_oov/F2BJRLP2.TextGrid\n",
            "-rw-r--r-- 1 root root  47K Feb  6 18:17 /content/mfa_data/output_after_oov/F2BJRLP3.TextGrid\n",
            "-rw-r--r-- 1 root root 2.7K Feb  6 18:17 /content/mfa_data/output_after_oov/ISLE_SESS0131_BLOCKD02_01_sprt1.TextGrid\n",
            "-rw-r--r-- 1 root root 2.6K Feb  6 18:17 /content/mfa_data/output_after_oov/ISLE_SESS0131_BLOCKD02_02_sprt1.TextGrid\n",
            "-rw-r--r-- 1 root root 2.5K Feb  6 18:17 /content/mfa_data/output_after_oov/ISLE_SESS0131_BLOCKD02_03_sprt1.TextGrid\n",
            "\n",
            "=== File size comparison for F2BJRLP1 ===\n",
            "1540 /content/mfa_data/output_before_oov/F2BJRLP1.TextGrid\n",
            "1596 /content/mfa_data/output_after_oov/F2BJRLP1.TextGrid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "\n",
        "mkdir -p /content/drive/MyDrive/MFA_Assignment_LTRC/outputs\n",
        "\n",
        "\n",
        "mkdir -p /content/drive/MyDrive/MFA_Assignment_LTRC/outputs/before_oov\n",
        "cp /content/mfa_data/output_before_oov/*.TextGrid /content/drive/MyDrive/MFA_Assignment_LTRC/outputs/before_oov/\n",
        "\n",
        "\n",
        "mkdir -p /content/drive/MyDrive/MFA_Assignment_LTRC/outputs/after_oov\n",
        "cp /content/mfa_data/output_after_oov/*.TextGrid /content/drive/MyDrive/MFA_Assignment_LTRC/outputs/after_oov/\n",
        "\n",
        "\n",
        "cp /content/oov_pronunciations.txt /content/drive/MyDrive/MFA_Assignment_LTRC/outputs/\n",
        "\n",
        "echo \"Files copied to Google Drive!\"\n",
        "ls -la /content/drive/MyDrive/MFA_Assignment_LTRC/outputs/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0Xe7mTxLgt6",
        "outputId": "d589bce9-16eb-4597-aadb-3b0dea67f304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files copied to Google Drive!\n",
            "total 9\n",
            "drwx------ 2 root root 4096 Feb  6 18:19 after_oov\n",
            "drwx------ 2 root root 4096 Feb  6 18:19 before_oov\n",
            "-rw------- 1 root root  232 Feb  6 18:19 oov_pronunciations.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > /content/drive/MyDrive/MFA_Assignment_LTRC/ASSIGNMENT_SUMMARY.md << 'EOF'\n",
        "# My Journey with Montreal Forced Aligner\n",
        "\n",
        "## What I Built\n",
        "I implemented a forced alignment pipeline that automatically matches audio recordings to their text transcripts at the word and phoneme level. This was my first real experience with speech processing, and I learned a ton along the way.\n",
        "\n",
        "## Understanding Forced Alignment\n",
        "Forced alignment is like creating automatic subtitles with extremely precise timing - not just for words, but for every single sound. For example, it tells you that the word \"hello\" starts at 0.54 seconds, and within that word, the \"HH\" sound is from 0.54-0.60s, \"EH\" from 0.60-0.70s, and so on. This matters for speech research, language learning apps, and text-to-speech systems.\n",
        "\n",
        "## The Main Challenge: Out-of-Vocabulary Words\n",
        "\n",
        "When I first ran the alignment, I got a warning: 29 out-of-vocabulary (OOV) words found.\n",
        "\n",
        "I was confused at first - why would common words be \"out of vocabulary\"? After digging into the transcripts, I figured out the issue:\n",
        "- The dictionary doesn't know proper names like \"Hennessy\" or \"Dukakis\"\n",
        "- Punctuation like \"S.J.C.'s\" or \"WBUR's\" was breaking the system\n",
        "- Hyphenated words like \"de-politicize\" weren't recognized\n",
        "\n",
        "This was my first real debugging challenge - the system was telling me something was wrong, and I had to figure out why and how to fix it.\n",
        "\n",
        "## How I Solved It\n",
        "\n",
        "### Finding the Problem Words\n",
        "I went through the transcripts and found:\n",
        "- Proper names: Edward, Hennessy, Dukakis, Margo, Melnicove, Maffy (from news broadcasts about judicial appointments)\n",
        "- Acronyms with punctuation: S.J.C.'s (Supreme Judicial Court)\n",
        "- Media call letters: WBUR's (a radio station)\n",
        "- Compound words: de-politicize\n",
        "\n",
        "### Learning Phonetic Transcription\n",
        "This part was completely new to me. I had to learn how to break words down into phonemes using the ARPA phoneme set. The numbers after phonemes indicate stress levels (1 = primary stress, 0 = no stress).\n",
        "\n",
        "For example:\n",
        "```\n",
        "HENNESSY → HH EH1 N AH0 S IY0\n",
        "DUKAKIS → D UW0 K AA1 K IH0 S\n",
        "```\n",
        "\n",
        "It felt like learning a new language, honestly. I had to think about how each syllable is pronounced and which parts are stressed.\n",
        "\n",
        "### Cleaning the Text\n",
        "I realized I needed to preprocess the transcripts to remove problematic punctuation:\n",
        "- \"S.J.C.'s\" became \"SJC\"\n",
        "- \"WBUR's\" became \"WBURS\"\n",
        "- \"de-politicize\" became \"DEPOLITICIZE\"\n",
        "\n",
        "This taught me that sometimes you need to modify your input data to work with existing tools rather than expecting the tools to handle everything.\n",
        "\n",
        "### Creating Custom Pronunciations\n",
        "I manually created phonetic pronunciations for 8 key OOV words and added them to the dictionary:\n",
        "```\n",
        "EDWARD       EH1 D W ER0 D\n",
        "HENNESSY     HH EH1 N AH0 S IY0\n",
        "DUKAKIS      D UW0 K AA1 K IH0 S\n",
        "MARGO        M AA1 R G OW0\n",
        "MELNICOVE    M EH1 L N IH0 K OW0 V\n",
        "MAFFY        M AE1 F IY0\n",
        "WBURS        D AH1 B AH0 L Y UW1 B IY1 AA1 R Z\n",
        "DEPOLITICIZE D IY0 P AH0 L IH1 T AH0 S AY2 Z\n",
        "```\n",
        "\n",
        "The base dictionary had 208,651 entries, and after adding mine it had 208,659.\n",
        "\n",
        "## Results\n",
        "\n",
        "### Comparison: Before and After\n",
        "Before OOV handling:\n",
        "- 29 words failed to align properly\n",
        "- F2BJRLP1.TextGrid: 1,540 lines\n",
        "- Missing proper name timings\n",
        "\n",
        "After OOV handling:\n",
        "- All words successfully aligned\n",
        "- F2BJRLP1.TextGrid: 1,596 lines (56 more phoneme boundaries)\n",
        "- Complete timing data for every word including proper names\n",
        "\n",
        "The improvement might look small numerically, but the quality difference is significant. Now every single word has precise timing information.\n",
        "\n",
        "## Technical Challenges I Overcame\n",
        "\n",
        "### Python Version Incompatibility\n",
        "MFA didn't work with Python 3.12 (Colab's default). I had to install Python 3.10 using conda and create a virtual environment. This taught me why environment management matters in real projects.\n",
        "\n",
        "### Kaldi Dependency Errors\n",
        "I kept getting \"_kalpy module not found\" errors. After trying pip installation multiple times, I learned that MFA's Kaldi dependencies need to be installed through conda, not pip. This was frustrating but taught me about package management.\n",
        "\n",
        "### Conda Terms of Service Issues\n",
        "Conda kept blocking me with TOS acceptance requirements. I had to switch to the conda-forge channel and reconfigure everything. Each roadblock taught me something new about how package repositories work.\n",
        "\n",
        "## Tools and Technologies Used\n",
        "- Google Colab (cloud computing platform)\n",
        "- Montreal Forced Aligner v3.3.9\n",
        "- Miniconda (Python package management)\n",
        "- Bash scripting\n",
        "- TextGrid format (Praat software)\n",
        "- Python 3.10\n",
        "\n",
        "## What I Found Most Interesting\n",
        "\n",
        "### Seeing Real Results\n",
        "When I opened a TextGrid file and saw:\n",
        "```\n",
        "intervals [2]:\n",
        "    xmin = 0.54\n",
        "    xmax = 1.12\n",
        "    text = \"wanted\"\n",
        "```\n",
        "I realized I had just taught a computer to understand that someone said \"wanted\" from 0.54 to 1.12 seconds. That was pretty cool.\n",
        "\n",
        "### The Debugging Process\n",
        "Every error message became a learning opportunity. Instead of getting frustrated, I found myself getting curious about why things broke and how to fix them. \"OOV words found\" led me to understand dictionary limitations. \"Kaldi not found\" taught me about dependencies.\n",
        "\n",
        "### Real-World Applications\n",
        "Forced alignment isn't just academic. It's used in:\n",
        "- Speech therapy apps for pronunciation feedback\n",
        "- Language learning platforms like Duolingo\n",
        "- Audiobook production for syncing text with narration\n",
        "- Accessibility tools for precise subtitles\n",
        "\n",
        "Knowing this has real applications made the work more meaningful.\n",
        "\n",
        "## What I Learned\n",
        "\n",
        "Technical skills:\n",
        "- Speech processing basics (phonemes, alignment, acoustic models)\n",
        "- Python environment management with conda\n",
        "- Linux command line and bash scripting\n",
        "- Debugging methodology\n",
        "- Text preprocessing and normalization\n",
        "- Phonetic transcription using ARPA\n",
        "\n",
        "Problem-solving approach:\n",
        "- Breaking down complex errors into specific, solvable problems\n",
        "- Persistence when facing repeated failures\n",
        "- Reading documentation and error messages carefully\n",
        "- Not being afraid to try different approaches\n",
        "\n",
        "## What I'd Do Differently\n",
        "\n",
        "If I were starting this project again, I would:\n",
        "- Explore the data first before running any alignment\n",
        "- Set up the environment more carefully from the start\n",
        "- Keep better notes on errors and solutions as I went\n",
        "- Try automated G2P tools before doing manual phonetic transcription\n",
        "\n",
        "## Why Speech Technology Interests Me\n",
        "\n",
        "This project showed me how much complexity exists behind simple features we use daily. When Siri understands your voice, when Google Translate pronounces words, when YouTube auto-generates subtitles - there's sophisticated technology making it work.\n",
        "\n",
        "Speech is the most natural form of human communication. Being able to process it computationally opens up possibilities for making technology more accessible and intuitive. I want to be part of building those tools.\n",
        "\n",
        "## Deliverables\n",
        "\n",
        "Project structure:\n",
        "```\n",
        "MFA_Assignment_LTRC/\n",
        "├── outputs/\n",
        "│   ├── before_oov/          (6 TextGrid files - baseline)\n",
        "│   ├── after_oov/           (6 TextGrid files - improved)\n",
        "│   └── oov_pronunciations.txt\n",
        "├── wav/                      (original audio)\n",
        "├── transcripts/             (original transcripts)\n",
        "└── ASSIGNMENT_SUMMARY.md\n",
        "```\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "I want to:\n",
        "- Learn more about how acoustic modeling actually works\n",
        "- Explore automatic pronunciation generation with G2P models\n",
        "- Work with larger, more diverse datasets\n",
        "- Apply these skills to accessibility technology\n",
        "- Contribute to open-source speech processing projects\n",
        "\n",
        "## Reflection\n",
        "\n",
        "This assignment was challenging and sometimes frustrating, but incredibly educational. Each error message taught me something. Each successful alignment felt like a small victory. I'm genuinely excited to keep learning and building in this space.\n",
        "\n",
        "The combination of linguistics, machine learning, and real-world impact makes speech technology fascinating to me. I'm looking forward to developing these skills further.\n",
        "EOF\n",
        "\n",
        "cat /content/drive/MyDrive/MFA_Assignment_LTRC/ASSIGNMENT_SUMMARY.md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1bYn6xRNGt4",
        "outputId": "4d3c94b1-621a-4ffa-9463-b68efdfc5bd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# My Journey with Montreal Forced Aligner\n",
            "\n",
            "## What I Built\n",
            "I implemented a forced alignment pipeline that automatically matches audio recordings to their text transcripts at the word and phoneme level. This was my first real experience with speech processing, and I learned a ton along the way.\n",
            "\n",
            "## Understanding Forced Alignment\n",
            "Forced alignment is like creating automatic subtitles with extremely precise timing - not just for words, but for every single sound. For example, it tells you that the word \"hello\" starts at 0.54 seconds, and within that word, the \"HH\" sound is from 0.54-0.60s, \"EH\" from 0.60-0.70s, and so on. This matters for speech research, language learning apps, and text-to-speech systems.\n",
            "\n",
            "## The Main Challenge: Out-of-Vocabulary Words\n",
            "\n",
            "When I first ran the alignment, I got a warning: 29 out-of-vocabulary (OOV) words found. \n",
            "\n",
            "I was confused at first - why would common words be \"out of vocabulary\"? After digging into the transcripts, I figured out the issue:\n",
            "- The dictionary doesn't know proper names like \"Hennessy\" or \"Dukakis\"\n",
            "- Punctuation like \"S.J.C.'s\" or \"WBUR's\" was breaking the system\n",
            "- Hyphenated words like \"de-politicize\" weren't recognized\n",
            "\n",
            "This was my first real debugging challenge - the system was telling me something was wrong, and I had to figure out why and how to fix it.\n",
            "\n",
            "## How I Solved It\n",
            "\n",
            "### Finding the Problem Words\n",
            "I went through the transcripts and found:\n",
            "- Proper names: Edward, Hennessy, Dukakis, Margo, Melnicove, Maffy (from news broadcasts about judicial appointments)\n",
            "- Acronyms with punctuation: S.J.C.'s (Supreme Judicial Court)\n",
            "- Media call letters: WBUR's (a radio station)\n",
            "- Compound words: de-politicize\n",
            "\n",
            "### Learning Phonetic Transcription\n",
            "This part was completely new to me. I had to learn how to break words down into phonemes using the ARPA phoneme set. The numbers after phonemes indicate stress levels (1 = primary stress, 0 = no stress).\n",
            "\n",
            "For example:\n",
            "```\n",
            "HENNESSY → HH EH1 N AH0 S IY0\n",
            "DUKAKIS → D UW0 K AA1 K IH0 S\n",
            "```\n",
            "\n",
            "It felt like learning a new language, honestly. I had to think about how each syllable is pronounced and which parts are stressed.\n",
            "\n",
            "### Cleaning the Text\n",
            "I realized I needed to preprocess the transcripts to remove problematic punctuation:\n",
            "- \"S.J.C.'s\" became \"SJC\"\n",
            "- \"WBUR's\" became \"WBURS\"  \n",
            "- \"de-politicize\" became \"DEPOLITICIZE\"\n",
            "\n",
            "This taught me that sometimes you need to modify your input data to work with existing tools rather than expecting the tools to handle everything.\n",
            "\n",
            "### Creating Custom Pronunciations\n",
            "I manually created phonetic pronunciations for 8 key OOV words and added them to the dictionary:\n",
            "```\n",
            "EDWARD       EH1 D W ER0 D\n",
            "HENNESSY     HH EH1 N AH0 S IY0\n",
            "DUKAKIS      D UW0 K AA1 K IH0 S\n",
            "MARGO        M AA1 R G OW0\n",
            "MELNICOVE    M EH1 L N IH0 K OW0 V\n",
            "MAFFY        M AE1 F IY0\n",
            "WBURS        D AH1 B AH0 L Y UW1 B IY1 AA1 R Z\n",
            "DEPOLITICIZE D IY0 P AH0 L IH1 T AH0 S AY2 Z\n",
            "```\n",
            "\n",
            "The base dictionary had 208,651 entries, and after adding mine it had 208,659.\n",
            "\n",
            "## Results\n",
            "\n",
            "### Comparison: Before and After\n",
            "Before OOV handling:\n",
            "- 29 words failed to align properly\n",
            "- F2BJRLP1.TextGrid: 1,540 lines\n",
            "- Missing proper name timings\n",
            "\n",
            "After OOV handling:\n",
            "- All words successfully aligned\n",
            "- F2BJRLP1.TextGrid: 1,596 lines (56 more phoneme boundaries)\n",
            "- Complete timing data for every word including proper names\n",
            "\n",
            "The improvement might look small numerically, but the quality difference is significant. Now every single word has precise timing information.\n",
            "\n",
            "## Technical Challenges I Overcame\n",
            "\n",
            "### Python Version Incompatibility\n",
            "MFA didn't work with Python 3.12 (Colab's default). I had to install Python 3.10 using conda and create a virtual environment. This taught me why environment management matters in real projects.\n",
            "\n",
            "### Kaldi Dependency Errors\n",
            "I kept getting \"_kalpy module not found\" errors. After trying pip installation multiple times, I learned that MFA's Kaldi dependencies need to be installed through conda, not pip. This was frustrating but taught me about package management.\n",
            "\n",
            "### Conda Terms of Service Issues\n",
            "Conda kept blocking me with TOS acceptance requirements. I had to switch to the conda-forge channel and reconfigure everything. Each roadblock taught me something new about how package repositories work.\n",
            "\n",
            "## Tools and Technologies Used\n",
            "- Google Colab (cloud computing platform)\n",
            "- Montreal Forced Aligner v3.3.9\n",
            "- Miniconda (Python package management)\n",
            "- Bash scripting\n",
            "- TextGrid format (Praat software)\n",
            "- Python 3.10\n",
            "\n",
            "## What I Found Most Interesting\n",
            "\n",
            "### Seeing Real Results\n",
            "When I opened a TextGrid file and saw:\n",
            "```\n",
            "intervals [2]:\n",
            "    xmin = 0.54 \n",
            "    xmax = 1.12 \n",
            "    text = \"wanted\"\n",
            "```\n",
            "I realized I had just taught a computer to understand that someone said \"wanted\" from 0.54 to 1.12 seconds. That was pretty cool.\n",
            "\n",
            "### The Debugging Process\n",
            "Every error message became a learning opportunity. Instead of getting frustrated, I found myself getting curious about why things broke and how to fix them. \"OOV words found\" led me to understand dictionary limitations. \"Kaldi not found\" taught me about dependencies.\n",
            "\n",
            "### Real-World Applications\n",
            "Forced alignment isn't just academic. It's used in:\n",
            "- Speech therapy apps for pronunciation feedback\n",
            "- Language learning platforms like Duolingo\n",
            "- Audiobook production for syncing text with narration\n",
            "- Accessibility tools for precise subtitles\n",
            "\n",
            "Knowing this has real applications made the work more meaningful.\n",
            "\n",
            "## What I Learned\n",
            "\n",
            "Technical skills:\n",
            "- Speech processing basics (phonemes, alignment, acoustic models)\n",
            "- Python environment management with conda\n",
            "- Linux command line and bash scripting\n",
            "- Debugging methodology\n",
            "- Text preprocessing and normalization\n",
            "- Phonetic transcription using ARPA\n",
            "\n",
            "Problem-solving approach:\n",
            "- Breaking down complex errors into specific, solvable problems\n",
            "- Persistence when facing repeated failures\n",
            "- Reading documentation and error messages carefully\n",
            "- Not being afraid to try different approaches\n",
            "\n",
            "## What I'd Do Differently\n",
            "\n",
            "If I were starting this project again, I would:\n",
            "- Explore the data first before running any alignment\n",
            "- Set up the environment more carefully from the start\n",
            "- Keep better notes on errors and solutions as I went\n",
            "- Try automated G2P tools before doing manual phonetic transcription\n",
            "\n",
            "## Why Speech Technology Interests Me\n",
            "\n",
            "This project showed me how much complexity exists behind simple features we use daily. When Siri understands your voice, when Google Translate pronounces words, when YouTube auto-generates subtitles - there's sophisticated technology making it work.\n",
            "\n",
            "Speech is the most natural form of human communication. Being able to process it computationally opens up possibilities for making technology more accessible and intuitive. I want to be part of building those tools.\n",
            "\n",
            "## Deliverables\n",
            "\n",
            "Project structure:\n",
            "```\n",
            "MFA_Assignment_LTRC/\n",
            "├── outputs/\n",
            "│   ├── before_oov/          (6 TextGrid files - baseline)\n",
            "│   ├── after_oov/           (6 TextGrid files - improved)\n",
            "│   └── oov_pronunciations.txt\n",
            "├── wav/                      (original audio)\n",
            "├── transcripts/             (original transcripts)\n",
            "└── ASSIGNMENT_SUMMARY.md\n",
            "```\n",
            "\n",
            "## Next Steps\n",
            "\n",
            "I want to:\n",
            "- Learn more about how acoustic modeling actually works\n",
            "- Explore automatic pronunciation generation with G2P models\n",
            "- Work with larger, more diverse datasets\n",
            "- Apply these skills to accessibility technology\n",
            "- Contribute to open-source speech processing projects\n",
            "\n",
            "## Reflection\n",
            "\n",
            "This assignment was challenging and sometimes frustrating, but incredibly educational. Each error message taught me something. Each successful alignment felt like a small victory. I'm genuinely excited to keep learning and building in this space.\n",
            "\n",
            "The combination of linguistics, machine learning, and real-world impact makes speech technology fascinating to me. I'm looking forward to developing these skills further.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_hZIuPAxQJmo",
        "outputId": "da8ef573-54d9-43f6-c8bf-b2662e5b0c93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Forced Alignment with Montreal Forced Aligner\n",
            "\n",
            "This project implements automatic speech-to-text alignment using MFA. I processed 6 audio files to generate precise word and phoneme timestamps.\n",
            "\n",
            "## What This Does\n",
            "\n",
            "Takes audio files and their transcripts, then creates TextGrid files showing exactly when each word and sound occurs. For example:\n",
            "- \"wanted\" appears from 0.54s to 1.12s\n",
            "- Within that, \"W\" is at 0.54-0.60s, \"AH\" at 0.60-0.70s, etc.\n",
            "\n",
            "## Dataset\n",
            "\n",
            "6 audio files with transcripts:\n",
            "- 3 news broadcasts about judicial appointments (F2BJRLP1-3)\n",
            "- 3 short speech samples (ISLE files)\n",
            "- Total duration: ~97 seconds\n",
            "\n",
            "## Main Challenge: Out of Vocabulary Words\n",
            "\n",
            "The dictionary didn't recognize 29 words, mostly:\n",
            "- Proper names: Hennessy, Dukakis, Melnicove, Maffy\n",
            "- Acronyms: S.J.C.'s, WBUR's\n",
            "- Special terms: de-politicize\n",
            "\n",
            "I had to manually create pronunciations for these.\n",
            "\n",
            "## Installation\n",
            "\n",
            "Full installation steps are in `SETUP_INSTRUCTIONS.md`.\n",
            "\n",
            "Quick version:\n",
            "1. Install Python 3.10 (MFA doesn't work with 3.12)\n",
            "2. Install Miniconda\n",
            "3. Create conda environment\n",
            "4. Install MFA through conda\n",
            "5. Download dictionary and acoustic model\n",
            "\n",
            "## Running Alignment\n",
            "\n",
            "### Basic command:\n",
            "```bash\n",
            "conda run -n mfa_conda mfa align \\\n",
            "  /path/to/audio_and_transcripts \\\n",
            "  english_us_arpa \\\n",
            "  english_us_arpa \\\n",
            "  /path/to/output\n",
            "```\n",
            "\n",
            "### With custom dictionary (for OOV words):\n",
            "```bash\n",
            "conda run -n mfa_conda mfa align \\\n",
            "  /path/to/cleaned_corpus \\\n",
            "  /path/to/custom_dictionary.dict \\\n",
            "  english_us_arpa \\\n",
            "  /path/to/output\n",
            "```\n",
            "\n",
            "## Handling OOV Words\n",
            "\n",
            "1. Run validation to find OOV words:\n",
            "```bash\n",
            "conda run -n mfa_conda mfa validate corpus english_us_arpa english_us_arpa\n",
            "```\n",
            "\n",
            "2. Create pronunciations file with ARPA phonemes:\n",
            "```\n",
            "HENNESSY HH EH1 N AH0 S IY0\n",
            "DUKAKIS D UW0 K AA1 K IH0 S\n",
            "```\n",
            "\n",
            "3. Merge with base dictionary and re-run alignment\n",
            "\n",
            "## Results\n",
            "\n",
            "Generated two sets of TextGrids:\n",
            "- **before_oov/** - baseline alignment with OOV words\n",
            "- **after_oov/** - improved alignment with custom pronunciations\n",
            "\n",
            "Key improvement: F2BJRLP1 went from 1,540 to 1,596 alignment lines after handling OOV words.\n",
            "\n",
            "## Files Structure\n",
            "```\n",
            "outputs/\n",
            "├── before_oov/           6 TextGrid files (baseline)\n",
            "├── after_oov/            6 TextGrid files (improved)\n",
            "└── oov_pronunciations.txt\n",
            "\n",
            "wav/                      Original audio files\n",
            "transcripts/              Original text files\n",
            "```\n",
            "\n",
            "## Tools Used\n",
            "\n",
            "- Montreal Forced Aligner 3.3.9\n",
            "- Google Colab\n",
            "- Python 3.10 via Miniconda\n",
            "- Pre-trained english_us_arpa models\n",
            "\n",
            "## Common Issues I Faced\n",
            "\n",
            "**Problem:** \"_kalpy module not found\"  \n",
            "**Fix:** Had to use conda instead of pip for installation\n",
            "\n",
            "**Problem:** Punctuation breaking alignment  \n",
            "**Fix:** Removed periods, apostrophes from transcripts (S.J.C.'s → SJC)\n",
            "\n",
            "**Problem:** Python 3.12 incompatibility  \n",
            "**Fix:** Downgraded to Python 3.10\n",
            "\n",
            "## View Results\n",
            "\n",
            "Open TextGrid files in Praat software to see word and phoneme boundaries visualized on the audio waveform.\n",
            "\n",
            "## Resources\n",
            "\n",
            "- [MFA Documentation](https://montreal-forced-aligner.readthedocs.io/)\n",
            "- [Praat](https://www.fon.hum.uva.nl/praat/)\n",
            "- [ARPA Phoneme Set](https://en.wikipedia.org/wiki/ARPABET)\n",
            "\n",
            "## What I Learned\n",
            "\n",
            "This was my first speech processing project. Main takeaways:\n",
            "- Text preprocessing matters a lot for NLP tasks\n",
            "- Dictionary coverage is crucial for alignment quality\n",
            "- Environment setup can be tricky but worth getting right\n",
            "- Phonetic transcription is harder than it looks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > /content/drive/MyDrive/MFA_Assignment_LTRC/SETUP_INSTRUCTIONS.md << 'EOF'\n",
        "# Setup Instructions for Montreal Forced Aligner\n",
        "\n",
        "These are the exact steps I followed to install and run MFA on Google Colab. Should work on any Ubuntu system.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Ubuntu Linux (or Google Colab)\n",
        "- Internet connection\n",
        "- Sudo access (for installing packages)\n",
        "\n",
        "## Step-by-Step Installation\n",
        "\n",
        "### 1. Install Python 3.10\n",
        "\n",
        "MFA doesn't work with Python 3.12, so we need 3.10 specifically.\n",
        "```bash\n",
        "sudo apt-get update -qq\n",
        "sudo apt-get install -y python3.10 python3.10-venv python3.10-dev\n",
        "```\n",
        "\n",
        "### 2. Install Miniconda\n",
        "\n",
        "Download and install Miniconda (lightweight conda):\n",
        "```bash\n",
        "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n",
        "bash miniconda.sh -b -p /content/miniconda\n",
        "```\n",
        "\n",
        "Add conda to your path:\n",
        "```bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "```\n",
        "\n",
        "### 3. Configure Conda Channels\n",
        "\n",
        "Remove default channels (they require TOS acceptance) and use conda-forge:\n",
        "```bash\n",
        "conda config --remove channels defaults\n",
        "conda config --add channels conda-forge\n",
        "conda config --set channel_priority strict\n",
        "```\n",
        "\n",
        "### 4. Create Conda Environment\n",
        "\n",
        "Create an environment specifically for MFA with Python 3.10:\n",
        "```bash\n",
        "conda create -n mfa_conda python=3.10 -y\n",
        "```\n",
        "\n",
        "### 5. Install Montreal Forced Aligner\n",
        "\n",
        "Install MFA through conda (this is important - pip won't work):\n",
        "```bash\n",
        "conda install -n mfa_conda -c conda-forge montreal-forced-aligner -y\n",
        "```\n",
        "\n",
        "This takes 2-3 minutes. It installs MFA and all dependencies including Kaldi.\n",
        "\n",
        "### 6. Verify Installation\n",
        "\n",
        "Check if MFA is installed correctly:\n",
        "```bash\n",
        "conda run -n mfa_conda mfa version\n",
        "```\n",
        "\n",
        "Should output: `3.3.9`\n",
        "\n",
        "### 7. Download Pre-trained Models\n",
        "\n",
        "Download the English dictionary:\n",
        "```bash\n",
        "conda run -n mfa_conda mfa model download dictionary english_us_arpa\n",
        "```\n",
        "\n",
        "Download the acoustic model:\n",
        "```bash\n",
        "conda run -n mfa_conda mfa model download acoustic english_us_arpa\n",
        "```\n",
        "\n",
        "Verify downloads:\n",
        "```bash\n",
        "conda run -n mfa_conda mfa model list dictionary\n",
        "conda run -n mfa_conda mfa model list acoustic\n",
        "```\n",
        "\n",
        "Both should show `english_us_arpa` in the list.\n",
        "\n",
        "## Preparing Your Data\n",
        "\n",
        "### Folder Structure\n",
        "\n",
        "Create a corpus folder with your audio and transcript files:\n",
        "```bash\n",
        "mkdir -p /content/mfa_data/corpus\n",
        "```\n",
        "\n",
        "Copy your files so each audio has a matching transcript:\n",
        "```\n",
        "corpus/\n",
        "├── file1.wav\n",
        "├── file1.txt\n",
        "├── file2.wav\n",
        "├── file2.txt\n",
        "...\n",
        "```\n",
        "\n",
        "**Important:** File names must match exactly (same name, different extension).\n",
        "\n",
        "### Transcript Format\n",
        "\n",
        "Text files should contain plain text of what's spoken. Remove excessive punctuation if you get OOV errors.\n",
        "\n",
        "## Running Basic Alignment\n",
        "```bash\n",
        "conda run -n mfa_conda mfa align \\\n",
        "  /content/mfa_data/corpus \\\n",
        "  english_us_arpa \\\n",
        "  english_us_arpa \\\n",
        "  /content/mfa_data/output\n",
        "```\n",
        "\n",
        "This takes 2-3 minutes for 6 files.\n",
        "\n",
        "## Handling OOV Words\n",
        "\n",
        "If you have OOV words (like proper names):\n",
        "\n",
        "Create a file `oov_pronunciations.txt` with ARPA phonemes:\n",
        "```\n",
        "HENNESSY HH EH1 N AH0 S IY0\n",
        "DUKAKIS D UW0 K AA1 K IH0 S\n",
        "```\n",
        "\n",
        "Then merge with base dictionary and re-run alignment with the custom dictionary.\n",
        "\n",
        "## Common Problems\n",
        "\n",
        "**\"kalpy module not found\"** - Use conda, not pip\n",
        "\n",
        "**\"Terms of Service\" error** - Switch to conda-forge channel\n",
        "\n",
        "**Many OOV words** - Check for punctuation, proper names, acronyms\n",
        "\n",
        "**Python version issues** - MFA needs Python 3.10\n",
        "\n",
        "## Time Estimates\n",
        "\n",
        "- Installation: 5-10 minutes\n",
        "- Model downloads: 2-3 minutes\n",
        "- Alignment: 2-3 minutes per run\n",
        "EOF\n",
        "\n",
        "cat /content/drive/MyDrive/MFA_Assignment_LTRC/SETUP_INSTRUCTIONS.md"
      ],
      "metadata": {
        "id": "MFDEXjrLVFl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cat > /content/drive/MyDrive/MFA_Assignment_LTRC/SETUP_INSTRUCTIONS.md << 'EOF'\n",
        "# Setup Instructions for Montreal Forced Aligner\n",
        "\n",
        "These are the exact steps I followed to install and run MFA on Google Colab. Should work on any Ubuntu system.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Ubuntu Linux (or Google Colab)\n",
        "- Internet connection\n",
        "- Sudo access (for installing packages)\n",
        "\n",
        "## Step-by-Step Installation\n",
        "\n",
        "### 1. Install Python 3.10\n",
        "\n",
        "MFA doesn't work with Python 3.12, so we need 3.10 specifically.\n",
        "```bash\n",
        "sudo apt-get update -qq\n",
        "sudo apt-get install -y python3.10 python3.10-venv python3.10-dev\n",
        "```\n",
        "\n",
        "### 2. Install Miniconda\n",
        "\n",
        "Download and install Miniconda (lightweight conda):\n",
        "```bash\n",
        "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n",
        "bash miniconda.sh -b -p /content/miniconda\n",
        "```\n",
        "\n",
        "Add conda to your path:\n",
        "```bash\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "```\n",
        "\n",
        "### 3. Configure Conda Channels\n",
        "\n",
        "Remove default channels (they require TOS acceptance) and use conda-forge:\n",
        "```bash\n",
        "conda config --remove channels defaults\n",
        "conda config --add channels conda-forge\n",
        "conda config --set channel_priority strict\n",
        "```\n",
        "\n",
        "### 4. Create Conda Environment\n",
        "\n",
        "Create an environment specifically for MFA with Python 3.10:\n",
        "```bash\n",
        "conda create -n mfa_conda python=3.10 -y\n",
        "```\n",
        "\n",
        "### 5. Install Montreal Forced Aligner\n",
        "\n",
        "Install MFA through conda (this is important - pip won't work):\n",
        "```bash\n",
        "conda install -n mfa_conda -c conda-forge montreal-forced-aligner -y\n",
        "```\n",
        "\n",
        "This takes 2-3 minutes. It installs MFA and all dependencies including Kaldi.\n",
        "\n",
        "### 6. Verify Installation\n",
        "\n",
        "Check if MFA is installed correctly:\n",
        "```bash\n",
        "conda run -n mfa_conda mfa version\n",
        "```\n",
        "\n",
        "Should output: `3.3.9`\n",
        "\n",
        "### 7. Download Pre-trained Models\n",
        "\n",
        "Download the English dictionary:\n",
        "```bash\n",
        "conda run -n mfa_conda mfa model download dictionary english_us_arpa\n",
        "```\n",
        "\n",
        "Download the acoustic model:\n",
        "```bash\n",
        "conda run -n mfa_conda mfa model download acoustic english_us_arpa\n",
        "```\n",
        "\n",
        "Verify downloads:\n",
        "```bash\n",
        "conda run -n mfa_conda mfa model list dictionary\n",
        "conda run -n mfa_conda mfa model list acoustic\n",
        "```\n",
        "\n",
        "Both should show `english_us_arpa` in the list.\n",
        "\n",
        "## Preparing Your Data\n",
        "\n",
        "### Folder Structure\n",
        "\n",
        "Create a corpus folder with your audio and transcript files:\n",
        "```bash\n",
        "mkdir -p /content/mfa_data/corpus\n",
        "```\n",
        "\n",
        "Copy your files so each audio has a matching transcript:\n",
        "```\n",
        "corpus/\n",
        "├── file1.wav\n",
        "├── file1.txt\n",
        "├── file2.wav\n",
        "├── file2.txt\n",
        "...\n",
        "```\n",
        "\n",
        "**Important:** File names must match exactly (same name, different extension).\n",
        "\n",
        "### Transcript Format\n",
        "\n",
        "Text files should contain plain text of what's spoken. Remove excessive punctuation if you get OOV errors.\n",
        "\n",
        "## Running Basic Alignment\n",
        "```bash\n",
        "conda run -n mfa_conda mfa align \\\n",
        "  /content/mfa_data/corpus \\\n",
        "  english_us_arpa \\\n",
        "  english_us_arpa \\\n",
        "  /content/mfa_data/output\n",
        "```\n",
        "\n",
        "This takes 2-3 minutes for 6 files.\n",
        "\n",
        "## Handling OOV Words\n",
        "\n",
        "If you have OOV words (like proper names):\n",
        "\n",
        "Create a file `oov_pronunciations.txt` with ARPA phonemes:\n",
        "```\n",
        "HENNESSY HH EH1 N AH0 S IY0\n",
        "DUKAKIS D UW0 K AA1 K IH0 S\n",
        "```\n",
        "\n",
        "Then merge with base dictionary and re-run alignment with the custom dictionary.\n",
        "\n",
        "## Common Problems\n",
        "\n",
        "**\"kalpy module not found\"** - Use conda, not pip\n",
        "\n",
        "**\"Terms of Service\" error** - Switch to conda-forge channel\n",
        "\n",
        "**Many OOV words** - Check for punctuation, proper names, acronyms\n",
        "\n",
        "**Python version issues** - MFA needs Python 3.10\n",
        "\n",
        "## Time Estimates\n",
        "\n",
        "- Installation: 5-10 minutes\n",
        "- Model downloads: 2-3 minutes\n",
        "- Alignment: 2-3 minutes per run\n",
        "EOF\n",
        "\n",
        "cat /content/drive/MyDrive/MFA_Assignment_LTRC/SETUP_INSTRUCTIONS.md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "K9K2ViGCVcjL",
        "outputId": "9765b276-cd64-495c-b2d6-3337629f76ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "bash: line 1: /content/drive/MyDrive/MFA_Assignment_LTRC/SETUP_INSTRUCTIONS.md: No such file or directory\n",
            "cat: /content/drive/MyDrive/MFA_Assignment_LTRC/SETUP_INSTRUCTIONS.md: No such file or directory\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'b'cat > /content/drive/MyDrive/MFA_Assignment_LTRC/SETUP_INSTRUCTIONS.md << \\'EOF\\'\\n# Setup Instructions for Montreal Forced Aligner\\n\\nThese are the exact steps I followed to install and run MFA on Google Colab. Should work on any Ubuntu system.\\n\\n## Prerequisites\\n\\n- Ubuntu Linux (or Google Colab)\\n- Internet connection\\n- Sudo access (for installing packages)\\n\\n## Step-by-Step Installation\\n\\n### 1. Install Python 3.10\\n\\nMFA doesn\\'t work with Python 3.12, so we need 3.10 specifically.\\n```bash\\nsudo apt-get update -qq\\nsudo apt-get install -y python3.10 python3.10-venv python3.10-dev\\n```\\n\\n### 2. Install Miniconda\\n\\nDownload and install Miniconda (lightweight conda):\\n```bash\\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\\nbash miniconda.sh -b -p /content/miniconda\\n```\\n\\nAdd conda to your path:\\n```bash\\nexport PATH=\"/content/miniconda/bin:$PATH\"\\n```\\n\\n### 3. Configure Conda Channels\\n\\nRemove default channels (they require TOS acceptance) and use conda-forge:\\n```bash\\nconda config --remove channels defaults\\nconda config --add channels conda-forge\\nconda config --set channel_priority strict\\n```\\n\\n### 4. Create Conda Environment\\n\\nCreate an environment specifically for MFA with Python 3.10:\\n```bash\\nconda create -n mfa_conda python=3.10 -y\\n```\\n\\n### 5. Install Montreal Forced Aligner\\n\\nInstall MFA through conda (this is important - pip won\\'t work):\\n```bash\\nconda install -n mfa_conda -c conda-forge montreal-forced-aligner -y\\n```\\n\\nThis takes 2-3 minutes. It installs MFA and all dependencies including Kaldi.\\n\\n### 6. Verify Installation\\n\\nCheck if MFA is installed correctly:\\n```bash\\nconda run -n mfa_conda mfa version\\n```\\n\\nShould output: `3.3.9`\\n\\n### 7. Download Pre-trained Models\\n\\nDownload the English dictionary:\\n```bash\\nconda run -n mfa_conda mfa model download dictionary english_us_arpa\\n```\\n\\nDownload the acoustic model:\\n```bash\\nconda run -n mfa_conda mfa model download acoustic english_us_arpa\\n```\\n\\nVerify downloads:\\n```bash\\nconda run -n mfa_conda mfa model list dictionary\\nconda run -n mfa_conda mfa model list acoustic\\n```\\n\\nBoth should show `english_us_arpa` in the list.\\n\\n## Preparing Your Data\\n\\n### Folder Structure\\n\\nCreate a corpus folder with your audio and transcript files:\\n```bash\\nmkdir -p /content/mfa_data/corpus\\n```\\n\\nCopy your files so each audio has a matching transcript:\\n```\\ncorpus/\\n\\xe2\\x94\\x9c\\xe2\\x94\\x80\\xe2\\x94\\x80 file1.wav\\n\\xe2\\x94\\x9c\\xe2\\x94\\x80\\xe2\\x94\\x80 file1.txt\\n\\xe2\\x94\\x9c\\xe2\\x94\\x80\\xe2\\x94\\x80 file2.wav\\n\\xe2\\x94\\x9c\\xe2\\x94\\x80\\xe2\\x94\\x80 file2.txt\\n...\\n```\\n\\n**Important:** File names must match exactly (same name, different extension).\\n\\n### Transcript Format\\n\\nText files should contain plain text of what\\'s spoken. Remove excessive punctuation if you get OOV errors.\\n\\n## Running Basic Alignment\\n```bash\\nconda run -n mfa_conda mfa align \\\\\\n  /content/mfa_data/corpus \\\\\\n  english_us_arpa \\\\\\n  english_us_arpa \\\\\\n  /content/mfa_data/output\\n```\\n\\nThis takes 2-3 minutes for 6 files.\\n\\n## Handling OOV Words\\n\\nIf you have OOV words (like proper names):\\n\\nCreate a file `oov_pronunciations.txt` with ARPA phonemes:\\n```\\nHENNESSY HH EH1 N AH0 S IY0\\nDUKAKIS D UW0 K AA1 K IH0 S\\n```\\n\\nThen merge with base dictionary and re-run alignment with the custom dictionary.\\n\\n## Common Problems\\n\\n**\"kalpy module not found\"** - Use conda, not pip\\n\\n**\"Terms of Service\" error** - Switch to conda-forge channel\\n\\n**Many OOV words** - Check for punctuation, proper names, acronyms\\n\\n**Python version issues** - MFA needs Python 3.10\\n\\n## Time Estimates\\n\\n- Installation: 5-10 minutes\\n- Model downloads: 2-3 minutes\\n- Alignment: 2-3 minutes per run\\nEOF\\n\\ncat /content/drive/MyDrive/MFA_Assignment_LTRC/SETUP_INSTRUCTIONS.md\\n'' returned non-zero exit status 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1810186490.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cat > /content/drive/MyDrive/MFA_Assignment_LTRC/SETUP_INSTRUCTIONS.md << \\'EOF\\'\\n# Setup Instructions for Montreal Forced Aligner\\n\\nThese are the exact steps I followed to install and run MFA on Google Colab. Should work on any Ubuntu system.\\n\\n## Prerequisites\\n\\n- Ubuntu Linux (or Google Colab)\\n- Internet connection\\n- Sudo access (for installing packages)\\n\\n## Step-by-Step Installation\\n\\n### 1. Install Python 3.10\\n\\nMFA doesn\\'t work with Python 3.12, so we need 3.10 specifically.\\n```bash\\nsudo apt-get update -qq\\nsudo apt-get install -y python3.10 python3.10-venv python3.10-dev\\n```\\n\\n### 2. Install Miniconda\\n\\nDownload and install Miniconda (lightweight conda):\\n```bash\\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\\nbash miniconda.sh -b -p /content/miniconda\\n```\\n\\nAdd conda to your path:\\n```bash\\nexport PATH=\"/content/miniconda/bin:$PATH\"\\n```\\n\\n### 3. Configure Conda Channels\\n\\nRemove default channels (they require TOS acceptance) and use conda-forge:\\n```bash\\nconda config --remove channels defaults\\nconda config --add channels conda-forge\\nconda config --set channel_priority strict\\n```\\n\\n### 4. Create Conda Environment\\n\\nCreate an environment specifically for MFA with Python 3.10:\\n```bash\\nconda create -n mfa_conda python=3.10 -...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'cat > /content/drive/MyDrive/MFA_Assignment_LTRC/SETUP_INSTRUCTIONS.md << \\'EOF\\'\\n# Setup Instructions for Montreal Forced Aligner\\n\\nThese are the exact steps I followed to install and run MFA on Google Colab. Should work on any Ubuntu system.\\n\\n## Prerequisites\\n\\n- Ubuntu Linux (or Google Colab)\\n- Internet connection\\n- Sudo access (for installing packages)\\n\\n## Step-by-Step Installation\\n\\n### 1. Install Python 3.10\\n\\nMFA doesn\\'t work with Python 3.12, so we need 3.10 specifically.\\n```bash\\nsudo apt-get update -qq\\nsudo apt-get install -y python3.10 python3.10-venv python3.10-dev\\n```\\n\\n### 2. Install Miniconda\\n\\nDownload and install Miniconda (lightweight conda):\\n```bash\\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\\nbash miniconda.sh -b -p /content/miniconda\\n```\\n\\nAdd conda to your path:\\n```bash\\nexport PATH=\"/content/miniconda/bin:$PATH\"\\n```\\n\\n### 3. Configure Conda Channels\\n\\nRemove default channels (they require TOS acceptance) and use conda-forge:\\n```bash\\nconda config --remove channels defaults\\nconda config --add channels conda-forge\\nconda config --set channel_priority strict\\n```\\n\\n### 4. Create Conda Environment\\n\\nCreate an environment specifically for MFA with Python 3.10:\\n```bash\\nconda create -n mfa_conda python=3.10 -y\\n```\\n\\n### 5. Install Montreal Forced Aligner\\n\\nInstall MFA through conda (this is important - pip won\\'t work):\\n```bash\\nconda ..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la /content/drive/MyDrive/ | grep MFA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "9kTYyy_OVoLV",
        "outputId": "389a21ce-29b0-4bba-da47-2fcd926b8dbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/bin/bash'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2834515086.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls -la /content/drive/MyDrive/ | grep MFA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    190\u001b[0m       \u001b[0;31m# TODO(b/115531839): Ensure that subprocesses are terminated upon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m       \u001b[0;31m# interrupt.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m       p = subprocess.Popen(\n\u001b[0m\u001b[1;32m    193\u001b[0m           \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m           \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1024\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m   1027\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1953\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merr_filename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1956\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/bin/bash'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "6vkGNC2-V17K",
        "outputId": "89e45f4e-af69-4dda-a9bf-c0b3a1c7b6ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EOF",
          "evalue": "End Of File (EOF).\n<pexpect.popen_spawn.PopenSpawn object at 0x7841f2c7d430>\nsearcher: searcher_re:\n    0: re.compile('root@0f72ba579b59-0b929dff004046fea069b4cc93d85427: ')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOF\u001b[0m                                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    176\u001b[0m   )\n\u001b[1;32m    177\u001b[0m   \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'unset HISTFILE; export PS1=\"{prompt}\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m   \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# The new prompt.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   \u001b[0mdrive_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opt/google/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m   \u001b[0;31m# Robustify to previously-running copies of drive. Don't only [pkill -9]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect\u001b[0;34m(self, pattern, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mcompiled_pattern_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_pattern_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         return self.expect_list(compiled_pattern_list,\n\u001b[0m\u001b[1;32m    355\u001b[0m                 timeout, searchwindowsize, async_)\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexpect_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     def expect_exact(self, pattern_list, timeout=-1, searchwindowsize=-1,\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mEOF\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTIMEOUT\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36meof\u001b[0;34m(self, err)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEOF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;31m# in Python 3.x we can use \"raise exc from None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEOF\u001b[0m: End Of File (EOF).\n<pexpect.popen_spawn.PopenSpawn object at 0x7841f2c7d430>\nsearcher: searcher_re:\n    0: re.compile('root@0f72ba579b59-0b929dff004046fea069b4cc93d85427: ')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "xPZpZ-F6WJRl",
        "outputId": "3a56d2af-69cf-48ff-9e9c-35c54bf011df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/bin/bash'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3983348904.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls /content/drive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    190\u001b[0m       \u001b[0;31m# TODO(b/115531839): Ensure that subprocesses are terminated upon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m       \u001b[0;31m# interrupt.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m       p = subprocess.Popen(\n\u001b[0m\u001b[1;32m    193\u001b[0m           \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m           \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[1;32m   1024\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m   1027\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[0m\n\u001b[1;32m   1953\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merr_filename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1956\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/bin/bash'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "tlc7SOnKWlr2",
        "outputId": "c1644b1d-f933-4ac3-c878-b44f24525bcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EOF",
          "evalue": "End Of File (EOF).\n<pexpect.popen_spawn.PopenSpawn object at 0x7cf52c56a5a0>\nsearcher: searcher_re:\n    0: re.compile('root@0f72ba579b59-0861c948120a4c9ba72c19f49845926a: ')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEOF\u001b[0m                                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    176\u001b[0m   )\n\u001b[1;32m    177\u001b[0m   \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'unset HISTFILE; export PS1=\"{prompt}\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m   \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# The new prompt.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   \u001b[0mdrive_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'opt/google/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m   \u001b[0;31m# Robustify to previously-running copies of drive. Don't only [pkill -9]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect\u001b[0;34m(self, pattern, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mcompiled_pattern_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_pattern_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m         return self.expect_list(compiled_pattern_list,\n\u001b[0m\u001b[1;32m    355\u001b[0m                 timeout, searchwindowsize, async_)\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexpect_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     def expect_exact(self, pattern_list, timeout=-1, searchwindowsize=-1,\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mEOF\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTIMEOUT\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36meof\u001b[0;34m(self, err)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEOF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;31m# in Python 3.x we can use \"raise exc from None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEOF\u001b[0m: End Of File (EOF).\n<pexpect.popen_spawn.PopenSpawn object at 0x7cf52c56a5a0>\nsearcher: searcher_re:\n    0: re.compile('root@0f72ba579b59-0861c948120a4c9ba72c19f49845926a: ')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56S2NiblXBwc",
        "outputId": "796a916e-7ddc-4cda-8c80-ee8e7f92b888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/ | grep MFA"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8dlm7rbXOgx",
        "outputId": "1d3ac625-0366-4621-8a48-47508479b409"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MFA_Assignment_LTRC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat > /content/drive/MyDrive/MFA_Assignment_LTRC/SETUP_INSTRUCTIONS.md << 'EOF'\n",
        "# Setup Instructions for Montreal Forced Aligner\n",
        "\n",
        "These are the exact steps I followed to install and run MFA on Google Colab.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Ubuntu Linux (or Google Colab)\n",
        "- Internet connection\n",
        "- Sudo access\n",
        "\n",
        "## Installation Steps\n",
        "\n",
        "### 1. Install Python 3.10\n",
        "\n",
        "MFA doesn't work with Python 3.12, so we need 3.10.\n",
        "```bash\n",
        "sudo apt-get update -qq\n",
        "sudo apt-get install -y python3.10 python3.10-venv python3.10-dev\n",
        "```\n",
        "\n",
        "### 2. Install Miniconda\n",
        "```bash\n",
        "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n",
        "bash miniconda.sh -b -p /content/miniconda\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "```\n",
        "\n",
        "### 3. Configure Conda\n",
        "```bash\n",
        "conda config --remove channels defaults\n",
        "conda config --add channels conda-forge\n",
        "conda config --set channel_priority strict\n",
        "```\n",
        "\n",
        "### 4. Create Environment\n",
        "```bash\n",
        "conda create -n mfa_conda python=3.10 -y\n",
        "```\n",
        "\n",
        "### 5. Install MFA\n",
        "```bash\n",
        "conda install -n mfa_conda -c conda-forge montreal-forced-aligner -y\n",
        "```\n",
        "\n",
        "### 6. Verify Installation\n",
        "```bash\n",
        "conda run -n mfa_conda mfa version\n",
        "```\n",
        "\n",
        "Should show: 3.3.9\n",
        "\n",
        "### 7. Download Models\n",
        "```bash\n",
        "conda run -n mfa_conda mfa model download dictionary english_us_arpa\n",
        "conda run -n mfa_conda mfa model download acoustic english_us_arpa\n",
        "```\n",
        "\n",
        "## Running Alignment\n",
        "\n",
        "Basic command:\n",
        "```bash\n",
        "conda run -n mfa_conda mfa align \\\n",
        "  /path/to/corpus \\\n",
        "  english_us_arpa \\\n",
        "  english_us_arpa \\\n",
        "  /path/to/output\n",
        "```\n",
        "\n",
        "## Handling OOV Words\n",
        "\n",
        "Create oov_pronunciations.txt with phonetic transcriptions, then merge with base dictionary.\n",
        "\n",
        "## Common Issues\n",
        "\n",
        "- kalpy error: Use conda not pip\n",
        "- TOS error: Use conda-forge channel\n",
        "- Python version: Must use 3.10\n",
        "EOF\n",
        "\n",
        "!cat /content/drive/MyDrive/MFA_Assignment_LTRC/SETUP_INSTRUCTIONS.md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "SiznciXGXbuC",
        "outputId": "b0f69c25-81b4-486f-b7ed-db29e2831fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unterminated string literal (detected at line 16) (ipython-input-1372095685.py, line 16)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1372095685.py\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    MFA doesn't work with Python 3.12, so we need 3.10.\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "setup_content = \"\"\"# Setup Instructions for Montreal Forced Aligner\n",
        "\n",
        "These are the exact steps I followed to install and run MFA on Google Colab.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Ubuntu Linux (or Google Colab)\n",
        "- Internet connection\n",
        "- Sudo access\n",
        "\n",
        "## Installation Steps\n",
        "\n",
        "### 1. Install Python 3.10\n",
        "\n",
        "MFA does not work with Python 3.12, so we need 3.10.\n",
        "```bash\n",
        "sudo apt-get update -qq\n",
        "sudo apt-get install -y python3.10 python3.10-venv python3.10-dev\n",
        "```\n",
        "\n",
        "### 2. Install Miniconda\n",
        "```bash\n",
        "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n",
        "bash miniconda.sh -b -p /content/miniconda\n",
        "export PATH=\"/content/miniconda/bin:$PATH\"\n",
        "```\n",
        "\n",
        "### 3. Configure Conda\n",
        "```bash\n",
        "conda config --remove channels defaults\n",
        "conda config --add channels conda-forge\n",
        "conda config --set channel_priority strict\n",
        "```\n",
        "\n",
        "### 4. Create Environment\n",
        "```bash\n",
        "conda create -n mfa_conda python=3.10 -y\n",
        "```\n",
        "\n",
        "### 5. Install MFA\n",
        "```bash\n",
        "conda install -n mfa_conda -c conda-forge montreal-forced-aligner -y\n",
        "```\n",
        "\n",
        "Takes 2-3 minutes. Installs MFA and Kaldi dependencies.\n",
        "\n",
        "### 6. Verify Installation\n",
        "```bash\n",
        "conda run -n mfa_conda mfa version\n",
        "```\n",
        "\n",
        "Should output: 3.3.9\n",
        "\n",
        "### 7. Download Models\n",
        "```bash\n",
        "conda run -n mfa_conda mfa model download dictionary english_us_arpa\n",
        "conda run -n mfa_conda mfa model download acoustic english_us_arpa\n",
        "```\n",
        "\n",
        "## Data Preparation\n",
        "\n",
        "Create corpus folder with matching wav and txt files:\n",
        "```\n",
        "corpus/\n",
        "├── file1.wav\n",
        "├── file1.txt\n",
        "├── file2.wav\n",
        "├── file2.txt\n",
        "```\n",
        "\n",
        "File names must match exactly.\n",
        "\n",
        "## Running Alignment\n",
        "```bash\n",
        "conda run -n mfa_conda mfa align \\\\\n",
        "  /path/to/corpus \\\\\n",
        "  english_us_arpa \\\\\n",
        "  english_us_arpa \\\\\n",
        "  /path/to/output\n",
        "```\n",
        "\n",
        "## Handling OOV Words\n",
        "\n",
        "1. Run validation to find OOV words\n",
        "2. Create oov_pronunciations.txt with ARPA phonemes\n",
        "3. Merge with base dictionary\n",
        "4. Re-run alignment with custom dictionary\n",
        "\n",
        "## Common Issues\n",
        "\n",
        "**kalpy module not found** - Use conda installation, not pip\n",
        "\n",
        "**Terms of Service error** - Switch to conda-forge channel\n",
        "\n",
        "**Python version error** - MFA requires Python 3.10\n",
        "\n",
        "**OOV words** - Create custom pronunciations using ARPA phoneme set\n",
        "\n",
        "## Time Estimates\n",
        "\n",
        "- Installation: 5-10 minutes\n",
        "- Model downloads: 2-3 minutes\n",
        "- Alignment (6 files): 2-3 minutes\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/drive/MyDrive/MFA_Assignment_LTRC/SETUP_INSTRUCTIONS.md', 'w') as f:\n",
        "    f.write(setup_content)\n",
        "\n",
        "print(\"SETUP_INSTRUCTIONS.md created!\")\n",
        "print(\"\\nFirst 30 lines:\")\n",
        "with open('/content/drive/MyDrive/MFA_Assignment_LTRC/SETUP_INSTRUCTIONS.md', 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    print(''.join(lines[:30]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhtYJxEQXnO2",
        "outputId": "ff88f77e-6aa3-4b1c-8b9c-95fa5c4b927e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SETUP_INSTRUCTIONS.md created!\n",
            "\n",
            "First 30 lines:\n",
            "# Setup Instructions for Montreal Forced Aligner\n",
            "\n",
            "These are the exact steps I followed to install and run MFA on Google Colab.\n",
            "\n",
            "## Prerequisites\n",
            "\n",
            "- Ubuntu Linux (or Google Colab)\n",
            "- Internet connection\n",
            "- Sudo access\n",
            "\n",
            "## Installation Steps\n",
            "\n",
            "### 1. Install Python 3.10\n",
            "\n",
            "MFA does not work with Python 3.12, so we need 3.10.\n",
            "```bash\n",
            "sudo apt-get update -qq\n",
            "sudo apt-get install -y python3.10 python3.10-venv python3.10-dev\n",
            "```\n",
            "\n",
            "### 2. Install Miniconda\n",
            "```bash\n",
            "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n",
            "bash miniconda.sh -b -p /content/miniconda\n",
            "export PATH=\"/content/miniconda/bin:$PATH\"\n",
            "```\n",
            "\n",
            "### 3. Configure Conda\n",
            "```bash\n",
            "conda config --remove channels defaults\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/drive/MyDrive/MFA_Assignment_LTRC/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asEJCHDfXuHL",
        "outputId": "393b0b62-5b1f-4630-dd84-63085b77db7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 26K\n",
            "-rw------- 1 root root 7.7K Feb  6 18:26 ASSIGNMENT_SUMMARY.md\n",
            "drwx------ 2 root root 4.0K Feb  6 18:19 outputs\n",
            "-rw------- 1 root root 3.4K Feb  6 18:39 README.md\n",
            "-rw------- 1 root root 2.2K Feb  7 04:31 SETUP_INSTRUCTIONS.md\n",
            "drwx------ 2 root root 4.0K Feb  6 17:13 transcripts\n",
            "drwx------ 2 root root 4.0K Feb  6 17:13 wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la /content/drive/MyDrive/MFA_Assignment_LTRC/outputs/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhYIIIqFX1NY",
        "outputId": "59f25c4e-2dbe-49b8-91a9-b58490f3d315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 9\n",
            "drwx------ 2 root root 4096 Feb  6 18:19 after_oov\n",
            "drwx------ 2 root root 4096 Feb  6 18:19 before_oov\n",
            "-rw------- 1 root root  232 Feb  6 18:19 oov_pronunciations.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import files\n",
        "files.download('/content/drive/MyDrive/MFA_Assignment_LTRC/outputs/before_oov/F2BJRLP1.TextGrid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "P2t5RCiGZb8f",
        "outputId": "a2616652-26cf-4cc6-ac6a-893e59625387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e1f19dec-a51e-49d0-a6e9-1d41a566784a\", \"F2BJRLP1.TextGrid\", 39164)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "files.download('/content/drive/MyDrive/MFA_Assignment_LTRC/outputs/after_oov/F2BJRLP1.TextGrid')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Pnuxp9CRZkCX",
        "outputId": "5743569f-2a6b-49ad-c683-1b9022b1c153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_135f36cd-8ba6-4542-b328-95fa5b91bd73\", \"F2BJRLP1.TextGrid\", 40666)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "files.download('/content/drive/MyDrive/MFA_Assignment_LTRC/wav/F2BJRLP1.wav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-k_rbmxJZnnv",
        "outputId": "66371f1d-54a1-4635-81e1-d27b677a9660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c07c3324-ef41-4995-a8b8-92f1193ec120\", \"F2BJRLP1.wav\", 810916)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Copy and rename before downloading\n",
        "shutil.copy('/content/drive/MyDrive/MFA_Assignment_LTRC/outputs/before_oov/F2BJRLP1.TextGrid',\n",
        "            '/content/F2BJRLP1_BEFORE.TextGrid')\n",
        "shutil.copy('/content/drive/MyDrive/MFA_Assignment_LTRC/outputs/after_oov/F2BJRLP1.TextGrid',\n",
        "            '/content/F2BJRLP1_AFTER.TextGrid')\n",
        "\n",
        "# Download both with different names\n",
        "files.download('/content/F2BJRLP1_BEFORE.TextGrid')\n",
        "files.download('/content/F2BJRLP1_AFTER.TextGrid')\n",
        "files.download('/content/drive/MyDrive/MFA_Assignment_LTRC/wav/F2BJRLP1.wav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "b8wJOkWucITn",
        "outputId": "f80c045e-5d3e-4408-d2ab-042a31581c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3f05aae1-3ed1-4e69-ba40-962f47b84026\", \"F2BJRLP1_BEFORE.TextGrid\", 39164)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_269ba12b-6109-4ec8-a6ec-fe1323153844\", \"F2BJRLP1_AFTER.TextGrid\", 40666)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_72f9888b-56f6-4755-829a-d106ca1a9d6f\", \"F2BJRLP1.wav\", 810916)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload your screenshots\n",
        "print(\"Upload Dukasis_before_OOV.png:\")\n",
        "uploaded1 = files.upload()\n",
        "\n",
        "print(\"\\nUpload Dukasis_after_OOV.png:\")\n",
        "uploaded2 = files.upload()\n",
        "\n",
        "# Move to Google Drive\n",
        "!mkdir -p /content/drive/MyDrive/MFA_Assignment_LTRC/praat_analysis\n",
        "!cp Dukasis_before_OOV.png /content/drive/MyDrive/MFA_Assignment_LTRC/praat_analysis/\n",
        "!cp Dukasis_after_OOV.png /content/drive/MyDrive/MFA_Assignment_LTRC/praat_analysis/\n",
        "\n",
        "print(\"\\nScreenshots saved to Google Drive!\")\n",
        "!ls /content/drive/MyDrive/MFA_Assignment_LTRC/praat_analysis/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "wBKM4sWefAFY",
        "outputId": "e986615d-e02e-48fa-a1bd-0a15a5828403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload Dukasis_before_OOV.png:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-336c8827-8af4-483c-b739-9c3108e23ecd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-336c8827-8af4-483c-b739-9c3108e23ecd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Dukasis_before_OOV.png to Dukasis_before_OOV.png\n",
            "\n",
            "Upload Dukasis_after_OOV.png:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-28df0d91-6ac4-4659-84c8-313bf069584d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-28df0d91-6ac4-4659-84c8-313bf069584d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Dukasis_after_OOV.png to Dukasis_after_OOV.png\n",
            "\n",
            "Screenshots saved to Google Drive!\n",
            "Dukasis_after_OOV.png  Dukasis_before_OOV.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "praat_section = \"\"\"\n",
        "\n",
        "## Praat Analysis and Visualization\n",
        "\n",
        "### Methodology\n",
        "I used Praat software to visually inspect and compare the alignment quality before and after OOV handling. I focused on the word \"Dukakis\" (a proper name that was identified as OOV) in the file F2BJRLP1.\n",
        "\n",
        "### Key Findings\n",
        "\n",
        "#### Before OOV Handling\n",
        "When analyzing the BEFORE alignment in Praat, I observed:\n",
        "- The word \"Dukakis\" appears in the word tier\n",
        "- However, in the phoneme tier below, it shows only \"spn\" (spoken noise)\n",
        "- This indicates MFA could not properly align the phonemes because the word was not in the dictionary\n",
        "- The system treated it as unrecognizable speech rather than a proper word\n",
        "\n",
        "**Screenshot:** See `praat_analysis/Dukasis_before_OOV.png`\n",
        "\n",
        "#### After OOV Handling\n",
        "After adding custom pronunciation (DUKAKIS D UW0 K AA1 K IH0 S) to the dictionary:\n",
        "- The word \"Dukakis\" appears correctly in the word tier\n",
        "- The phoneme tier now shows individual phonemes: D, UW, K, AA, K, IH, S\n",
        "- Each phoneme has precise timing boundaries\n",
        "- The alignment matches the actual pronunciation\n",
        "\n",
        "**Screenshot:** See `praat_analysis/Dukasis_after_OOV.png`\n",
        "\n",
        "### Visual Comparison\n",
        "The Praat visualization clearly shows:\n",
        "- **Waveform** (top): Audio amplitude over time\n",
        "- **Spectrogram** (middle): Frequency content showing formants and sound characteristics\n",
        "- **Word tier**: Word-level segmentation\n",
        "- **Phoneme tier**: Phoneme-level segmentation with timing\n",
        "\n",
        "The improvement is dramatic - going from a generic \"spn\" marker to detailed phoneme-by-phoneme alignment.\n",
        "\n",
        "### Impact of OOV Handling\n",
        "This visual analysis confirms that handling OOV words significantly improves alignment quality:\n",
        "1. Proper names and specialized terms get accurate phonetic transcriptions\n",
        "2. Phoneme boundaries become precise instead of being lumped as \"spoken noise\"\n",
        "3. The resulting TextGrids are much more useful for downstream applications like speech synthesis or phonetic research\n",
        "\n",
        "### Other Observations\n",
        "- Words that were already in the dictionary (like \"appointment\", \"important\") showed good alignment even before OOV handling\n",
        "- The spectrogram visualization helps verify that phoneme boundaries align with actual acoustic changes\n",
        "- Praat's visual interface makes it easy to spot alignment errors and verify improvements\n",
        "\"\"\"\n",
        "\n",
        "# Read existing summary\n",
        "with open('/content/drive/MyDrive/MFA_Assignment_LTRC/ASSIGNMENT_SUMMARY.md', 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# Add Praat section before \"What's Next?\" or at the end\n",
        "if \"What's Next?\" in content:\n",
        "    content = content.replace(\"What's Next?\", praat_section + \"\\n## What's Next?\")\n",
        "else:\n",
        "    content = content + praat_section\n",
        "\n",
        "# Write updated summary\n",
        "with open('/content/drive/MyDrive/MFA_Assignment_LTRC/ASSIGNMENT_SUMMARY.md', 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"ASSIGNMENT_SUMMARY.md updated with Praat analysis!\")\n",
        "print(\"\\nPreview of new section:\")\n",
        "print(praat_section[:500] + \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ny7uyRqfgGl",
        "outputId": "c730f175-8cd8-48e5-d34c-8d8bab63ca7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ASSIGNMENT_SUMMARY.md updated with Praat analysis!\n",
            "\n",
            "Preview of new section:\n",
            "\n",
            "\n",
            "## Praat Analysis and Visualization\n",
            "\n",
            "### Methodology\n",
            "I used Praat software to visually inspect and compare the alignment quality before and after OOV handling. I focused on the word \"Dukakis\" (a proper name that was identified as OOV) in the file F2BJRLP1.\n",
            "\n",
            "### Key Findings\n",
            "\n",
            "#### Before OOV Handling\n",
            "When analyzing the BEFORE alignment in Praat, I observed:\n",
            "- The word \"Dukakis\" appears in the word tier\n",
            "- However, in the phoneme tier below, it shows only \"spn\" (spoken noise)\n",
            "- This indicates MFA...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "readme_praat = \"\"\"\n",
        "\n",
        "## Viewing and Analyzing Results with Praat\n",
        "\n",
        "### Installing Praat\n",
        "\n",
        "1. Download Praat from: https://www.fon.hum.uva.nl/praat/\n",
        "2. Extract the downloaded file\n",
        "3. Run Praat.exe (Windows may show security warning - click \"More info\" then \"Run anyway\")\n",
        "\n",
        "### Opening TextGrids in Praat\n",
        "\n",
        "1. Open Praat (you'll see \"Praat Objects\" window)\n",
        "2. Click **Open** → **Read from file...**\n",
        "3. Select your audio file (e.g., F2BJRLP1.wav)\n",
        "4. Click **Open** → **Read from file...**\n",
        "5. Select the corresponding TextGrid file\n",
        "6. Select both files (hold Ctrl and click both)\n",
        "7. Click **View & Edit** button\n",
        "\n",
        "### What You'll See\n",
        "\n",
        "- **Top**: Waveform showing audio amplitude\n",
        "- **Middle**: Spectrogram showing frequency content\n",
        "- **Bottom tiers**:\n",
        "  - Tier 1: Word boundaries with timestamps\n",
        "  - Tier 2: Phoneme boundaries with individual sounds\n",
        "\n",
        "### Zooming for Detail\n",
        "\n",
        "The full audio is too long to see details. To zoom:\n",
        "- Click and drag on the waveform to select a region (5-10 seconds)\n",
        "- Click the **\"sel\"** button at the bottom to zoom to selection\n",
        "\n",
        "### Comparing Before and After OOV\n",
        "\n",
        "To see the improvement:\n",
        "1. Open the BEFORE TextGrid and note how OOV words show \"spn\" (spoken noise)\n",
        "2. Open the AFTER TextGrid and see proper phoneme boundaries for the same words\n",
        "\n",
        "Example: The word \"Dukakis\" goes from showing \"spn\" to showing \"D UW K AA K IH S\"\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/MFA_Assignment_LTRC/README.md', 'r') as f:\n",
        "    readme_content = f.read()\n",
        "\n",
        "\n",
        "if \"## Resources\" in readme_content:\n",
        "    readme_content = readme_content.replace(\"## Resources\", readme_praat + \"\\n## Resources\")\n",
        "else:\n",
        "    readme_content = readme_content + readme_praat\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/MFA_Assignment_LTRC/README.md', 'w') as f:\n",
        "    f.write(readme_content)\n",
        "\n",
        "print(\"README.md updated with Praat instructions!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX4CG-f0fnQ3",
        "outputId": "8ff28e93-56a3-4c90-a878-426fa5e663e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.md updated with Praat instructions!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "praat_setup = \"\"\"\n",
        "\n",
        "## Installing and Using Praat (for Analysis)\n",
        "\n",
        "### Download and Install\n",
        "\n",
        "1. Go to https://www.fon.hum.uva.nl/praat/\n",
        "2. Download the version for your operating system (Windows/Mac/Linux)\n",
        "3. Extract the downloaded file to a folder\n",
        "4. Run Praat.exe (or Praat application)\n",
        "\n",
        "**Note:** Windows may show a security warning. Click \"More info\" then \"Run anyway\" - Praat is safe software from University of Amsterdam.\n",
        "\n",
        "### Opening Files in Praat\n",
        "\n",
        "Once Praat opens, you'll see the \"Praat Objects\" window.\n",
        "\n",
        "To view alignment results:\n",
        "\n",
        "1. Click **Open** → **Read from file...**\n",
        "2. Navigate to your audio file (e.g., F2BJRLP1.wav) and open it\n",
        "3. Click **Open** → **Read from file...**\n",
        "4. Navigate to the TextGrid file (e.g., F2BJRLP1.TextGrid) and open it\n",
        "5. Select both files (click first one, hold Ctrl, click second one)\n",
        "6. Click **View & Edit** button\n",
        "\n",
        "### Understanding the Visualization\n",
        "\n",
        "You'll see three main areas:\n",
        "\n",
        "- **Waveform (top)**: Shows the audio signal amplitude over time\n",
        "- **Spectrogram (middle)**: Shows frequency content (darker = more energy at that frequency)\n",
        "- **Annotation tiers (bottom)**:\n",
        "  - Words tier: Shows word boundaries and labels\n",
        "  - Phones tier: Shows individual phoneme boundaries\n",
        "\n",
        "### Zoom to See Details\n",
        "\n",
        "The full recording is too long to see phoneme details. Zoom in:\n",
        "\n",
        "1. Click and drag on the waveform to select 5-10 seconds\n",
        "2. Click the **sel** button at bottom left\n",
        "3. Now you can see individual phonemes clearly\n",
        "\n",
        "### What to Look For\n",
        "\n",
        "**Good alignment:**\n",
        "- Phoneme boundaries align with visible changes in the spectrogram\n",
        "- Each phoneme has a clear label (like K, AA, T, etc.)\n",
        "\n",
        "**Poor alignment (OOV words before handling):**\n",
        "- Shows \"spn\" (spoken noise) instead of actual phonemes\n",
        "- Missing detailed timing information\n",
        "\n",
        "### Comparing Before and After\n",
        "\n",
        "Open both BEFORE and AFTER TextGrids with the same audio file to compare:\n",
        "- Look for proper names (Hennessy, Dukakis, etc.)\n",
        "- BEFORE: These show as \"spn\"\n",
        "- AFTER: These show detailed phoneme sequences\n",
        "\n",
        "This visual comparison clearly demonstrates the improvement from OOV handling.\n",
        "\"\"\"\n",
        "\n",
        "# Read current setup instructions\n",
        "with open('/content/drive/MyDrive/MFA_Assignment_LTRC/SETUP_INSTRUCTIONS.md', 'r') as f:\n",
        "    setup_content = f.read()\n",
        "\n",
        "# Add at the end\n",
        "setup_content = setup_content + \"\\n\" + praat_setup\n",
        "\n",
        "# Write updated file\n",
        "with open('/content/drive/MyDrive/MFA_Assignment_LTRC/SETUP_INSTRUCTIONS.md', 'w') as f:\n",
        "    f.write(setup_content)\n",
        "\n",
        "print(\"SETUP_INSTRUCTIONS.md updated with Praat setup!\")\n",
        "print(\"\\nAll documentation is now complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxLytw6xgCXB",
        "outputId": "fc4e2e67-7da7-4b62-e1bf-7131cc803695"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SETUP_INSTRUCTIONS.md updated with Praat setup!\n",
            "\n",
            "All documentation is now complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZQlUCQPXK2c",
        "outputId": "9e9bc120-7c0e-497d-cc30-e1532f357c16"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"=== README.md ===\"\n",
        "!wc -l /content/drive/MyDrive/MFA_Assignment_LTRC/README.md\n",
        "!echo \"\"\n",
        "!echo \"=== SETUP_INSTRUCTIONS.md ===\"\n",
        "!wc -l /content/drive/MyDrive/MFA_Assignment_LTRC/SETUP_INSTRUCTIONS.md\n",
        "!echo \"\"\n",
        "!echo \"=== ASSIGNMENT_SUMMARY.md ===\"\n",
        "!wc -l /content/drive/MyDrive/MFA_Assignment_LTRC/ASSIGNMENT_SUMMARY.md\n",
        "!echo \"\"\n",
        "!echo \"=== All files in your folder ===\"\n",
        "!ls -lh /content/drive/MyDrive/MFA_Assignment_LTRC/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi40ATinXVw9",
        "outputId": "8772b806-ca08-4ff4-8e64-bfa66871aec6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== README.md ===\n",
            "168 /content/drive/MyDrive/MFA_Assignment_LTRC/README.md\n",
            "\n",
            "=== SETUP_INSTRUCTIONS.md ===\n",
            "166 /content/drive/MyDrive/MFA_Assignment_LTRC/SETUP_INSTRUCTIONS.md\n",
            "\n",
            "=== ASSIGNMENT_SUMMARY.md ===\n",
            "224 /content/drive/MyDrive/MFA_Assignment_LTRC/ASSIGNMENT_SUMMARY.md\n",
            "\n",
            "=== All files in your folder ===\n",
            "total 36K\n",
            "-rw------- 1 root root 9.9K Feb  7 05:06 ASSIGNMENT_SUMMARY.md\n",
            "drwx------ 2 root root 4.0K Feb  6 18:19 outputs\n",
            "drwx------ 2 root root 4.0K Feb  7 05:04 praat_analysis\n",
            "-rw------- 1 root root 4.7K Feb  7 05:08 README.md\n",
            "-rw------- 1 root root  179 Feb  7 08:51 README.md.gdoc\n",
            "-rw------- 1 root root 4.2K Feb  7 05:09 SETUP_INSTRUCTIONS.md\n",
            "drwx------ 2 root root 4.0K Feb  6 17:13 transcripts\n",
            "drwx------ 2 root root 4.0K Feb  6 17:13 wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "readme_natural = \"\"\"# Forced Alignment with Montreal Forced Aligner\n",
        "\n",
        "I built an automatic speech alignment system using MFA that takes audio recordings and matches them with text transcripts at the word and phoneme level. Processed 6 audio files to get precise timing for every sound.\n",
        "\n",
        "## What It Does\n",
        "\n",
        "The system creates TextGrid files that show exactly when each word and sound happens in the audio. For example, if someone says \"wanted\" from 0.54-1.12 seconds, it breaks that down further - the \"W\" sound is at 0.54-0.60s, \"AH\" at 0.60-0.70s, and so on.\n",
        "\n",
        "## Dataset\n",
        "\n",
        "Worked with 6 audio files:\n",
        "- 3 news broadcasts about judicial appointments (F2BJRLP1-3)\n",
        "- 3 short speech discrimination samples (ISLE files)\n",
        "- Total: about 97 seconds of audio\n",
        "\n",
        "## The Main Problem: Missing Words\n",
        "\n",
        "When I first ran the alignment, the dictionary couldn't recognize 29 words. Most were:\n",
        "- Proper names like Hennessy, Dukakis, Melnicove, Maffy\n",
        "- Acronyms with punctuation: S.J.C.'s, WBUR's\n",
        "- Specialized terms: de-politicize\n",
        "\n",
        "I had to create phonetic pronunciations for these manually.\n",
        "\n",
        "## Getting Started\n",
        "\n",
        "See SETUP_INSTRUCTIONS.md for detailed installation steps.\n",
        "\n",
        "Quick overview:\n",
        "1. Install Python 3.10 (MFA breaks on 3.12)\n",
        "2. Set up Miniconda\n",
        "3. Create conda environment\n",
        "4. Install MFA via conda\n",
        "5. Download the english_us_arpa dictionary and acoustic model\n",
        "\n",
        "## Running the Alignment\n",
        "\n",
        "Basic usage:\n",
        "```bash\n",
        "conda run -n mfa_conda mfa align \\\\\n",
        "  /path/to/corpus \\\\\n",
        "  english_us_arpa \\\\\n",
        "  english_us_arpa \\\\\n",
        "  /path/to/output\n",
        "```\n",
        "\n",
        "With custom dictionary for OOV words:\n",
        "```bash\n",
        "conda run -n mfa_conda mfa align \\\\\n",
        "  /path/to/cleaned_corpus \\\\\n",
        "  /path/to/custom_dictionary.dict \\\\\n",
        "  english_us_arpa \\\\\n",
        "  /path/to/output\n",
        "```\n",
        "\n",
        "## Fixing Out-of-Vocabulary Words\n",
        "\n",
        "1. Run validation to identify which words are missing:\n",
        "```bash\n",
        "conda run -n mfa_conda mfa validate corpus english_us_arpa english_us_arpa\n",
        "```\n",
        "\n",
        "2. Create a pronunciations file using ARPA phonemes:\n",
        "```\n",
        "HENNESSY HH EH1 N AH0 S IY0\n",
        "DUKAKIS D UW0 K AA1 K IH0 S\n",
        "```\n",
        "\n",
        "3. Merge with the base dictionary and re-run alignment\n",
        "\n",
        "## Results\n",
        "\n",
        "Created two sets of outputs:\n",
        "- **before_oov/** - Initial alignment (some words failed)\n",
        "- **after_oov/** - Improved alignment with custom pronunciations\n",
        "\n",
        "The improvement was measurable. For example, F2BJRLP1.TextGrid went from 1,540 to 1,596 lines after adding OOV pronunciations - more detailed phoneme boundaries.\n",
        "\n",
        "## Project Structure\n",
        "```\n",
        "outputs/\n",
        "├── before_oov/           Baseline TextGrids\n",
        "├── after_oov/            Improved TextGrids\n",
        "└── oov_pronunciations.txt\n",
        "\n",
        "wav/                      Audio files\n",
        "transcripts/              Text transcripts\n",
        "praat_analysis/           Screenshots comparing before/after\n",
        "```\n",
        "\n",
        "## Tech Stack\n",
        "\n",
        "- Montreal Forced Aligner 3.3.9\n",
        "- Google Colab (for compute)\n",
        "- Python 3.10 via Miniconda\n",
        "- Pre-trained english_us_arpa models\n",
        "\n",
        "## Problems I Hit\n",
        "\n",
        "**Kaldi dependency errors**: Kept getting \"_kalpy module not found\". Turned out MFA needs conda installation, pip doesn't work.\n",
        "\n",
        "**Text preprocessing issues**: Punctuation like periods and apostrophes broke the alignment. Had to clean transcripts (S.J.C.'s became SJC).\n",
        "\n",
        "**Python version**: MFA doesn't support 3.12. Had to downgrade to 3.10.\n",
        "\n",
        "## Analyzing Results with Praat\n",
        "\n",
        "### Setup\n",
        "1. Download from https://www.fon.hum.uva.nl/praat/\n",
        "2. Extract and run Praat.exe (Windows might warn you - it's safe)\n",
        "\n",
        "### Viewing Alignments\n",
        "1. Open Praat\n",
        "2. Load audio file: Open → Read from file → select .wav\n",
        "3. Load TextGrid: Open → Read from file → select .TextGrid\n",
        "4. Select both, click \"View & Edit\"\n",
        "\n",
        "You'll see:\n",
        "- Waveform at top\n",
        "- Spectrogram in middle\n",
        "- Word tier and phoneme tier at bottom\n",
        "\n",
        "### Zoom In\n",
        "Click and drag to select 5-10 seconds, then click \"sel\" button to zoom.\n",
        "\n",
        "### Before vs After Comparison\n",
        "The difference is dramatic. In the BEFORE version, \"Dukakis\" shows up as \"spn\" (spoken noise) in the phoneme tier. In the AFTER version, it's properly segmented: D, UW, K, AA, K, IH, S.\n",
        "\n",
        "See `praat_analysis/` folder for screenshots.\n",
        "\n",
        "## References\n",
        "\n",
        "- [MFA Documentation](https://montreal-forced-aligner.readthedocs.io/)\n",
        "- [Praat](https://www.fon.hum.uva.nl/praat/)\n",
        "- [ARPA Phoneme Set](https://en.wikipedia.org/wiki/ARPABET)\n",
        "\n",
        "## Takeaways\n",
        "\n",
        "First time working with speech processing. Key lessons:\n",
        "- Text cleaning is critical for NLP pipelines\n",
        "- Dictionary coverage directly impacts alignment quality\n",
        "- Environment setup is half the battle\n",
        "- Phonetic transcription requires careful attention to pronunciation\n",
        "\"\"\"\n",
        "\n",
        "with open('/content/drive/MyDrive/MFA_Assignment_LTRC/README.md', 'w') as f:\n",
        "    f.write(readme_natural)\n",
        "\n",
        "print(\"✓ README.md updated!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyZRx6VbYFYv",
        "outputId": "063134b6-6016-4bcf-8831-1151afc8d743"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ README.md updated!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8gAwRzIEYwhb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}